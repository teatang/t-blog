---
title: 日志采集方案Loki详解：轻量、高效、可扩展
date: 2025-02-11 06:24:00
tags:
  - 2025
  - Loki
  - Grafana
  - 数据监控
  - Prometheus
categories:
  - 开发工具
  - 数据监控
---

> **Loki** 是由 Grafana Labs 构建的一款开源的、**多租户日志聚合系统**，它与其他日志系统最大的不同在于它**不索引日志内容，只索引日志的元数据 (labels)**。这种设计思路使得 Loki 在存储和查询方面都非常高效和经济，尤其适合与 Prometheus 和 Grafana 配合使用，形成一个完整的可观测性栈。

{% note info %}
核心理念：**日志不是用来全文搜索的，而是用来从标签维度过滤的。**
{% endnote %}

## 一、传统日志系统的痛点

在理解 Loki 之前，我们先回顾一下传统日志系统（如 Elasticsearch + Logstash + Kibana，即 ELK 栈）在使用中可能遇到的问题：

1.  **存储成本高昂**：为了实现全文搜索，ELK 会为每条日志的全部内容建立倒排索引。这导致索引数据量巨大，通常是原始日志的数倍，存储成本显著增加。
2.  **维护复杂**：ELK 栈组件多，部署和维护复杂，对系统资源要求高。
3.  **计算资源消耗大**：全文搜索对 CPU 和内存消耗巨大，尤其是在处理海量日志时。
4.  **实时性挑战**：索引构建需要时间，查询实时性可能受影响。

Loki 的出现就是旨在解决这些痛点，提供一个更轻量、更经济的日志解决方案。

## 二、什么是 Loki？

Loki 与 Prometheus 的设计理念非常相似。Prometheus 专注于度量指标 (metrics) 的收集和存储，而 Loki 则专注于日志 (logs)。它们都使用**标签 (labels)** 来识别和组织数据，并且在 Grafana 中可以无缝地进行查询和可视化。

Loki 的关键特点：

1.  **只索引元数据 (Labels)**：这是 Loki 最核心的设计。它不会解析日志内容的每一个词语，而是像 Prometheus 一样，为日志流附加一组键值对标签。这些标签在摄取时被索引，用于快速过滤日志流。
2.  **像 Prometheus 一样操作日志 (Logs like Metrics)**：Loki 鼓励你像处理指标一样处理日志。通过匹配标签，而不是全文搜索，来高效地查询日志。
3.  **分块存储 (Chunked Storage)**：日志数据本身被压缩并以块 (chunks) 的形式存储，不参与索引。只有当标签匹配时，才会加载和扫描相应的日志块。
4.  **LogQL 查询语言**：Loki 使用一种名为 `LogQL` 的查询语言，它受到 Prometheus 的 `PromQL` 启发，语法非常相似，易于学习。
5.  **多租户支持**：原生地支持多租户，可以在同一套 Loki 系统中分离不同租户的日志。
6.  **组件化架构**：Loki 包含多个核心组件，但可以以微服务或单体的方式部署。

## 三、Loki 的核心组件

Loki 的架构设计是高度可扩展和组件化的。一个完整的 Loki 部署通常包括以下核心组件：

1.  **Grafana (前端 UI)**：用于可视化和查询 Loki 中的日志。通过其 explore 功能，可以像 PromQL 一样使用 LogQL 查询日志。
2.  **Promtail (日志收集代理)**：这是 Loki 生态系统中最常用的客户端代理。它运行在需要收集日志的每台机器上，负责从本地文件、Systemd Journal 或其他源读取日志，并为它们添加标签，然后发送到 Loki 服务端。
3.  **Loki 服务端**：核心组件，负责接收、存储和查询日志。它又可以分解为以下微服务：
    *   **Distributor (分发器)**：所有摄入的日志首先到达这里。它验证、格式化日志，计算哈希值，并将日志分发给 Ingester。
    *   **Ingester (摄取器)**：负责接收 Distributors 发送的日志流，将相似标签的日志合并成块，并写入持久存储后端（如 S3、GCS、MinIO、Ceph 或本地文件系统）。它还负责管理索引和块的生命周期。
    *   **Querier (查询器)**：处理来自 Grafana 或其他客户端的 LogQL 查询。它会查询 Index 来找到匹配的日志流，然后从存储中拉取相应的日志块，进行过滤和聚合，最后返回结果。
    *   **Ruler (规则管理器)**：可选组件，类似于 Prometheus 的 Alertmanager，可以根据 LogQL 查询结果触发告警。
    *   **Compactor (压缩器)**：可选组件，负责合并 Ingester 生成的小块，优化存储。

![Loki 架构图 (来源: Grafana Labs)](https://grafana.com/docs/loki/latest/setup/architecture/loki-architecture.png)

## 四、Promtail：日志收集代理

Promtail 是 Loki 的眼睛和耳朵。它的主要职责是：

1.  **发现日志文件**：类似 Prometheus 的服务发现机制，可以通过配置 `scrape_configs` 来定义要收集的日志源。
2.  **添加标签**：根据配置，从文件路径、Kubernetes Pod 元数据或其他信息中提取标签，并附加到日志流上。
3.  **日志转换**：可以使用 `pipeline_stages` 对日志内容进行解析（如 JSON 解析、Regex 匹配）和转换，提取额外标签或重写日志内容。
4.  **发送到 Loki**：将加好标签的日志发送到 Loki 的 Distributor 服务。

**Promtail 配置示例 (`promtail-config.yaml`)**：

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml # 记录已处理日志文件的偏移量，防止重复采集

clients:
  - url: http://loki:3100/loki/api/v1/push # Loki 服务端的 push 接口

scrape_configs:
  - job_name: system # 定义一个任务名称
    static_configs: # 静态配置，用于直接指定文件路径和标签
      - targets:
          - localhost
        labels:
          job: varlogs # 任务标签
          __path__: /var/log/*log # 要监控的日志文件路径
  - job_name: kubernetes-pods # 收集 Kubernetes Pod 日志
    kubernetes_sd_configs:
      - role: pod
    relabel_configs: # 通过 relabel_configs 从 Pod 元数据中提取标签
      - source_labels:
          - __meta_kubernetes_pod_label_app # 从 Pod 标签中提取 app
        target_label: app
      - source_labels:
          - __meta_kubernetes_pod_container_name # 从容器名中提取
        target_label: container
      - source_labels:
          - __meta_kubernetes_namespace # 从命名空间中提取
        target_label: namespace
      - source_labels:
          - __meta_kubernetes_pod_uid
        target_label: pod_uid
      - regex: ^/(.*)
        target_label: __path__
        replacement: /var/log/pods/$1/*.log # 实际的日志文件路径
    pipeline_stages: # 日志管道，可以在发送前处理日志内容
      - json:
          expressions:
            level: level  # 如果日志是 JSON 格式，可以提取 `level` 字段作为标签
      - regex:
          expression: '^(?P<time>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d+Z)\s(?P<log>.*)$' # 匹配时间戳和日志内容
      - labels:
          level: # 将提取的 level 字段作为标签
```

## 五、LogQL：查询语言

LogQL 是 Loki 的查询语言，它的语法与 PromQL 类似，核心是**流选择器 (stream selector)** 和**日志管道 (log pipeline)**。

### 5.1 流选择器

用于过滤日志流，基于标签进行匹配。

*   `{job="nginx"}`：匹配所有 `job` 标签为 `nginx` 的日志流。
*   `{app="frontend", env="production"}`：匹配 `app` 为 `frontend` 且 `env` 为 `production` 的日志流。
*   `{job="nginx", container=~"nginx-(prod|dev)"}`：使用正则表达式匹配 `container` 标签。

### 5.2 日志管道

在选定日志流后，可以使用一系列的操作来进一步过滤、解析和转换日志内容。

*   **行过滤器 (Line filters)**：基于日志内容的字符串或正则表达式匹配。
    *   `|= "error"`：包含 "error" 字符串的日志。
    *   `!~ "debug"`：不包含 "debug" 正则表达式匹配的日志。
*   **解析器 (Parsers)**：从日志行中提取字段。
    *   `| json`：如果日志是 JSON 格式，可以解析出字段。
    *   `| regexp "<expression>"`：使用正则表达式解析字段。
    *   `| logfmt`：解析 logfmt 格式的日志。
*   **标签格式化器 (Label formatters)**：从解析出的字段中创建新的标签或修改现有标签。
    *   `| label_format env="{{.environment}}"`：将解析出的 `environment` 字段值赋给新的 `env` 标签。
*   **指标转换器 (Metric Converters)**：将日志流转换为指标，例如计算日志行数、提取数值进行聚合。
    *   `| count_over_time(1m)`：计算每分钟的日志行数。
    *   `| rate(json.response_time[5m])`：计算 `response_time` 字段在 5 分钟内的平均速率。

**LogQL 示例**：

*   查询 `job` 为 `nginx` 且日志内容包含 `error` 的所有日志：
    ```logql
    {job="nginx"} |= "error"
    ```
*   查询 `namespace` 为 `default` 的 `pod` 日志，并过滤出 `level` 为 `error` 的 JSON 日志：
    ```logql
    {namespace="default", job="kubernetes-pods"} | json | level="error"
    ```
*   统计每 5 分钟内，`job` 为 `my-app` 的日志中，`status_code` 为 `500` 的日志数量：
    ```logql
    sum by (instance) (count_over_time({job="my-app"} |= "status_code=500"[5m]))
    ```

## 六、Loki 的部署方式

Loki 可以以多种方式部署，从单体模式到分布式微服务模式：

1.  **单体部署 (Monolithic)**：所有 Loki 组件运行在一个进程中，适合小型项目或测试环境。
2.  **微服务部署 (Microservices)**：每个组件独立运行，可以横向扩展，适合大规模、高并发场景。这是生产环境推荐的部署方式。
3.  **Helm Chart / Kubernetes Operator**：在 Kubernetes 集群中，Loki 官方提供了 Helm Chart，可以非常方便地部署和管理 Loki 及其组件。许多云提供商也支持。
4.  **Docker Compose**：对于本地开发或小规模部署，可以使用 Docker Compose 快速搭建 Loki + Promtail + Grafana 栈。

## 七、Loki 与其他日志系统的比较

| 特性           | Loki                                      | ELK Stack (Elasticsearch, Logstash, Kibana) | Splunk                                    |
| :------------- | :---------------------------------------- | :------------------------------------------ | :---------------------------------------- |
| **存储方式**   | 只索引元数据 (labels)，日志内容分块存储。 | 全文索引日志内容。                          | 全文索引日志内容，但也支持结构化数据。    |
| **成本**       | **低**，存储和计算资源需求较低。          | **高**，存储和计算资源需求高。              | **非常高**，昂贵的商业许可和硬件成本。    |
| **查询速度**   | 通过标签快速过滤，然后扫描少量日志块。    | 通过倒排索引全文搜索。                    | 通过索引和搜索语言。                      |
| **复杂度**     | 较低，相对易于部署和维护。                | 较高，组件多，维护复杂。                    | 高，功能强大但配置复杂。                  |
| **数据关联**   | 与 Prometheus 的指标数据通过标签高度关联。 | 可通过字段值关联。                          | 可通过字段值关联。                        |
| **场景**       | **可观测性栈** (Metrics + Logs + Traces) | **日志分析、安全审计、运营监控**            | **企业安全、IT 运维、业务分析**           |
| **学习曲线**   | 熟悉 PromQL 后学习 LogQL 较快。           | 需要学习 Elasticsearch 查询 DSL 和 Kibana。 | 需要学习 Splunk Search Processing Language (SPL)。 |

## 八、总结与展望

Loki 以其独特的“只索引元数据”设计，在日志聚合领域开辟了一条新的道路。它与 Prometheus 和 Grafana 形成了一个自然的生态系统，为用户提供了**统一的标签驱动型可观测性体验**。

**Loki 的优势**：

*   **极致的成本效益**：通过减少索引量，大大降低存储和计算成本。
*   **简洁的查询体验**：LogQL 借鉴 PromQL，降低了学习难度，并能方便地将日志和指标关联起来。
*   **轻量和高性能**：适合处理大规模的日志数据，同时保持良好的性能。
*   **云原生友好**：易于在 Kubernetes 等云原生环境中部署和扩展。

Loki 并非要取代所有传统日志系统，它在需要大规模、经济高效地收集和查询运营日志，并与指标数据紧密结合的场景中表现出色。如果你正在构建一套云原生可观测性解决方案，并且已经在使用 Prometheus 和 Grafana，那么 Loki 无疑是你的日志聚合首选。