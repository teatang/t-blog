---
title: 多轮对话与上下文记忆详解
date: 2025-04-27 06:24:00
tags:
  - 2025
  - AI
  - LLM
categories:
  - AI
  - LLM
---

> 在构建基于大型语言模型 (LLM) 的交互式应用时，仅仅能够进行单次问答是远远不够的。为了实现自然、流畅且富有意义的交流，我们需要让 LLM 能够进行**多轮对话**，并且**记住并理解**对话的先前内容，即拥有**上下文记忆 (Context Memory)**。这使得 LLM 能够在理解历史信息的基础上对新问题做出连贯且相关的响应。

{% note info %}
核心思想：**多轮对话要求 LLM "记住"之前的交流内容，并通过各种 "记忆策略" (例如拼接、总结、检索) 来将相关上下文传递给每次新的模型调用，从而实现连贯且智能的交互。**
{% endnote %}

------

## 一、什么是多轮对话 (Multi-turn Conversation)

**多轮对话** 指的是用户与 AI 之间的一系列相互关联、彼此依赖的交流轮次。与单轮对话（一次提问，一次回答，对话结束）不同，多轮对话中的每一次交互都会受到先前对话内容的影响，并且会为后续对话提供新的上下文。

**特点**：
*   **连续性**：多个请求和响应构成一个逻辑流，而非孤立的事件。
*   **上下文依赖**：用户后续的提问或指令常常省略先前已经提及的信息，需要 AI 自动关联。
*   **共同状态维护**：用户和 AI 在对话过程中逐渐建立起对某个主题或任务的共同理解。

**为什么需要多轮对话？**
1.  **自然的用户体验**：模仿人类交流方式，用户无需反复重申背景信息。
2.  **复杂任务解决**：许多复杂任务（如预订、规划、调试）需要逐步明确需求、收集信息，单轮对话难以完成。
3.  **增量式信息输入**：用户可能分多次提供信息，或逐步修正想法。

## 二、什么是上下文记忆 (Context Memory)

**上下文记忆** 是指 LLM 在多轮对话过程中，能够记住并利用先前对话内容的能力。它确保了模型在每次响应时都能考虑到整个对话历史，从而保持对话的连贯性、相关性和准确性。

**为什么上下文记忆至关重要？**
*   **保持连贯性**：防止模型在对话中“忘记”之前说过的话，避免矛盾或重复信息。
*   **理解指代**：允许用户使用代词（如“它”、“那个”）或省略主语，模型能够正确理解其指代的先前实体。
*   **避免重复信息**：用户无需在每次提问时都提供完整的背景信息。
*   **处理复杂任务**：只有记住任务的当前状态和已完成的步骤，才能逐步引导用户完成任务。

**上下文记忆的挑战**：
1.  **Token 窗口限制**：大多数 LLM 都有最大输入 Token 限制。随着对话的进行，历史信息会积累，很容易超出限制。
2.  **相关性过滤**：并非所有历史信息都对当前回复有用，如何有效筛选相关信息是关键。
3.  **信息密度**：随着对话变长，原始对话记录可能变得冗长且低效。
4.  **计算成本**：输入越长，推理成本和延时越高。

## 三、上下文记忆的实现策略

由于 LLM 本身是无状态的，它不会自动“记住”之前的对话。因此，实现上下文记忆需要应用程序在每次调用 LLM 时，策略性地将相关历史信息包含在新的 Prompt 中。

### 3.1 短时记忆 (Short-term Memory)

短时记忆主要关注如何将最近的对话历史直接传递给 LLM。

#### 3.1.1 拼接历史 (Concatenation / Stacking)

这是最直接也最常用的方法，将所有或最近的 N 条对话消息直接作为新的 Prompt 一部分输入给 LLM。

*   **工作原理**：将用户和 AI 之间的每一轮对话（`HumanMessage` 和 `AIMessage`）按时间顺序连接起来，形成一个更长的字符串或消息列表，然后与当前的用户输入一起发送给模型。
*   **优点**：
    *   **简单易实现**：无需复杂的逻辑。
    *   **保留完整语义**：原始对话内容完整地传递给模型。
*   **缺点**：
    *   **Token 限制严重**：对话一长就容易超出 LLM 的输入 Token 限制。
    *   **效率低**：模型每次都需要处理冗余信息，增加推理时间和成本。
*   **适用模型**：非对话模型（需要应用层手动拼接成一个大字符串）和对话模型（通过消息列表形式）。

**示例 (逻辑示意)**：
```
# 初始对话
Prompt = "Human: 你好！\nAI: 你好！有什么可以帮助你的吗？"

# 第二轮
current_user_input = "请问法国大革命是哪一年发生的？"
new_prompt = Prompt + "\nHuman: " + current_user_input + "\nAI:"
# 发送 new_prompt 给 LLM
```

#### 3.1.2 消息列表 (Message List)

专为对话模型设计，通过 `SystemMessage`, `HumanMessage`, `AIMessage` 等对象组成的列表来传递上下文。这是 LangChain 等框架推荐的方式。

*   **工作原理**：将每轮对话包装成特定类型的消息对象，并按照对话顺序存储在列表中。每次调用时，将整个消息列表发送给对话模型。
*   **优点**：
    *   **模型原生支持**：对话模型（如 GPT-3.5-turbo, GPT-4）在训练时就优化了这种输入格式，能更好地理解角色和上下文。
    *   **结构清晰**：消息类型有助于模型区分不同角色的发言。
*   **缺点**：
    *   仍受 Token 限制，但通过模型优化，通常比字符串拼接更有效率。
*   **适用模型**：对话模型 (Chat Models)。

### 3.2 长时记忆 (Long-term Memory)

当对话变得非常长，超出了短时记忆（拼接历史 / 消息列表）的 Token 限制时，我们需要更复杂的策略来总结、过滤或检索相关信息。

#### 3.2.1 总结 (Summarization)

不把所有原始对话内容都传递给模型，而是定期或按需对对话历史进行总结，将摘要作为上下文传递。

*   **工作原理**：当对话历史达到一定长度时，调用 LLM 对过往对话进行总结，生成一个简洁的摘要。后续Prompt中，用这个摘要替代大部分原始历史。
*   **优点**：
    *   **显著节省 Token**：将大量信息压缩成少量 Token。
    *   **保留核心信息**：摘要捕捉对话的关键主题和结论。
*   **缺点**：
    *   **信息损失**：总结不可避免地会丢失一些细节。
    *   **总结质量影响**：如果LLM总结得不好，会影响后续对话质量。
    *   **额外的LLM调用**：总结本身也需要调用LLM，增加了成本和延时。
*   **实现方式示例**：LangChain 中的 `ConversationSummaryMemory`。

#### 3.2.2 基于向量数据库的检索 (Retrieval-Augmented Generation - RAG)

将对话历史（或外部知识库）嵌入成向量并存储在向量数据库中。当需要上下文时，通过当前用户查询的语义相似性从数据库中检索最相关的历史片段。

*   **工作原理**：
    1.  将每一轮对话或重要的外部文档片段嵌入成向量并存储在向量数据库中。
    2.  当用户提出新问题时，将该问题也嵌入成向量。
    3.  在向量数据库中检索与用户问题最相似的 K 段历史对话或知识。
    4.  将检索到的相关片段和当前用户问题一起作为 Prompt 发送给 LLM。
*   **优点**：
    *   **突破 Token 限制**：可以无限扩展记忆容量，只检索最相关的部分。
    *   **结合外部知识**：不仅限于对话历史，还可以引入企业文档、知识库等。
    *   **提高准确性**：为模型提供更精确、更具体的上下文。
*   **缺点**：
    *   **复杂性增加**：需要额外的组件（嵌入模型、向量数据库）。
    *   **检索质量影响**：如果检索到的信息不相关或不准确，会影响 LLM 响应。
    *   **实时性问题**：检索过程会增加延时。
*   **实现方式示例**：LangChain 的 RAG 模式，结合 `VectorStoreRetriever`。

#### 3.2.3 基于图数据库的记忆 (Graph-based Memory)

将对话中提取的实体、概念及其关系存储在图数据库中。模型可以通过对图的遍历来构建更高级的上下文理解。

*   **工作原理**：从对话中识别实体（人、地点、事物）和它们之间的关系，存储在图数据库中。当需要上下文时，根据当前对话焦点，查询图数据库以提取相关的事实和关系。
*   **优点**：
    *   **结构化知识**：提供深层次的语义理解和推理能力。
    *   **避免 Token 爆炸**：不需要存储原始文本，只存储抽象的知识表示。
*   **缺点**：
    *   **实现难度高**：需要强大的实体识别和关系提取能力。
    *   **维护成本**：图数据的更新和管理复杂。
*   **适用场景**：需要复杂逻辑推理、知识关联的Agent或高级对话系统。

## 四、LangChain 中的记忆 (Memory) 模块

LangChain 提供了一套强大的 `Memory` 模块来简化上下文记忆的实现。这些模块封装了不同的记忆策略，并能方便地与 LLM 和 Chain 集成。

所有 LangChain 的 `Memory` 类都继承自 `BaseMemory`。

### 4.1 常见的 LangChain 记忆类型

1.  **`ChatMessageHistory`**: 最基本的记忆类，只存储原始的 `BaseMessage` 列表。
2.  **`ConversationBufferMemory`**: 将所有对话历史作为字符串存储在内存中。最简单，但受 Token 限制。
    *   **工作方式**：将 `input_key` 和 `output_key` 对应的消息拼接成一个字符串。
    *   **示例** (Python):
        ```python
        from langchain.memory import ConversationBufferMemory
        from langchain_openai import ChatOpenAI
        from langchain.chains import ConversationChain

        llm = ChatOpenAI(temperature=0.7)
        memory = ConversationBufferMemory() # 默认为空

        conversation = ConversationChain(
            llm=llm,
            memory=memory,
            verbose=False # 设置为 True 可以看到完整的 Prompt
        )

        print(conversation.invoke("我的名字是 Alice。")['response'])
        print(conversation.invoke("你在和谁说话？")['response'])
        print(conversation.memory.buffer) # 查看记忆中存储的内容
        ```
        输出示例：
        ```
        很高兴认识你，Alice！有什么我可以帮助你的吗？
        我在和 Alice 说话，你就是 Alice 对吧？很高兴能和你交流！
        Human: 我的名字是 Alice。
        AI: 很高兴认识你，Alice！有什么我可以帮助你的吗？
        Human: 你在和谁说话？
        AI: 我在和 Alice 说话，你就是 Alice 对吧？很高兴能和你交流！
        ```

3.  **`ConversationBufferWindowMemory`**: 存储最近 K 轮对话，当对话超过 K 轮时，移除最旧的对话。
    *   **工作方式**：用一个滑动窗口来限制记忆大小，只保留最近的 N 轮对话。
    *   **示例** (Python):
        ```python
        from langchain.memory import ConversationBufferWindowMemory
        # ... (同上导入 ChatOpenAI, ConversationChain)

        # 记住最近 2 轮对话
        memory = ConversationBufferWindowMemory(k=2)

        conversation = ConversationChain(llm=llm, memory=memory)
        _ = conversation.invoke("我的名字是 Alice。")
        _ = conversation.invoke("我的爱好是阅读。")
        _ = conversation.invoke("我现在在问你什么？") # 这里的回答会基于最后2轮对话
        print(conversation.memory.buffer) # 查看记忆中存储的内容，会发现第一轮被移除了
        ```

4.  **`ConversationSummaryMemory`**: 总结对话历史，将摘要存储在内存中。当对话达到一定长度时，旧的原始对话会被摘要替换。
    *   **工作方式**：通过另一个 LLM 对对话历史进行总结，用总结文本作为记忆。
    *   **优点**：有效应对 Token 限制，适用于长对话。
    *   **缺点**：总结过程需额外 LLM 调用。

5.  **`ConversationSummaryBufferMemory`**: `ConversationBufferWindowMemory` 和 `ConversationSummaryMemory` 的结合。在 Token 限制内保留原始对话，超过限制则自动生成摘要。
    *   **工作方式**：在达到某个 Token 阈值之前，行为与 `ConversationBufferMemory` 类似。一旦超过阈值，它就会调用另一个 LLM 来总结较旧的对话，并用摘要替换它们，只保留最近的原始对话块。

6.  **`ConversationTokenBufferMemory`**: 类似于 `ConversationBufferWindowMemory`，但它是基于 Token 数量而不是对话轮次来限制记忆大小。
    *   **优点**：更精确地控制记忆大小，避免超出 LLM Token 限制。

7.  **`ConversationKnnMemory`**: 基于语义相似性检索记忆。存储的记忆会通过 K-近邻算法与当前输入进行匹配，并返回最相关的 K 条记忆。

### 4.2 将记忆集成到 Chain 中

在 LangChain 中，通过在 `Chain` 初始化时传入 `memory` 参数，可以将这些记忆模块轻松集成到对话流中。例如 `ConversationChain`、`RunnableWithMessageHistory`。

**示例：使用 `RunnableWithMessageHistory` 实现存储在会话 ID 中的记忆**
```python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.messages import AIMessage, HumanMessage

# 设置 LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)

# 创建一个 Prompt Template，包含一个 MessagesPlaceholder 用于插入历史消息
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "你是一个友好的助手。在每次对话中，请记住我的名字。"),
        MessagesPlaceholder(variable_name="history"), # Placeholder for the chat history
        ("human", "{input}"),
    ]
)

# 使用 RunnableWithMessageHistory 构建链
# get_session_history 定义了如何为每个会话 ID 获取或创建消息历史
# 这里使用简单的字典模拟数据库存储
store = {}
def get_session_history(session_id: str) -> ChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# 创建一个带记忆的 Runnable 对象
with_message_history = RunnableWithMessageHistory(
    prompt | llm, # LCEL 链: Prompt -> LLM
    get_session_history_for_session=get_session_history,
    input_messages_key="input", # 用户输入的键
    history_messages_key="history", # 历史消息的键
)

# 模拟与不同用户进行对话
# 用户 A
config_user_a = {"configurable": {"session_id": "user_a"}}
print("--- 用户 A 的对话 ---")
print(with_message_history.invoke({"input": "我的名字是 Bob。"}, config=config_user_a).content)
print(with_message_history.invoke({"input": "你在和谁说话？"}, config=config_user_a).content)

# 用户 B
config_user_b = {"configurable": {"session_id": "user_b"}}
print("\n--- 用户 B 的对话 ---")
print(with_message_history.invoke({"input": "我的名字是 Eva。"}, config=config_user_b).content)
print(with_message_history.invoke({"input": "你在和谁说话？"}, config=config_user_b).content)

# 再次与用户 A 对话，之前的信息会被记住
print("\n--- 用户 A 再次对话 ---")
print(with_message_history.invoke({"input": "我的名字是什么？"}, config=config_user_a).content)

# 查看存储
print("\n--- 存储内容 ---")
print(store)
```

## 五、挑战与考量

1.  **Token 爆炸**：这是最核心的挑战。即使通过总结和检索，也总有达到 Token 限制的可能。智能的记忆管理策略是关键。
2.  **遗忘机制**：何时以及如何“遗忘”不相关或过时的信息？如何平衡记忆的广度与深度？
3.  **信息幻觉**：LLM 有时会在总结或响应中出现“幻觉”，凭空捏造信息。记忆管理不当可能加剧此问题。
4.  **隐私与安全**：对话历史可能包含敏感信息。如何在记住对话的同时保护用户隐私是一个重要考量。需要对记忆进行脱敏或加密。
5.  **实时性与成本**：更复杂的记忆策略（如总结、检索）需要额外的计算资源和时间，可能影响应用的实时响应速度和运行成本。
6.  **检索质量**：对于基于检索的记忆，嵌入模型和检索算法的质量直接影响记忆的有效性。

## 六、总结

多轮对话和上下文记忆是构建智能、交互式 LLM 应用的基石。理解 LLM 是无状态的这一本质，并通过策略性地管理和传递上下文，是让 AI 能够理解“记忆”并进行连贯交流的关键。从简单的拼接历史到复杂的总结和检索机制，每种策略都有其优缺点和适用场景。LangChain 等框架提供的 `Memory` 模块极大地简化了这些复杂性的处理，使得开发者能够更专注于构建功能丰富、用户体验友好的 LLM 应用程序。在实际开发中，往往需要根据具体应用需求权衡 Token 效率、信息保持、实时性和成本，选择最合适的记忆策略。