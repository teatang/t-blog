---
title: 共识算法详解
date: 2026-02-20 06:24:00
tags:
  - 2026
  - 计算机网络
  - 网络技术
categories:
  - 计算机网络
  - 网络技术
---

在分布式系统中，如何确保系统中的所有节点就某个数据或操作达成一致，是一个核心挑战。这种在多个独立节点之间达成统一决议的过程被称为**共识 (Consensus)**。共识算法是解决这一问题的关键技术，广泛应用于数据库复制、分布式文件系统、区块链等领域。

> **共识算法 (Consensus Algorithm)** 是一种分布式计算协议，旨在让分布式系统中的多个节点在存在故障（包括节点崩溃、网络延迟、消息丢失甚至恶意行为）的情况下，就某个或某些值达成一致的协议。

{% note info %}
核心思想：在分布式环境中，即使部分节点故障或行为异常，系统也能像单一实体一样运作，对外提供一致的服务。
{% endnote %}

------

## 一、共识的必要性与挑战

### 1.1 为什么需要共识？

在分布式系统中，由于节点之间相互独立，数据复制和服务状态同步是常态。如果没有共识机制，可能出现以下问题：
*   **数据不一致**：不同节点存储的数据版本不同，导致读取结果不确定。
*   **服务分裂 (Split-Brain)**：当集群网络分区时，每个分区的节点都认为自己是活动的，并独立对外提供服务，造成数据冲突和系统行为异常。
*   **操作非原子性**：分布式事务难以保证原子性，可能出现部分成功部分失败的状态。

共识算法旨在解决这些问题，确保分布式系统的**一致性 (Consistency)**、**可用性 (Availability)** 和**分区容错性 (Partition Tolerance)** 之间的权衡（CAP 定理）。在需要强一致性的场景中，共识算法是不可或缺的。

### 1.2 分布式系统中的挑战

达成共识面临诸多挑战：
1.  **网络故障**：消息可能丢失、重复、乱序或延迟。
2.  **节点故障**：节点可能崩溃停止运行 (Crash Faults)。
3.  **拜占庭故障 (Byzantine Faults)**：节点不仅可能崩溃，还可能发送任意错误信息，甚至恶意协作破坏系统。
4.  **异步系统**：在纯异步系统中，无法设定消息传输时间或节点处理时间上限，这使得超时判断变得困难。
5.  **FLP 不可能性定理 (FLP Impossibility)**：在一个完全异步的分布式系统中，只要有一个节点可能崩溃，就不可能设计出一个能保证总能终止的确定性共识算法。这意味着实际的共识算法必须牺牲一些属性，例如引入同步假设（如部分同步系统），或者允许在某些极端情况下不终止，或者引入随机性。

## 二、共识算法的分类与核心属性

根据容错模型，共识算法主要分为两大类：

1.  **崩溃容错 (Crash Fault Tolerant, CFT) 算法**：
    *   假设节点只可能彻底停止运行（崩溃），但不会发送错误或恶意消息。
    *   典型算法：Paxos, Raft。
    *   容错能力：通常可以容忍 $f$ 个节点故障，只需要 $2f+1$ 个或更多的节点存活即可。
2.  **拜占庭容错 (Byzantine Fault Tolerant, BFT) 算法**：
    *   假设节点除了崩溃，还可能出现任意行为，包括发送错误信息、虚假信息或恶意协作。
    *   典型算法：PBFT (Practical Byzantine Fault Tolerance), 以及区块链中的 PoW (Proof of Work), PoS (Proof of Stake) 等。
    *   容错能力：通常可以容忍 $f$ 个拜占庭节点故障，需要至少 $3f+1$ 个节点才能达成共识。

### 2.1 共识算法的核心属性

无论哪种类型，一个有效的共识算法通常需要满足以下属性：

*   **安全性 (Safety)**：
    *   **一致性 (Agreement)**：所有未故障的节点最终都会对同一值达成一致。
    *   **有效性 (Validity)**：如果所有未故障的节点都提议了相同的值，那么最终达成的共识值必须是该值。
    *   **不会产生冲突 (No Conflict)**：一旦某个节点决定了一个值，其他节点就不能决定不同的值。
*   **活性 (Liveness)**：
    *   **终止性 (Termination)**：所有未故障的节点最终都会决定一个值。
    *   **无死锁 (No Starvation)**：只要有足够的节点存活，共识过程总能向前推进。

## 三、经典崩溃容错算法 (CFT)

### 3.1 Paxos

Paxos 是最早提出且最具影响力的共识算法之一，由 Leslie Lamport 于 1990 年代提出。Paxos 的核心挑战在于其理解和实现都非常复杂。

#### 3.1.1 角色定义

Paxos 将参与者分为三类角色：
*   **提议者 (Proposer)**：提议一个值，并试图说服接受者接受该值。
*   **接受者 (Acceptor)**：在众多提议中选择一个值，可以接受或拒绝提议。
*   **学习者 (Learner)**：从接受者那里学习最终被选定的值。

在实际系统中，一个节点通常可以身兼多职。

#### 3.1.2 算法流程

Paxos 算法分为两个阶段，每个阶段使用轮次 (Round Number) 来区分不同的提议：

**阶段 1：准备 (Prepare) 阶段**

1.  **提议者 (Proposer)**：
    *   选择一个**新的提议编号 (proposal number)** $N$，该编号必须比之前用过的所有提议编号都大。
    *   向大多数**接受者 (Acceptors)** 发送一个包含 $N$ 的 **Prepare 请求**。
2.  **接受者 (Acceptor)**：
    *   接收到 Prepare 请求后，如果 $N$ 大于它已经响应过的任何 Prepare 请求的编号，则不再接受编号小于 $N$ 的提议。
    *   向提议者返回一个 **Promise 响应**，承诺不再接受任何编号小于 $N$ 的提议。
    *   如果接受者之前已经接受过任何值，它会把**已接受的最高编号的提议 (Max_Accepted_N, Accepted_Value)** 返回给提议者。

**阶段 2：接受 (Accept) 阶段**

1.  **提议者 (Proposer)**：
    *   如果提议者收到大多数接受者的 Promise 响应，它会检查这些响应中返回的（Max_Accepted_N, Accepted_Value）对。
    *   如果所有响应都没有返回已经接受的值，提议者就可以自由地提出自己的值 $V$。
    *   如果有一个或多个接受者返回了已经接受的值，提议者必须选择其中编号最高的那个值作为自己的提议值 $V$。
    *   向大多数接受者发送一个包含提议编号 $N$ 和提议值 $V$ 的 **Accept 请求**。
2.  **接受者 (Acceptor)**：
    *   接收到 Accept 请求后，如果它还没有向编号大于 $N$ 的 Prepare 请求做出承诺，则**接受 (Accept)** 该提议。
    *   向所有学习者发送一个 **Accepted 响应**。

**值学习 (Value Learning)**：
当学习者收到多数接受者对某个值 $V$ 的 Accepted 响应时，它就知道 $V$ 已经被选定。

{% mermaid %}
sequenceDiagram
    participant P as Proposer
    participant A1 as Acceptor 1
    participant A2 as Acceptor 2
    participant A3 as Acceptor 3
    participant L as Learner

    P->>A1: Prepare(N=1)
    P->>A2: Prepare(N=1)
    P->>A3: Prepare(N=1)
    A1-->>P: Promise(N=1, null)
    A2-->>P: Promise(N=1, null)
    A3-->>P: Promise(N=1, null)

    P->>A1: Accept(N=1, V='value')
    P->>A2: Accept(N=1, V='value')
    P->>A3: Accept(N=1, V='value')
    A1-->>L: Accepted(N=1, V='value')
    A2-->>L: Accepted(N=1, V='value')

    Note right of L: L received 2/3 (majority) Accepted, consensus reached!
{% endmermaid %}

#### 3.1.3 优缺点

*   **优点**：
    *   **高容错性**：在大多数节点正常工作的情况下，即使有故障节点也能达成共识。
    *   **永不冲突 (No Conflict)**：一旦决定了某个值，就不会再改变。
*   **缺点**：
    *   **复杂性高**：难以理解和实现，容易出错。
    *   **活锁风险**：在极端情况下（多个提议者同时竞争），可能会出现 Prepare 请求和 Accept 请求来回竞争，导致活锁，需要额外的机制来打破，如随机退避。
    *   **性能开销大**：两阶段提交以及多轮通信。

### 3.2 Raft

Raft 算法是一种比 Paxos 更易于理解和实现的共识算法，但提供了与 Paxos 相同的容错能力。它由 Ongaro 和 Ousterhout 在 2013 年提出，其设计哲学是“可理解性优先”。

#### 3.2.1 角色定义

Raft 将节点状态分为三种：
*   **领导者 (Leader)**：处理所有客户端请求（日志复制、心跳等），并将日志条目复制到跟随者。集群中在任何时刻最多只有一个领导者。
*   **跟随者 (Follower)**：完全被动，只响应领导者和候选者的请求。
*   **候选者 (Candidate)**：在选举新的领导者时，自身变成候选者，并发起选举。

#### 3.2.2 算法流程

Raft 算法的核心分为三个子问题：

**1. 领导者选举 (Leader Election)**

*   所有节点最初都是跟随者。
*   每个跟随者都有一个随机的**选举超时时间**。
*   如果跟随者在给定的时间内没有收到来自领导者（或候选者）的心跳，它就会增加当前的**任期 (Term)**，并转变为**候选者 (Candidate)**。
*   候选者向所有其他节点发送 **RequestVote RPC (远程过程调用)** 请求投票。
*   **投票规则**：
    *   每个节点在一个任期内只能投一票。
    *   如果候选者的日志至少和自己的日志一样新，并且该节点还没有投票给其他候选者，就会投票给该候选者。
*   **选举结果**：
    *   如果候选者获得大多数节点的投票，它就成为新的领导者，并发送心跳包给所有跟随者。
    *   如果选举超时，没有达到多数，则进入下一个任期并再次发起选举。
    *   如果一个跟随者收到有效领导者的心跳，它就会返回跟随者状态。

{% mermaid %}
sequenceDiagram
    participant F1 as Follower 1
    participant F2 as Follower 2
    participant F3 as Follower 3
    participant F4 as Follower 4
    participant F5 as Follower 5

    Note over F1,F5: All start as Followers
    F1->>F1: Election timeout elapsed
    F1->>F1: F1 becomes Candidate (Term N+1)
    F1->>F2: RequestVote(Term=N+1, LogIndex=X)
    F1->>F3: RequestVote(Term=N+1, LogIndex=X)
    F1->>F4: RequestVote(Term=N+1, LogIndex=X)
    F1->>F5: RequestVote(Term=N+1, LogIndex=X)
    F2-->>F1: Vote(Term=N+1)
    F3-->>F1: Vote(Term=N+1)
    F4-->>F1: Vote(Term=N+1)
    Note over F1: F1 receives 3/5 votes (majority)
    F1->>F1: F1 becomes Leader (Term N+1)
    F1->>F2: AppendEntries (Heartbeat)
    F1->>F3: AppendEntries (Heartbeat)
    F1->>F4: AppendEntries (Heartbeat)
    F1->>F5: AppendEntries (Heartbeat)
{% endmermaid %}

**2. 日志复制 (Log Replication)**

*   所有客户端请求都由**领导者 (Leader)** 处理。
*   领导者把请求作为**日志条目 (Log Entry)** 追加到自己的日志中。
*   领导者并行地向所有**跟随者 (Followers)** 发送 **AppendEntries RPC**（包含新的日志条目和心跳）。
*   跟随者接收到 AppendEntries 后，如果日志一致，则追加日志并返回成功。
*   领导者需要收到**大多数跟随者**的成功响应后，才认为日志条目已**提交 (Committed)**。
*   已提交的日志条目可以被安全地应用到状态机，并回复客户端。
*   Raft 通过强制领导者拥有最新的已提交日志来确保日志一致性 (Log Consistency)。

**3. 安全性 (Safety)**

Raft 引入了“任期”和投票限制来确保安全性：
*   **选举限制**：投票给某个候选者的节点，必须满足候选者的日志至少和自己本地的日志一样新（通过比较日志的任期和索引）。
*   **集群成员变更**：采用**联合一致性 (Joint Consensus)** 机制，平滑地改变集群成员，避免脑裂。

#### 3.2.3 优缺点

*   **优点**：
    *   **易于理解和实现**：相比 Paxos 的一大优势，降低了分布式系统开发的门槛。
    *   **健壮性好**：在各种网络和节点故障下都能正常工作。
    *   **性能较好**：领导者处理所有请求，减少了复杂协商的开销。
*   **缺点**：
    *   **强领导者模式**：所有的请求都需要经过领导者，如果领导者出现故障或网络分区，恢复时间会影响可用性。
    *   **不容忍拜占庭故障**：Raft 依然是 CFT 算法。

## 四、拜占庭容错算法 (BFT)

### 4.1 Practical Byzantine Fault Tolerance (PBFT)

PBFT 是一种高效的拜占庭容错算法，由 Miguel Castro 和 Barbara Liskov 在 1999 年提出。它能在异步网络环境中，容忍不超过 $f$ 个拜占庭节点故障，前提是系统总节点数 $N \geq 3f+1$。

#### 4.1.1 角色定义

PBFT 假设系统中有 $N$ 个副本节点：
*   **主节点 (Primary)**：负责接收客户端请求并协调共识过程。
*   **备份节点 (Backup)**：响应主节点的请求并参与共识。

主节点是动态的，会根据视图编号 (View Number) 轮换。

#### 4.1.2 算法流程

PBFT 算法通过多阶段的投票和消息交换来达成共识，确保即使有恶意节点也无法破坏一致性。

**阶段 0：客户端请求 (Client Request)**

1.  客户端向主节点发送请求 `<REQUEST, o, t, c>`，其中 $o$ 是操作，$t$ 是时间戳，$c$ 是客户端 ID。

**阶段 1：预准备 (Pre-prepare)**

1.  主节点收到客户端请求后，为该请求分配一个序列号 $n$，并向所有备份节点广播一个 **Pre-prepare 消息**：
    `<PRE-PREPARE, v, n, d(o)>`
    其中 $v$ 是当前视图编号，$n$ 是序列号，$d(o)$ 是请求的摘要。
2.  备份节点接收到 Pre-prepare 消息后，进行校验（例如，检查消息的有效性和序列号）。
3.  如果校验通过，备份节点进入 Pre-prepare 状态，并向所有其他节点（包括主节点）广播 **Prepare 消息**。

{% mermaid %}
sequenceDiagram
    participant C as Client
    participant P as Primary (f0)
    participant B1 as Backup 1 (f1)
    participant B2 as Backup 2 (f2)
    participant B3 as Backup 3 (f3)

    C->>P: Request(op, timestamp, client_id)
    Note over P: P assigns sequence 'n'
    P->>B1: Pre-prepare(v, n, Request_digest)
    P->>B2: Pre-prepare(v, n, Request_digest)
    P->>B3: Pre-prepare(v, n, Request_digest)
{% endmermaid %}

**阶段 2：准备 (Prepare)**

1.  所有节点（包括主节点本身）在收到 Pre-prepare 消息后，会向所有其他节点广播 **Prepare 消息**：
    `<PREPARE, v, n, d(o), i>`
    其中 $i$ 是自己的节点 ID。
2.  节点在收到了至少 $2f+1$ 个**合法的 Pre-prepare 和 Prepare 消息**（包括自己的 Pre-prepare 或 Prepare 消息）后，就认为自己进入了 Prepare 状态，表示所有诚实节点都收到了相同的请求。

{% mermaid %}
sequenceDiagram
    participant C as Client
    participant P as Primary (f0)
    participant B1 as Backup 1 (f1)
    participant B2 as Backup 2 (f2)
    participant B3 as Backup 3 (f3)

    C->>P: Request(op, timestamp, client_id)
    P->>B1: Pre-prepare(...)
    P->>B2: Pre-prepare(...)
    P->>B3: Pre-prepare(...)

    B1->>P: Prepare(...)
    B1->>B2: Prepare(...)
    B1->>B3: Prepare(...)
    B2->>P: Prepare(...)
    B2->>B1: Prepare(...)
    B2->>B3: Prepare(...)
    B3->>P: Prepare(...)
    B3->>B1: Prepare(...)
    B3->>B2: Prepare(...)

    Note over P,B3: All nodes collect 2f+1 (e.g., 3 if f=1) Prepare messages
{% endmermaid %}

**阶段 3：提交 (Commit)**

1.  节点进入 Prepare 状态后，会向所有其他节点广播 **Commit 消息**：
    `<COMMIT, v, n, d(o), i>`
2.  当节点收到至少 $2f+1$ 个**合法的 Commit 消息**后，就认为该请求已经被大多数节点认可，进入 Commit 状态。此时，请求可以被安全地应用。

{% mermaid %}
sequenceDiagram
    participant C as Client
    participant P as Primary (f0)
    participant B1 as Backup 1 (f1)
    participant B2 as Backup 2 (f2)
    participant B3 as Backup 3 (f3)

    C->>P: Request(op, timestamp, client_id)
    P->>B1: Pre-prepare(...)
    P->>B2: Pre-prepare(...)
    P->>B3: Pre-prepare(...)

    B1->>P: Prepare(...)
    B1->>B2: Prepare(...)
    B1->>B3: Prepare(...)
    B2->>P: Prepare(...)
    B2->>B1: Prepare(...)
    B2->>B3: Prepare(...)
    B3->>P: Prepare(...)
    B3->>B1: Prepare(...)
    B3->>B2: Prepare(...)

    P->>B1: Commit(...)
    P->>B2: Commit(...)
    P->>B3: Commit(...)
    B1->>P: Commit(...)
    B1->>B2: Commit(...)
    B1->>B3: Commit(...)
    B2->>P: Commit(...)
    B2->>B1: Commit(...)
    B2->>B3: Commit(...)
    B3->>P: Commit(...)
    B3->>B1: Commit(...)
    B3->>B2: Commit(...)

    Note over P,B3: All nodes collect 2f+1 Commit messages, request is committed.
{% endmermaid %}

**阶段 4：回复 (Reply)**

1.  节点提交请求后，执行相应的操作，并将结果发送回客户端：
    `<REPLY, v, t, c, r>`
    其中 $r$ 是操作结果。
2.  客户端等待接收到 $f+1$ 个来自不同节点的相同回复，以确认操作已经完成。

**视图更换 (View Change)**：
如果主节点发生故障或行为异常，备份节点会发起**视图更换**协议，选举新的主节点。这是 PBFT 确保活性的关键。

#### 4.1.3 优缺点

*   **优点**：
    *   **高容错性**：能容忍拜占庭故障，保证安全性和活性。
    *   **最终确定性 (Finality)**：一旦达成共识，交易结果就是最终的，不会被回滚。
    *   **性能较好**：相比于区块链 PoW 机制，在小规模联盟链或私有链中性能显著更高。
*   **缺点**：
    *   **可伸缩性差**：通信复杂度为 $O(N^2)$ (每个节点需要向 $N-1$ 个节点发送消息)，不适用于大规模网络，通常节点数上限在几十个。
    *   **需要知道所有节点信息**：所有节点必须是已知的，且相对稳定，不适用于开放式的公有链。
    *   **初始信任假设**：存在 $f$ 个恶意节点的前提下，要求有 $3f+1$ 个正常节点，意味着对最初的节点设置有一定信任要求。

## 五、区块链中的共识机制简述

区块链技术由于其去中心化和无需信任的特性，对共识算法提出了独特的需求，特别是解决了**开放网络中的拜占庭容错问题**。

*   **工作量证明 (Proof of Work, PoW)**：
    *   **原理**：通过计算满足特定条件的哈希值（“挖矿”）来竞争生成新区块的权利。第一个找到满足条件的节点获得区块奖励，并广播新区块。
    *   **拜占庭容错**：通过巨大的计算成本和“最长链原则”来确保链的安全性。恶意节点难以在计算能力上超越多数诚实节点，从而无法伪造交易或篡改历史。
    *   **优点**：高度去中心化，安全性高。
    *   **缺点**：资源消耗大，交易吞吐量低，确认时间长。
*   **权益证明 (Proof of Stake, PoS)**：
    *   **原理**：节点（验证者）根据其持有的代币数量（权益）来竞争生成新区块的权利。权益越高，被选中的概率越大。
    *   **拜占庭容错**：通过惩罚机制（如 slash 没收质押）来约束恶意行为。恶意行为的成本是其持有的权益，使得作恶经济上不划算。
    *   **优点**：能耗低，交易吞吐量通常高于 PoW。
    *   **缺点**：可能存在“富者越富”效应，中心化风险相对 PoW 理论上更高。

PoW 和 PoS 等区块链共识机制通过结合经济激励和密码学技术，在开放且无需许可的环境中实现了大规模的拜占庭容错。

## 六、共识算法对比

| 特性 / 算法 | Paxos               | Raft                 | PBFT                  | PoW (比特币)          | PoS (以太坊 2.0)     |
| :---------- | :------------------ | :------------------- | :-------------------- | :-------------------- | :------------------- |
| **类型**    | CFT                 | CFT                  | BFT                     | BFT (通过经济激励)    | BFT (通过经济激励)   |
| **容错能力**| $f$ 个节点崩溃      | $f$ 个节点崩溃       | $f$ 个节点拜占庭故障  | 大部分哈希算力为诚实  | 大部分质押为诚实     |
| **所需节点**| $2f+1$              | $2f+1$               | $3f+1$                | 无特定数量，取决于算力分布 | 无特定数量，取决于质押分布 |
| **通信复杂度**| 2PC (两阶段提交)，活锁风险 | Leader-Follower (单领导者) | $O(N^2)$              | 广播区块，P2P 网络   | P2P 网络，委员会投票 |
| **性能/吞吐量** | 中等              | 较好                 | 高 (小规模)           | 极低                  | 中等偏高             |
| **易理解性**| 极复杂              | 易于理解             | 复杂                  | 直观简单（作为用户）  | 相对复杂             |
| **应用场景**| 分布式数据库，文件系统 | 分布式服务，配置管理，K/V 存储 | 联盟链，私有链，许可链 | 公有链                | 公有链，私有链       |
| **最终性**  | 即时性确定        | 即时性确定         | 即时性确定          | 概率性确定（需等待多个区块确认） | 概率性确定（需等待多个 Slot/Epoch 确认） |
| **网络环境**| 部分同步或同步      | 部分同步             | 异步 (但有视图切换保障活性) | 异步                  | 异步                 |

## 七、总结

共识算法是分布式系统领域中的基石，它使多个独立的计算机能够像一个整体一样协同工作，即使在面对各种故障和挑战时也能保持数据的一致性和服务的可靠性。从理论上优美但实践中复杂的 Paxos，到旨在易于理解和实现的 Raft，再到可以抵御恶意节点攻击的 PBFT，每种算法都有其特定的应用场景和优缺点。

随着区块链技术的兴起，以 PoW 和 PoS 为代表的新型共识机制，在开放且无需信任的环境中解决了大规模的拜占庭容错问题，为去中心化应用奠定了基础。

理解这些共识算法的原理，对于设计、实现和维护高性能、高可用且安全的分布式系统至关重要。开发者需要根据系统的具体需求（如容错模型、网络规模、性能要求和一致性级别）来审慎选择和使用适合的共识算法。