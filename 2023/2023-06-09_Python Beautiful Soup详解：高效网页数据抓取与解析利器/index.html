<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Python Beautiful Soup详解：高效网页数据抓取与解析利器 | 1024 维度</title><meta name="author" content="TeaTang"><meta name="copyright" content="TeaTang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Beautiful Soup 是一个 Python 库，用于从 HTML 或 XML 文件中提取数据。它通过解析文档并提供用于导航、搜索和修改解析树的 Pythonic 接口，将复杂的 HTML&#x2F;XML 文档转化为易于处理的数据结构。Beautiful Soup 与 requests 等 HTTP 库结合使用，是构建网络爬虫进行数据抓取的强大工具。  核心思想：Beautiful So">
<meta property="og:type" content="article">
<meta property="og:title" content="Python Beautiful Soup详解：高效网页数据抓取与解析利器">
<meta property="og:url" content="https://blog.tbf1211.xx.kg/2023/2023-06-09_Python%20Beautiful%20Soup%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%AB%98%E6%95%88%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96%E4%B8%8E%E8%A7%A3%E6%9E%90%E5%88%A9%E5%99%A8/index.html">
<meta property="og:site_name" content="1024 维度">
<meta property="og:description" content="Beautiful Soup 是一个 Python 库，用于从 HTML 或 XML 文件中提取数据。它通过解析文档并提供用于导航、搜索和修改解析树的 Pythonic 接口，将复杂的 HTML&#x2F;XML 文档转化为易于处理的数据结构。Beautiful Soup 与 requests 等 HTTP 库结合使用，是构建网络爬虫进行数据抓取的强大工具。  核心思想：Beautiful So">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.tbf1211.xx.kg/img/cover/default_cover-04.jpg">
<meta property="article:published_time" content="2023-06-08T22:24:00.000Z">
<meta property="article:modified_time" content="2025-11-03T10:13:15.815Z">
<meta property="article:author" content="TeaTang">
<meta property="article:tag" content="2023">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="HTML">
<meta property="article:tag" content="网络爬虫">
<meta property="article:tag" content="Beautiful Soup">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.tbf1211.xx.kg/img/cover/default_cover-04.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Python Beautiful Soup详解：高效网页数据抓取与解析利器",
  "url": "https://blog.tbf1211.xx.kg/2023/2023-06-09_Python%20Beautiful%20Soup%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%AB%98%E6%95%88%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96%E4%B8%8E%E8%A7%A3%E6%9E%90%E5%88%A9%E5%99%A8/",
  "image": "https://blog.tbf1211.xx.kg/img/cover/default_cover-04.jpg",
  "datePublished": "2023-06-08T22:24:00.000Z",
  "dateModified": "2025-11-03T10:13:15.815Z",
  "author": [
    {
      "@type": "Person",
      "name": "TeaTang",
      "url": "https://blog.tbf1211.xx.kg"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon-1.ico"><link rel="canonical" href="https://blog.tbf1211.xx.kg/2023/2023-06-09_Python%20Beautiful%20Soup%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%AB%98%E6%95%88%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96%E4%B8%8E%E8%A7%A3%E6%9E%90%E5%88%A9%E5%99%A8/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><meta name="google-site-verification" content="NdIUXAOVyGnnBhcrip0ksCawbdAzT0hlBZDE9u4jx6k"/><meta name="msvalidate.01" content="567E47D75E8DCF1282B9623AD914701E"/><meta name="baidu-site-verification" content="code-pE5rnuxcfD"/><link rel="stylesheet" href="/css/index.css?v=5.5.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":true,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":150,"languages":{"author":"作者: TeaTang","link":"链接: ","source":"来源: 1024 维度","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Python Beautiful Soup详解：高效网页数据抓取与解析利器',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="preconnect" href="https://jsd.012700.xyz"><link href="/self/btf.css" rel="stylesheet"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="1024 维度" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/loading.gif" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">204</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">172</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">58</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 我的轨迹</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/2023/"><i class="fa-fw fa-solid fa-bug"></i><span> 2023</span></a></li><li><a class="site-page child" href="/archives/2024/"><i class="fa-fw fa-solid fa-code"></i><span> 2024</span></a></li><li><a class="site-page child" href="/archives/2025/"><i class="fa-fw fa-solid fa-network-wired"></i><span> 2025</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa-solid fa-calendar-days"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/img/cover/default_cover-04.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">1024 维度</span></a><a class="nav-page-title" href="/"><span class="site-name">Python Beautiful Soup详解：高效网页数据抓取与解析利器</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 我的轨迹</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/2023/"><i class="fa-fw fa-solid fa-bug"></i><span> 2023</span></a></li><li><a class="site-page child" href="/archives/2024/"><i class="fa-fw fa-solid fa-code"></i><span> 2024</span></a></li><li><a class="site-page child" href="/archives/2025/"><i class="fa-fw fa-solid fa-network-wired"></i><span> 2025</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa-solid fa-calendar-days"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Python Beautiful Soup详解：高效网页数据抓取与解析利器</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2023-06-08T22:24:00.000Z" title="发表于 2023-06-09 06:24:00">2023-06-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/%E5%BA%93/">库</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">3.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="umamiPV" data-path="/2023/2023-06-09_Python%20Beautiful%20Soup%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%AB%98%E6%95%88%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96%E4%B8%8E%E8%A7%A3%E6%9E%90%E5%88%A9%E5%99%A8/"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><blockquote>
<p><strong>Beautiful Soup</strong> 是一个 Python 库，用于从 HTML 或 XML 文件中<strong>提取数据</strong>。它通过解析文档并提供用于导航、搜索和修改解析树的 Pythonic 接口，将复杂的 HTML&#x2F;XML 文档转化为易于处理的数据结构。Beautiful Soup 与 <code>requests</code> 等 HTTP 库结合使用，是构建网络爬虫进行数据抓取的强大工具。</p>
</blockquote>
<div class="note info flat"><p>核心思想：Beautiful Soup 将杂乱的 HTML&#x2F;XML 文档“煲成一锅美味的汤”，让你能够轻松地在其中挑选出你需要的数据元素，如同在厨房里筛选食材一样简单。</p>
</div>
<hr>
<h2 id="一、为什么需要-Beautiful-Soup？"><a href="#一、为什么需要-Beautiful-Soup？" class="headerlink" title="一、为什么需要 Beautiful Soup？"></a>一、为什么需要 Beautiful Soup？</h2><p>在网络上，大量有价值的信息以 HTML 页面的形式存在。如果我们需要从这些页面中获取结构化数据（例如，产品信息、新闻标题、评论内容），直接操作原始的 HTML 字符串是非常困难和脆弱的。传统的字符串查找和正则表达式虽然可行，但存在以下问题：</p>
<ul>
<li><strong>HTML 结构复杂</strong>：HTML 标签嵌套层级深，结构不规则，使用正则表达式难以精确匹配。</li>
<li><strong>HTML 容错性</strong>：浏览器会自动纠正不规范的 HTML 结构，但正则表达式无法处理这种容错性。</li>
<li><strong>维护性差</strong>：网页结构一旦改变，正则表达式需要大量修改，维护成本高。</li>
<li><strong>代码可读性差</strong>：复杂的正则表达式难以理解和调试。</li>
</ul>
<p>Beautiful Soup 提供了一个优雅的解决方案：</p>
<ul>
<li><strong>容错性强</strong>：能够处理格式不规范的 HTML 文档，就像浏览器一样。</li>
<li><strong>强大的解析器</strong>：支持多种解析器（如 <code>html.parser</code>, <code>lxml</code>, <code>html5lib</code>），可以根据需求选择。</li>
<li><strong>简单直观的 API</strong>：提供 Python 对象 (<code>Tag</code>, <code>NavigableString</code>, <code>BeautifulSoup</code>) 来表示 HTML 结构，通过 <code>.</code> 属性和 <code>.find()</code>, <code>.find_all()</code> 等方法轻松导航和搜索。</li>
<li><strong>易于数据提取</strong>：方便地获取标签的属性、文本内容。</li>
</ul>
<h2 id="二、安装-Beautiful-Soup"><a href="#二、安装-Beautiful-Soup" class="headerlink" title="二、安装 Beautiful Soup"></a>二、安装 Beautiful Soup</h2><p>Beautiful Soup 库名为 <code>beautifulsoup4</code>（因为它是第四个版本）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>

<p>此外，你可能还需要安装一个 LXML 解析器（推荐，速度快，功能强）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure>

<p>或者 <code>html5lib</code> (浏览器级别的容错性):</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install html5lib</span><br></pre></td></tr></table></figure>

<h2 id="三、基本使用：创建-Beautiful-Soup-对象"><a href="#三、基本使用：创建-Beautiful-Soup-对象" class="headerlink" title="三、基本使用：创建 Beautiful Soup 对象"></a>三、基本使用：创建 Beautiful Soup 对象</h2><p>首先，你需要获取网页的 HTML 内容（通常使用 <code>requests</code> 库），然后将其传给 Beautiful Soup 构造函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: 获取 HTML 内容</span></span><br><span class="line">url = <span class="string">&quot;https://www.example.com&quot;</span> <span class="comment"># 替换为你想抓取的实际网页</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    response.raise_for_status() <span class="comment"># 检查请求是否成功</span></span><br><span class="line">    html_content = response.text</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.HTTPError <span class="keyword">as</span> errh:</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;Http Error:&quot;</span>,errh)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> errc:</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;Error Connecting:&quot;</span>,errc)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.Timeout <span class="keyword">as</span> errt:</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;Timeout Error:&quot;</span>,errt)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> err:</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;OOps: Something Else&quot;</span>,err)</span><br><span class="line">    html_content = <span class="string">&quot;&quot;</span> <span class="comment"># 如果请求失败，将内容设为空</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2: 创建 Beautiful Soup 对象</span></span><br><span class="line"><span class="comment"># 使用 &#x27;lxml&#x27; 解析器 (推荐)</span></span><br><span class="line">soup = BeautifulSoup(html_content, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以使用 Python 内置的 &#x27;html.parser&#x27;</span></span><br><span class="line"><span class="comment"># soup = BeautifulSoup(html_content, &#x27;html.parser&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者 &#x27;html5lib&#x27; (如果遇到极其残缺不全的 HTML)</span></span><br><span class="line"><span class="comment"># soup = BeautifulSoup(html_content, &#x27;html5lib&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Beautiful Soup 对象类型: <span class="subst">&#123;<span class="built_in">type</span>(soup)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;网页标题: <span class="subst">&#123;soup.title.string&#125;</span>&quot;</span>) <span class="comment"># 直接访问 &lt;title&gt; 标签并获取其文本内容</span></span><br></pre></td></tr></table></figure>

<h2 id="四、Beautiful-Soup-的四大对象类型"><a href="#四、Beautiful-Soup-的四大对象类型" class="headerlink" title="四、Beautiful Soup 的四大对象类型"></a>四、Beautiful Soup 的四大对象类型</h2><p>Beautiful Soup 将复杂的 HTML 文档解析成以下四种对象：</p>
<ol>
<li><p><strong><code>BeautifulSoup</code> 对象</strong>：表示整个文档，是解析后的根节点。</p>
<ul>
<li><code>soup</code> 对象本身。</li>
</ul>
</li>
<li><p><strong><code>Tag</code> 对象</strong>：表示 HTML&#x2F;XML 文档中的一个标签，如 <code>&lt;p&gt;</code>, <code>&lt;a&gt;</code>, <code>&lt;div&gt;</code>。</p>
<ul>
<li><code>soup.title</code>, <code>soup.a</code></li>
</ul>
</li>
<li><p><strong><code>NavigableString</code> 对象</strong>：表示标签中的文本内容，但不包含任何标签。</p>
<ul>
<li><code>soup.title.string</code></li>
</ul>
</li>
<li><p><strong><code>Comment</code> 对象</strong>：表示文档中的注释。</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">html_doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;My Home Page&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">    &lt;!-- 这是个注释 --&gt;</span></span><br><span class="line"><span class="string">    &lt;p class=&quot;story&quot;&gt;</span></span><br><span class="line"><span class="string">        Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">        &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">        &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">        &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">        and they lived at the bottom of a well.</span></span><br><span class="line"><span class="string">    &lt;/p&gt;</span></span><br><span class="line"><span class="string">    &lt;p&gt;...&lt;a href=&quot;http://example.com/test&quot;&gt;Test Link&lt;/a&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;/body&gt;&lt;/html&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">soup_example = BeautifulSoup(html_doc, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># BeautifulSoup 对象</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;BeautifulSoup 对象示例: <span class="subst">&#123;<span class="built_in">type</span>(soup_example)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tag 对象</span></span><br><span class="line">title_tag = soup_example.title</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nTitle Tag 对象示例:\n类型: <span class="subst">&#123;<span class="built_in">type</span>(title_tag)&#125;</span>\nTag 名: <span class="subst">&#123;title_tag.name&#125;</span>\nTag 属性: <span class="subst">&#123;title_tag.attrs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># &lt;title&gt;My Home Page&lt;/title&gt;</span></span><br><span class="line"></span><br><span class="line">a_tag = soup_example.a <span class="comment"># 找到第一个 &lt;a&gt; 标签</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n第一个 A Tag 对象示例:\n类型: <span class="subst">&#123;<span class="built_in">type</span>(a_tag)&#125;</span>\nTag 名: <span class="subst">&#123;a_tag.name&#125;</span>\nTag 属性: <span class="subst">&#123;a_tag.attrs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># NavigableString 对象</span></span><br><span class="line">title_string = title_tag.string</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nNavigableString 对象示例:\n类型: <span class="subst">&#123;<span class="built_in">type</span>(title_string)&#125;</span>\n文本内容: <span class="subst">&#123;title_string&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># My Home Page</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Comment 对象</span></span><br><span class="line">comment = soup_example.body.string <span class="comment"># 直接访问可能不是 Comment，需要遍历</span></span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> soup_example.body.contents:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(element, <span class="built_in">type</span>(soup_example.comment)): <span class="comment"># 判断是否是 Comment 类型</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\nComment 对象示例:\n类型: <span class="subst">&#123;<span class="built_in">type</span>(element)&#125;</span>\n注释内容: <span class="subst">&#123;element&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># 这是个注释</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h2 id="五、导航文档树-Navigating-the-Tree"><a href="#五、导航文档树-Navigating-the-Tree" class="headerlink" title="五、导航文档树 (Navigating the Tree)"></a>五、导航文档树 (Navigating the Tree)</h2><p>Beautiful Soup 提供了多种方式来遍历和查找 HTML 元素。</p>
<h3 id="5-1-通过标签名直接访问"><a href="#5-1-通过标签名直接访问" class="headerlink" title="5.1 通过标签名直接访问"></a>5.1 通过标签名直接访问</h3><p>你可以像访问对象的属性一样访问标签名。这会返回找到的第一个同名标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Head 标签: <span class="subst">&#123;soup.head&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Body 标签: <span class="subst">&#123;soup.body&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;第一个 P 标签: <span class="subst">&#123;soup.p&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-2-contents-和-children"><a href="#5-2-contents-和-children" class="headerlink" title="5.2 contents 和 children"></a>5.2 <code>contents</code> 和 <code>children</code></h3><ul>
<li><code>contents</code>：将子节点作为列表返回，包括 <code>NavigableString</code> 和 <code>Tag</code>。</li>
<li><code>children</code>：返回一个生成器，可迭代地获取子节点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">body_tag = soup_example.body</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nBody 的所有子节点 (contents):\n<span class="subst">&#123;body_tag.contents&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># [u&#x27;\n&#x27;, &lt;!-- 这是个注释 --&gt;, u&#x27;\n&#x27;, &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;, u&#x27;\n&#x27;, &lt;p&gt;...&lt;/p&gt;, u&#x27;\n&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> body_tag.children:</span><br><span class="line">    <span class="keyword">if</span> child.name: <span class="comment"># 只打印 Tag 对象</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Body 的子标签: <span class="subst">&#123;child.name&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># p</span></span><br><span class="line"><span class="comment"># p</span></span><br></pre></td></tr></table></figure>

<h3 id="5-3-parent-和-parents"><a href="#5-3-parent-和-parents" class="headerlink" title="5.3 parent 和 parents"></a>5.3 <code>parent</code> 和 <code>parents</code></h3><ul>
<li><code>parent</code>：访问元素的父节点。</li>
<li><code>parents</code>：返回一个生成器，可迭代地获取所有祖先节点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a_tag = soup_example.a</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n第一个 A 标签的父节点: <span class="subst">&#123;a_tag.parent.name&#125;</span>&quot;</span>) <span class="comment"># p</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;第一个 A 标签的所有祖先节点:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> a_tag.parents:</span><br><span class="line">    <span class="keyword">if</span> parent.name:</span><br><span class="line">        <span class="built_in">print</span>(parent.name)</span><br><span class="line"><span class="comment"># p</span></span><br><span class="line"><span class="comment"># body</span></span><br><span class="line"><span class="comment"># html</span></span><br><span class="line"><span class="comment"># [document]</span></span><br></pre></td></tr></table></figure>

<h3 id="5-4-next-sibling-和-previous-sibling"><a href="#5-4-next-sibling-和-previous-sibling" class="headerlink" title="5.4 next_sibling 和 previous_sibling"></a>5.4 <code>next_sibling</code> 和 <code>previous_sibling</code></h3><ul>
<li><code>next_sibling</code>：访问当前节点的下一个兄弟节点。</li>
<li><code>previous_sibling</code>：访问当前节点的上一个兄弟节点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">link1 = soup_example.find(<span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>) <span class="comment"># 找到 id 为 link1 的标签</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n&#x27;Elsie&#x27; 链接的下一个兄弟节点: <span class="subst">&#123;link1.next_sibling&#125;</span>&quot;</span>) <span class="comment"># &#x27;, &#x27; (这是一个 NavigableString)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;&#x27;Elsie&#x27; 链接的下一个兄弟标签: <span class="subst">&#123;link1.next_sibling.next_sibling.name&#125;</span>&quot;</span>) <span class="comment"># a (这是 &#x27;Lacie&#x27; 链接)</span></span><br></pre></td></tr></table></figure>

<h2 id="六、搜索文档树-Searching-the-Tree"><a href="#六、搜索文档树-Searching-the-Tree" class="headerlink" title="六、搜索文档树 (Searching the Tree)"></a>六、搜索文档树 (Searching the Tree)</h2><p>这是 Beautiful Soup 最强大的功能，用于精确查找需要的元素。</p>
<h3 id="6-1-find-和-find-all"><a href="#6-1-find-和-find-all" class="headerlink" title="6.1 find() 和 find_all()"></a>6.1 <code>find()</code> 和 <code>find_all()</code></h3><ul>
<li><strong><code>find_all(name, attrs, recursive, text, limit, **kwargs)</code></strong>：查找所有符合条件的标签。<ul>
<li><code>name</code>：标签名 (e.g., ‘a’, ‘div’, [‘a’, ‘p’])。</li>
<li><code>attrs</code>：属性字典 (e.g., {‘class’: ‘sister’, ‘id’: ‘link1’})。</li>
<li><code>recursive</code>：是否递归查找子孙节点 (默认为 True)。</li>
<li><code>text</code>：查找文本内容。</li>
<li><code>limit</code>：限制返回结果的数量。</li>
</ul>
</li>
<li><strong><code>find(name, attrs, recursive, text, **kwargs)</code></strong>：与 <code>find_all</code> 相同，但只返回第一个符合条件的标签。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找所有 &lt;a&gt; 标签</span></span><br><span class="line">all_a_tags = soup_example.find_all(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n所有 &lt;a&gt; 标签数量: <span class="subst">&#123;<span class="built_in">len</span>(all_a_tags)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> all_a_tags:</span><br><span class="line">    <span class="built_in">print</span>(tag.get(<span class="string">&#x27;href&#x27;</span>), tag.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 class=&#x27;sister&#x27; 的 &lt;a&gt; 标签</span></span><br><span class="line">sister_links = soup_example.find_all(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&#x27;sister&#x27;</span>) <span class="comment"># class 是 Python 关键字，用 class_</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n所有 class=&#x27;sister&#x27; 的 &lt;a&gt; 标签:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> sister_links:</span><br><span class="line">    <span class="built_in">print</span>(link.get(<span class="string">&#x27;href&#x27;</span>), link.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 id=&#x27;link2&#x27; 的标签</span></span><br><span class="line">link2 = soup_example.find(<span class="built_in">id</span>=<span class="string">&#x27;link2&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nID 为 &#x27;link2&#x27; 的标签: <span class="subst">&#123;link2.string&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找所有文本内容为 &#x27;Tillie&#x27; 的标签</span></span><br><span class="line">tillie_tag = soup_example.find(string=<span class="string">&#x27;Tillie&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n文本内容为 &#x27;Tillie&#x27; 的标签: <span class="subst">&#123;tillie_tag.parent.name&#125;</span>&quot;</span>) <span class="comment"># parent 是 &lt;a&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找同时是 &#x27;p&#x27; 标签且 class=&#x27;story&#x27; 的元素</span></span><br><span class="line">story_p = soup_example.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;story&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nClass 为 &#x27;story&#x27; 的 P 标签:\n<span class="subst">&#123;story_p.prettify()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找包含特定字符串的标签</span></span><br><span class="line"><span class="comment"># 例如，查找 href 属性包含 &quot;example.com&quot; 的 &lt;a&gt; 标签</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">example_links = soup_example.find_all(<span class="string">&#x27;a&#x27;</span>, href=re.<span class="built_in">compile</span>(<span class="string">r&quot;example\.com&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nHref 包含 &#x27;example.com&#x27; 的链接:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> example_links:</span><br><span class="line">    <span class="built_in">print</span>(link.get(<span class="string">&#x27;href&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找同时满足多个属性的标签</span></span><br><span class="line">link_by_attrs = soup_example.find(<span class="string">&#x27;a&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;sister&#x27;</span>, <span class="string">&#x27;href&#x27;</span>: <span class="string">&#x27;http://example.com/lacie&#x27;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n按多个属性查找的链接: <span class="subst">&#123;link_by_attrs.string&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="6-2-CSS-选择器-select"><a href="#6-2-CSS-选择器-select" class="headerlink" title="6.2 CSS 选择器 (select())"></a>6.2 CSS 选择器 (<code>select()</code>)</h3><p>Beautiful Soup 支持使用 CSS 选择器来查找元素，这对于前端开发人员来说非常熟悉和方便。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找所有 p 标签</span></span><br><span class="line">all_p_tags = soup_example.select(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n通过 CSS 选择器查找所有 P 标签:\n<span class="subst">&#123;all_p_tags&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 class 为 sister 的 a 标签</span></span><br><span class="line">sister_a_tags = soup_example.select(<span class="string">&#x27;a.sister&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n通过 CSS 选择器查找 class=&#x27;sister&#x27; 的 A 标签:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> sister_a_tags:</span><br><span class="line">    <span class="built_in">print</span>(tag.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 id 为 link3 的标签</span></span><br><span class="line">link3 = soup_example.select_one(<span class="string">&#x27;#link3&#x27;</span>) <span class="comment"># select_one 相当于 find</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n通过 CSS 选择器查找 ID 为 &#x27;link3&#x27; 的标签: <span class="subst">&#123;link3.string&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 p 标签下的所有 a 标签</span></span><br><span class="line">p_a_tags = soup_example.select(<span class="string">&#x27;p a&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n查找 p 标签下的所有 a 标签:\n<span class="subst">&#123;p_a_tags&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结构化选择器: 查找父元素 p 并且 class 是 story 的 a 元素</span></span><br><span class="line">story_a_tags = soup_example.select(<span class="string">&#x27;p.story &gt; a&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n在 class=&#x27;story&#x27; 的 p 标签下的直接子 a 标签:\n<span class="subst">&#123;story_a_tags&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="七、提取数据"><a href="#七、提取数据" class="headerlink" title="七、提取数据"></a>七、提取数据</h2><p>一旦找到目标标签，就可以提取其属性或文本内容。</p>
<h3 id="7-1-获取标签属性"><a href="#7-1-获取标签属性" class="headerlink" title="7.1 获取标签属性"></a>7.1 获取标签属性</h3><p>标签的属性存储在 <code>.attrs</code> 字典中，也可以通过 <code>tag.get()</code> 方法获取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">link1 = soup_example.find(<span class="built_in">id</span>=<span class="string">&#x27;link1&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n链接属性 dict: <span class="subst">&#123;link1.attrs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;链接的 href 属性: <span class="subst">&#123;link1[<span class="string">&#x27;href&#x27;</span>]&#125;</span>&quot;</span>) <span class="comment"># 字典方式访问</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;链接的 class 属性: <span class="subst">&#123;link1.get(<span class="string">&#x27;class&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;尝试获取不存在的属性 (返回 None): <span class="subst">&#123;link1.get(<span class="string">&#x27;data-foo&#x27;</span>)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="7-2-获取文本内容"><a href="#7-2-获取文本内容" class="headerlink" title="7.2 获取文本内容"></a>7.2 获取文本内容</h3><ul>
<li><code>tag.string</code>：如果标签只有一个子 NavigableString，则返回该字符串。如果包含多个子节点或子标签，则返回 None。</li>
<li><code>tag.text</code>：获取标签内所有文本内容的组合，包括子标签的文本，并去除多余空白。</li>
<li><code>tag.get_text()</code>：与 <code>tag.text</code> 类似，但提供了更多参数控制。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">title_tag = soup_example.title</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nTitle 标签的 string: <span class="subst">&#123;title_tag.string&#125;</span>&quot;</span>) <span class="comment"># My Home Page</span></span><br><span class="line"></span><br><span class="line">p_tag = soup_example.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;story&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;P 标签的 string: <span class="subst">&#123;p_tag.string&#125;</span>&quot;</span>) <span class="comment"># None (因为它有文本和多个 &lt;a&gt; 子标签)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;P 标签的 text (所有子标签文本): <span class="subst">&#123;p_tag.text&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="comment"># Elsie,</span></span><br><span class="line"><span class="comment"># Lacie and</span></span><br><span class="line"><span class="comment"># Tillie;</span></span><br><span class="line"><span class="comment"># and they lived at the bottom of a well.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;P 标签的 get_text(separator=&#x27;|&#x27;, strip=True):\n<span class="subst">&#123;p_tag.get_text(separator=<span class="string">&#x27;|&#x27;</span>, strip=<span class="literal">True</span>)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Once upon a time there were three little sisters;|and their names were|Elsie,|Lacie and|Tillie;|and they lived at the bottom of a well.</span></span><br></pre></td></tr></table></figure>

<h2 id="八、常见爬虫流程示例"><a href="#八、常见爬虫流程示例" class="headerlink" title="八、常见爬虫流程示例"></a>八、常见爬虫流程示例</h2><div class="mermaid-wrap"><pre class="mermaid-src" hidden>
    sequenceDiagram
    participant User as 用户
    participant PythonScript as Python 脚本
    participant WebServer as 目标网站服务器

    User-&gt;&gt;PythonScript: 运行爬虫脚本
    PythonScript-&gt;&gt;WebServer: 1. 发送 HTTP 请求 (requests.get(url))
    WebServer-&gt;&gt;PythonScript: 2. 返回 HTML 响应
    PythonScript-&gt;&gt;PythonScript: 3. 使用 Beautiful Soup 解析 HTML (BeautifulSoup(html_content, &#39;lxml&#39;))
    PythonScript-&gt;&gt;PythonScript: 4. 遍历&#x2F;搜索解析树 (find_all(), select())
    PythonScript-&gt;&gt;PythonScript: 5. 提取所需数据 (tag.get(&#39;attr&#39;), tag.text)
    PythonScript-&gt;&gt;PythonScript: 6. 数据清洗与存储 (CSV&#x2F;JSON&#x2F;DB)
    PythonScript-&gt;&gt;User: 7. 提供抓取结果
  </pre></div>

<p><strong>示例：抓取网站导航栏链接</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_navigation_links</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        soup = BeautifulSoup(response.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 假设导航链接在 nav 标签中，并且是 ul &gt; li &gt; a 的结构</span></span><br><span class="line">        <span class="comment"># 这需要根据实际网页结构调整</span></span><br><span class="line">        nav_links = soup.select(<span class="string">&#x27;nav ul li a&#x27;</span>)</span><br><span class="line">      </span><br><span class="line">        links_data = []</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> nav_links:</span><br><span class="line">            text = link.text.strip()</span><br><span class="line">            href = link.get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> text <span class="keyword">and</span> href: <span class="comment"># 确保文本和链接都存在</span></span><br><span class="line">                links_data.append(&#123;<span class="string">&#x27;text&#x27;</span>: text, <span class="string">&#x27;href&#x27;</span>: href&#125;)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> links_data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;请求失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 抓取一个实际网站的例子 (例如，Python 官方文档首页的一部分)</span></span><br><span class="line"><span class="comment"># 注意：抓取任何网站前请查看其 robots.txt 和服务条款，遵守相关规定</span></span><br><span class="line">target_url = <span class="string">&quot;https://www.python.org/doc/&quot;</span></span><br><span class="line">nav_items = get_navigation_links(target_url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> nav_items:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n从 <span class="subst">&#123;target_url&#125;</span> 抓取的导航链接:&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> nav_items:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  文本: <span class="subst">&#123;item[<span class="string">&#x27;text&#x27;</span>]&#125;</span>, 链接: <span class="subst">&#123;item[<span class="string">&#x27;href&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n未能从 <span class="subst">&#123;target_url&#125;</span> 抓取导航链接。&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="九、安全性与注意事项"><a href="#九、安全性与注意事项" class="headerlink" title="九、安全性与注意事项"></a>九、安全性与注意事项</h2><ul>
<li><strong>遵守 <code>robots.txt</code></strong>：在爬取网站之前，务必检查网站的 <code>robots.txt</code> 文件，它声明了网站允许或禁止爬取的规则。</li>
<li><strong>频率限制</strong>：不要在短时间内向网站发送大量请求，这可能导致你的 IP 被封锁，甚至对网站服务器造成负担。</li>
<li><strong>用户代理 (User-Agent)</strong>：模拟浏览器请求头，防止被网站识别为爬虫。</li>
<li><strong>处理异常</strong>：网络请求和解析过程中都可能出现异常（如网络错误、页面结构变化），需要使用 <code>try-except</code> 块进行处理。</li>
<li><strong>异步抓取</strong>：对于大规模抓取，考虑使用 <code>httpx</code> 或 <code>aiohttp</code> 配合 <code>asyncio</code> 进行异步请求，提高效率。</li>
<li><strong>验证码&#x2F;反爬机制</strong>：高级的反爬虫机制（如验证码、JS 动态加载、数据加密等）可能需要更复杂的解决方案，如 Selenium (针对 JS 渲染) 或机器学习。</li>
<li><strong>法律与道德</strong>：尊重网站版权和隐私，不要抓取敏感数据，遵守当地法律法规。</li>
</ul>
<h2 id="十、总结与进阶"><a href="#十、总结与进阶" class="headerlink" title="十、总结与进阶"></a>十、总结与进阶</h2><p>Beautiful Soup 是 Python 爬虫入门和处理结构化数据提取的绝佳选择。它的 API 友好，易于学习，并且能够很好地处理不规范的 HTML。</p>
<p><strong>进阶方向：</strong></p>
<ul>
<li><strong>与 <code>Requests</code> 库深度结合</strong>：学习如何处理会话 (Session)、Cookies、代理、头部信息等。</li>
<li><strong>动态网页抓取 (<code>Selenium</code>)</strong>：对于 JavaScript 动态渲染的网页，Beautiful Soup 无法直接获取渲染后的内容，需要结合 Selenium 自动化浏览器。</li>
<li><strong>Scrapy 框架</strong>：对于更复杂、大规模的爬虫项目，使用 Scrapy 这种专业的爬虫框架能提供更多功能（如调度、中间件、管道）。</li>
<li><strong>数据存储</strong>：将抓取到的数据存储到 CSV、JSON、数据库（SQLite, PostgreSQL, MongoDB）等。</li>
<li><strong>异常处理和日志记录</strong>：构建健壮的爬虫，处理各种运行时错误。</li>
</ul>
<p>掌握 Beautiful Soup，你将能够从海量的网页信息中提取有用的数据，为数据分析、市场研究、内容聚合等提供原始数据支持。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.tbf1211.xx.kg">TeaTang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.tbf1211.xx.kg/2023/2023-06-09_Python%20Beautiful%20Soup%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%AB%98%E6%95%88%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96%E4%B8%8E%E8%A7%A3%E6%9E%90%E5%88%A9%E5%99%A8/">https://blog.tbf1211.xx.kg/2023/2023-06-09_Python%20Beautiful%20Soup%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%AB%98%E6%95%88%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96%E4%B8%8E%E8%A7%A3%E6%9E%90%E5%88%A9%E5%99%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.tbf1211.xx.kg" target="_blank">1024 维度</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2023/">2023</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/HTML/">HTML</a><a class="post-meta__tags" href="/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/">网络爬虫</a><a class="post-meta__tags" href="/tags/Beautiful-Soup/">Beautiful Soup</a></div><div class="post-share"><div class="social-share" data-image="/img/cover/default_cover-04.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2023/2023-06-15_Python%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BB%8E%E5%9F%BA%E7%A1%80%E5%88%B0%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/" title="Python装饰器详解：从基础到高级应用"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-25.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Python装饰器详解：从基础到高级应用</div></div><div class="info-2"><div class="info-item-1"> Python 装饰器 (Decorators) 是一种强大而优雅的语法糖，它允许你在不修改原函数代码的情况下，给函数添加额外的功能或修改其行为。装饰器本质上是一个接受函数作为参数并返回一个新函数的函数。它广泛应用于日志记录、性能测试、事务处理、权限验证等场景，是 Python 高级编程中不可或缺的工具。  “装饰器是 Python 的一项强大功能，它使得代码更加模块化、可读性更高，能够优雅地实现功能的扩展和复用，而无需侵入式地修改原有代码。”   一、理解装饰器前的预备知识要真正理解装饰器，我们需要先掌握几个 Python 核心概念： 1.1 函数是第一类对象 (First-Class Objects)在 Python 中，函数与其他数据类型（如整数、字符串）一样，是第一类对象。这意味着你可以：  将函数赋值给变量 将函数作为参数传递给其他函数 将函数作为另一个函数的返回值 在数据结构中存储函数  示例： 123456789101112131415161718192021def greet(name):    return f&quot;Hello, &#123;name&#1...</div></div></div></a><a class="pagination-related" href="/2023/2023-06-05_Python%20lxml%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%AB%98%E6%95%88XML%20HTML%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%A4%84%E7%90%86/" title="Python lxml详解：高效XML/HTML解析与处理"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-14.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Python lxml详解：高效XML/HTML解析与处理</div></div><div class="info-2"><div class="info-item-1"> lxml 是 Python 的一个强大且功能丰富的库，用于解析和处理 XML 和 HTML 文档。它结合了 C 语言库 libxml2 和 libxslt 的速度和功能，以及 Python 的简洁和灵活性。lxml 提供了多种解析方式（如 ElementTree API 和 SAX），并支持强大的 XPath 和 CSS 选择器进行数据提取。在高性能要求的场景下，lxml 往往是处理大型 XML&#x2F;HTML 文档的首选。  核心思想：lxml 利用底层的 C 库，提供了比纯 Python 解析器快得多的性能，同时通过 Pythonic 的接口，使得 XML&#x2F;HTML 的解析、导航和数据提取变得高效而直观。   一、为什么选择 lxml？在 Python 处理 XML&#x2F;HTML 文档时，我们有多种选择，例如 Python 标准库中的 xml.etree.ElementTree、minidom，以及 Beautiful Soup。然而，lxml 在性能和功能上提供了独特的优势：  极高的性能：由于其核心解析引擎是用 C 语言实现的 libxml2 和 l...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2023/2023-06-05_Python%20lxml%E8%AF%A6%E8%A7%A3%EF%BC%9A%E9%AB%98%E6%95%88XML%20HTML%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%A4%84%E7%90%86/" title="Python lxml详解：高效XML&#x2F;HTML解析与处理"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-14.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-05</div><div class="info-item-2">Python lxml详解：高效XML&#x2F;HTML解析与处理</div></div><div class="info-2"><div class="info-item-1"> lxml 是 Python 的一个强大且功能丰富的库，用于解析和处理 XML 和 HTML 文档。它结合了 C 语言库 libxml2 和 libxslt 的速度和功能，以及 Python 的简洁和灵活性。lxml 提供了多种解析方式（如 ElementTree API 和 SAX），并支持强大的 XPath 和 CSS 选择器进行数据提取。在高性能要求的场景下，lxml 往往是处理大型 XML&#x2F;HTML 文档的首选。  核心思想：lxml 利用底层的 C 库，提供了比纯 Python 解析器快得多的性能，同时通过 Pythonic 的接口，使得 XML&#x2F;HTML 的解析、导航和数据提取变得高效而直观。   一、为什么选择 lxml？在 Python 处理 XML&#x2F;HTML 文档时，我们有多种选择，例如 Python 标准库中的 xml.etree.ElementTree、minidom，以及 Beautiful Soup。然而，lxml 在性能和功能上提供了独特的优势：  极高的性能：由于其核心解析引擎是用 C 语言实现的 libxml2 和 l...</div></div></div></a><a class="pagination-related" href="/2023/2023-02-09_Python%E5%85%83%E7%B1%BB(Metaclass)%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/" title="Python元类(Metaclass)深度解析"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-17.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-09</div><div class="info-item-2">Python元类(Metaclass)深度解析</div></div><div class="info-2"><div class="info-item-1">Python 元类深度解析：从概念到实战  “Everything is an object.” - Python之禅“Classes are objects too.” - 元类的核心思想  在 Python 中，万物皆对象。你用 class 关键字定义的类，例如 str、int、list，它们本身也是对象。那么，是谁创建了这些类对象呢？答案就是“元类”(Metaclass)。元类是创建类的类，它允许我们在类被创建时对其行为进行定制，是 Python 中进行高级面向对象编程的强大工具。 1. 什么是元类？在 Python 中，当你定义一个类 class MyClass: pass 的时候，Python 解释器会自动执行以下步骤：  定义一个类对象：解释器读取 MyClass 的定义，并创建一个名为 MyClass 的类对象。 将类对象绑定到命名空间：这个 MyClass 类对象被绑定到当前的命名空间中。  然后，当你通过 my_instance = MyClass() 来创建实例时，MyClass 这个类对象就会被调用，从而创建并返回一个实例对象。 元类就是用来创建这些类对象的...</div></div></div></a><a class="pagination-related" href="/2023/2023-02-15_Python%20NumPy%E8%AF%A6%E8%A7%A3%EF%BC%9A%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E7%9A%84%E5%9F%BA%E7%9F%B3/" title="Python NumPy详解：科学计算的基石"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-21.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-15</div><div class="info-item-2">Python NumPy详解：科学计算的基石</div></div><div class="info-2"><div class="info-item-1"> NumPy (Numerical Python) 是 Python 中用于科学计算的核心库。它提供了一个高性能的多维数组对象 ndarray，以及用于处理这些数组的工具。NumPy 是 Python 数据科学和机器学习生态系统的基石，许多其他库（如 SciPy, Pandas, Matplotlib, Scikit-learn）都建立在 NumPy 数组之上。  核心思想：NumPy 引入了高效的 ndarray 数据结构，通过向量化操作显著提升了 Python 处理数值数据的性能。   一、为什么选择 NumPy？Python 语言本身处理列表等数据结构时效率较高，但对于大规模数值计算而言，原生的 Python 列表效率低下。NumPy 通过以下方式解决了这个问题：  高性能 ndarray 对象：ndarray 存储同类型数据，在内存中连续存储，相比 Python 列表，占用的内存更少，访问速度更快。 向量化操作：NumPy 允许对整个数组进行操作，而无需编写显式的循环。这些操作通常在 C 或 Fortran 中实现，执行速度远超 Python 循环。 广播 (Broadc...</div></div></div></a><a class="pagination-related" href="/2023/2023-02-17_Pug(%E5%89%8DJade)%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E%E8%AF%A6%E8%A7%A3/" title="Pug(前Jade)模板引擎详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-04.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-17</div><div class="info-item-2">Pug(前Jade)模板引擎详解</div></div><div class="info-2"><div class="info-item-1"> Pug（发音 &#x2F;pʌɡ&#x2F;），前身为 Jade，是一个高性能的 Node.js 模板引擎。它以其简洁、富有表现力的语法而闻名，旨在让 HTML 编写变得更加高效和愉快。Pug 摒弃了传统 HTML 的尖括号和闭合标签，转而使用缩进和基于文本的语法，这使得模板文件更小、更易读、也更不易出错。  核心思想：Pug 通过简洁的缩进语法替代冗长的 HTML 标签，提供强大的动态数据渲染、代码重用和条件逻辑功能。   一、Pug 简介1.1 什么是模板引擎？模板引擎是一种将数据填充到预定义模板中以生成最终输出（通常是 HTML 字符串）的工具。它将页面的结构（模板）与数据分离，使得前端开发更加模块化和可维护。 1.2 Pug 的特点 独特语法：使用缩进表示嵌套关系，无需关闭标签。 简洁明了：代码量显著少于对应的 HTML。 强大功能：支持变量、循环、条件判断、Mixin（类似于函数或组件）、包含（文件复用）、布局继承等高级特性。 编译到 HTML：Pug 模板最终会被编译成标准的 HTML。 Node.js 支持：作为 Node.js 的模板引擎，Pug 完美集成于 E...</div></div></div></a><a class="pagination-related" href="/2023/2023-02-21_Python%20Pandas%E8%AF%A6%E8%A7%A3%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E5%88%86%E6%9E%90%E7%9A%84%E7%91%9E%E5%A3%AB%E5%86%9B%E5%88%80/" title="Python Pandas详解：数据处理与分析的瑞士军刀"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-02.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-21</div><div class="info-item-2">Python Pandas详解：数据处理与分析的瑞士军刀</div></div><div class="info-2"><div class="info-item-1"> Pandas 是 Python 中用于数据分析和处理的核心库。它提供了一套高性能、易于使用的数据结构，最主要的是 DataFrame（二维表格数据）和 Series（一维带标签数组），用于快速处理和分析结构化数据（如 CSV、Excel、数据库表格数据）。Pandas 以其直观的语法和强大的功能，成为数据科学家和数据工程师的首选工具。  核心思想：Pandas 将表格数据抽象为 DataFrame 和 Series 对象，提供类似 SQL 和 Excel 的操作，通过向量化和 C&#x2F;Cython 实现的底层优化，极大提升了数据处理效率。   一、为什么选择 Pandas？在数据驱动的时代，我们经常需要处理各种形式的表格数据。Python 原生的数据结构（如列表、字典）虽然灵活，但在处理大量、复杂、异构的表格数据时显得力不从心。Pandas 解决了这些痛点：  直观的数据结构：DataFrame 和 Series 提供了强大的标签索引功能，使得数据操作更加直观，无需关注底层实现。 高效的数据操作：底层基于 NumPy 优化，利用 C 和 Cython 实现，对于大规模数据...</div></div></div></a><a class="pagination-related" href="/2023/2023-02-28_Python%20Requests%E5%BA%93%E8%AF%A6%E8%A7%A3%EF%BC%9AHTTP%E8%AF%B7%E6%B1%82%E7%9A%84%E8%89%BA%E6%9C%AF/" title="Python Requests库详解：HTTP请求的艺术"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-18.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-28</div><div class="info-item-2">Python Requests库详解：HTTP请求的艺术</div></div><div class="info-2"><div class="info-item-1"> requests 库 是 Python 生态系统中最流行、最强大、也是最优雅的 HTTP 客户端库之一。它简化了复杂的 HTTP 请求操作，让开发者能够以极少量的代码发送各种类型的 HTTP 请求，并轻松处理响应。与 Python 内置的 urllib 模块相比，requests 提供了更友好、更直观的 API，被誉为“面向人类的 HTTP 服务”。  核心思想：requests 封装了底层 HTTP 协议的复杂性，提供简洁的 API，让开发者专注于业务逻辑而非网络通信的细节。   一、为什么选择 Requests？在 Python 中进行 HTTP 请求有多种方式，例如内置的 urllib 模块。但 requests 库之所以广受欢迎，主要得益于以下优势：  友好的 API：设计直观，易学易用，代码可读性高。 功能强大：支持几乎所有 HTTP 功能，包括 GET, POST, PUT, DELETE 等方法，以及请求头、数据、文件上传、Cookie、身份认证、代理、SSL 验证等。 自动处理：自动处理 URL 编码、重定向、会话管理等常见任务。 JSON 支持：内置 JSON...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/loading.gif" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">TeaTang</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">204</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">172</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">58</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/teatang"><i class="fab fa-github"></i><span>GitHub主页</span></a><div class="card-info-social-icons"><a class="social-icon" href="mailto:tea.tang1211@gmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">网站更多功能即将上线，敬请期待！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-Beautiful-Soup%EF%BC%9F"><span class="toc-text">一、为什么需要 Beautiful Soup？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85-Beautiful-Soup"><span class="toc-text">二、安装 Beautiful Soup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%EF%BC%9A%E5%88%9B%E5%BB%BA-Beautiful-Soup-%E5%AF%B9%E8%B1%A1"><span class="toc-text">三、基本使用：创建 Beautiful Soup 对象</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Beautiful-Soup-%E7%9A%84%E5%9B%9B%E5%A4%A7%E5%AF%B9%E8%B1%A1%E7%B1%BB%E5%9E%8B"><span class="toc-text">四、Beautiful Soup 的四大对象类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AF%BC%E8%88%AA%E6%96%87%E6%A1%A3%E6%A0%91-Navigating-the-Tree"><span class="toc-text">五、导航文档树 (Navigating the Tree)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E9%80%9A%E8%BF%87%E6%A0%87%E7%AD%BE%E5%90%8D%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE"><span class="toc-text">5.1 通过标签名直接访问</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-contents-%E5%92%8C-children"><span class="toc-text">5.2 contents 和 children</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-parent-%E5%92%8C-parents"><span class="toc-text">5.3 parent 和 parents</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-next-sibling-%E5%92%8C-previous-sibling"><span class="toc-text">5.4 next_sibling 和 previous_sibling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%90%9C%E7%B4%A2%E6%96%87%E6%A1%A3%E6%A0%91-Searching-the-Tree"><span class="toc-text">六、搜索文档树 (Searching the Tree)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-find-%E5%92%8C-find-all"><span class="toc-text">6.1 find() 和 find_all()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-CSS-%E9%80%89%E6%8B%A9%E5%99%A8-select"><span class="toc-text">6.2 CSS 选择器 (select())</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-text">七、提取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E5%B1%9E%E6%80%A7"><span class="toc-text">7.1 获取标签属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E8%8E%B7%E5%8F%96%E6%96%87%E6%9C%AC%E5%86%85%E5%AE%B9"><span class="toc-text">7.2 获取文本内容</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%B8%B8%E8%A7%81%E7%88%AC%E8%99%AB%E6%B5%81%E7%A8%8B%E7%A4%BA%E4%BE%8B"><span class="toc-text">八、常见爬虫流程示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E5%AE%89%E5%85%A8%E6%80%A7%E4%B8%8E%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-text">九、安全性与注意事项</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%81%E3%80%81%E6%80%BB%E7%BB%93%E4%B8%8E%E8%BF%9B%E9%98%B6"><span class="toc-text">十、总结与进阶</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/2025-10-28_nftables%20%E8%AF%A6%E8%A7%A3/" title="nftables 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-20.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="nftables 详解"/></a><div class="content"><a class="title" href="/2025/2025-10-28_nftables%20%E8%AF%A6%E8%A7%A3/" title="nftables 详解">nftables 详解</a><time datetime="2025-10-27T22:24:00.000Z" title="发表于 2025-10-28 06:24:00">2025-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/2025-10-25_iptables%20%E8%AF%A6%E8%A7%A3/" title="iptables 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-22.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="iptables 详解"/></a><div class="content"><a class="title" href="/2025/2025-10-25_iptables%20%E8%AF%A6%E8%A7%A3/" title="iptables 详解">iptables 详解</a><time datetime="2025-10-24T22:24:00.000Z" title="发表于 2025-10-25 06:24:00">2025-10-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/2025-10-23_Go%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C%E8%AF%A6%E8%A7%A3/" title="Go语言并发与并行详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-10.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Go语言并发与并行详解"/></a><div class="content"><a class="title" href="/2025/2025-10-23_Go%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C%E8%AF%A6%E8%A7%A3/" title="Go语言并发与并行详解">Go语言并发与并行详解</a><time datetime="2025-10-22T22:24:00.000Z" title="发表于 2025-10-23 06:24:00">2025-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/2025-10-16_%E5%B8%B8%E7%94%A8%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E7%9A%84Go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/" title="常用限流算法的Go语言实现详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-14.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="常用限流算法的Go语言实现详解"/></a><div class="content"><a class="title" href="/2025/2025-10-16_%E5%B8%B8%E7%94%A8%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E7%9A%84Go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/" title="常用限流算法的Go语言实现详解">常用限流算法的Go语言实现详解</a><time datetime="2025-10-15T22:24:00.000Z" title="发表于 2025-10-16 06:24:00">2025-10-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/2025-10-10_NativeScript-Vue3%E8%AF%A6%E8%A7%A3/" title="NativeScript-Vue3详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-03.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="NativeScript-Vue3详解"/></a><div class="content"><a class="title" href="/2025/2025-10-10_NativeScript-Vue3%E8%AF%A6%E8%A7%A3/" title="NativeScript-Vue3详解">NativeScript-Vue3详解</a><time datetime="2025-10-09T22:24:00.000Z" title="发表于 2025-10-10 06:24:00">2025-10-10</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/cover/default_cover-04.jpg);"><div class="footer-flex"><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">我的轨迹</div><div class="footer-flex-content"><a href="/archives/2023/" target="_blank" title="📌 2023">📌 2023</a><a href="/archives/2024/" target="_blank" title="❓ 2024">❓ 2024</a><a href="/archives/2025/" target="_blank" title="🚀 2025">🚀 2025</a></div></div></div><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">维度</div><div class="footer-flex-content"><a href="/categories/" target="_blank" title="分类">分类</a><a href="/tags/" target="_blank" title="标签">标签</a><a href="/categories/" target="_blank" title="时间线">时间线</a></div></div></div><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">其他</div><div class="footer-flex-content"><a href="/shuoshuo" target="_blank" title="说说">说说</a></div></div></div></div><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2021 - 2025 By TeaTang</span><span class="framework-info"><span class="footer-separator">|</span><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.1"></script><script src="/js/main.js?v=5.5.1"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.0/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const applyThemeDefaultsConfig = theme => {
    if (theme === 'dark-mode') {
      Chart.defaults.color = "rgba(255, 255, 255, 0.8)"
      Chart.defaults.borderColor = "rgba(255, 255, 255, 0.2)"
      Chart.defaults.scale.ticks.backdropColor = "transparent"
    } else {
      Chart.defaults.color = "rgba(0, 0, 0, 0.8)"
      Chart.defaults.borderColor = "rgba(0, 0, 0, 0.1)"
      Chart.defaults.scale.ticks.backdropColor = "transparent"
    }
  }

  // Recursively traverse the config object and automatically apply theme-specific color schemes
  const applyThemeConfig = (obj, theme) => {
    if (typeof obj !== 'object' || obj === null) return

    Object.keys(obj).forEach(key => {
      const value = obj[key]
      // If the property is an object and has theme-specific options, apply them
      if (typeof value === 'object' && value !== null) {
        if (value[theme]) {
          obj[key] = value[theme] // Apply the value for the current theme
        } else {
          // Recursively process child objects
          applyThemeConfig(value, theme)
        }
      }
    })
  }

  const runChartJS = ele => {
    window.loadChartJS = true

    Array.from(ele).forEach((item, index) => {
      const chartSrc = item.firstElementChild
      const chartID = item.getAttribute('data-chartjs-id') || ('chartjs-' + index) // Use custom ID or default ID
      const width = item.getAttribute('data-width')
      const existingCanvas = document.getElementById(chartID)

      // If a canvas already exists, remove it to avoid rendering duplicates
      if (existingCanvas) {
          existingCanvas.parentNode.remove()
      }

      const chartDefinition = chartSrc.textContent
      const canvas = document.createElement('canvas')
      canvas.id = chartID

      const div = document.createElement('div')
      div.className = 'chartjs-wrap'

      if (width) {
        div.style.width = width
      }

      div.appendChild(canvas)
      chartSrc.insertAdjacentElement('afterend', div)

      const ctx = document.getElementById(chartID).getContext('2d')

      const config = JSON.parse(chartDefinition)

      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark-mode' : 'light-mode'

      // Set default styles (initial setup)
      applyThemeDefaultsConfig(theme)

      // Automatically traverse the config and apply dual-mode color schemes
      applyThemeConfig(config, theme)

      new Chart(ctx, config)
    })
  }

  const loadChartJS = () => {
    const chartJSEle = document.querySelectorAll('#article-container .chartjs-container')
    if (chartJSEle.length === 0) return

    window.loadChartJS ? runChartJS(chartJSEle) : btf.getScript('https://cdn.jsdelivr.net/npm/chart.js@4.5.0/dist/chart.umd.min.js').then(() => runChartJS(chartJSEle))
  }

  // Listen for theme change events
  btf.addGlobalFn('themeChange', loadChartJS, 'chartjs')
  btf.addGlobalFn('encrypt', loadChartJS, 'chartjs')

  window.pjax ? loadChartJS() : document.addEventListener('DOMContentLoaded', loadChartJS)
})()</script></div><script data-pjax src="/self/btf.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="ture"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,200,200" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => {
      try {
        fn()
      } catch (err) {
        console.debug('Pjax callback failed:', err)
      }
    })
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      true
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script>(() => {
  const option = null
  const config = {"site_uv":true,"site_pv":true,"page_pv":true,"token":"qTvz1SkmPDt785fgh6BpiA5qiFFIVUwxj8Ft+rPW+cdN59v1hXjwRgSmy0+ji9m+oLlcxvo2NfDSMa6epVl3NTlsN3ejCIwWeP8Y51aEJ0Sbem4UexGmJLspB7AkOBId2SdtT6QWEBlGmFIIQgchQ2zAKYxTmc/kpBED5aLSr+3uvmQ9/G7FJQeVFpveDkK0xM1hu36xq4a6/FSeROxtoEp5zabzTWiYTlLsQzIl/NlELnCq3nxK+oo/vl3UQo/oM/rae/gJX/MaVKsgIUCd2ABJogNkx2KTenBIBpbPki5FzOgPh6/z4GPa4HvhNO51DDVG1SEQZooqEYmt/gnybLBWFbN+7liZWw=="}

  const runTrack = () => {
    if (typeof umami !== 'undefined' && typeof umami.track === 'function') {
      umami.track(props => ({ ...props, url: window.location.pathname, title: GLOBAL_CONFIG_SITE.title }))
    } else {
      console.warn('Umami Analytics: umami.track is not available')
    }
  }

  const loadUmamiJS = () => {
    btf.getScript('https://umami.012700.xyz/script.js', {
      'data-website-id': '2a796d6c-6499-42d8-8eb4-d9a2930b0ff3',
      'data-auto-track': 'false',
      ...option
    }).then(() => {
      runTrack()
    }).catch(error => {
      console.error('Umami Analytics: Error loading script', error)
    })
  }

  const getData = async (isPost) => {
    try {
      const now = Date.now()
      const keyUrl = isPost ? `&url=${window.location.pathname}` : ''
      const headerList = { 'Accept': 'application/json' }

      if (true) {
        headerList['Authorization'] = `Bearer ${config.token}`
      } else {
        headerList['x-umami-api-key'] = config.token
      }

      const res = await fetch(`https://umami.012700.xyz/api/websites/2a796d6c-6499-42d8-8eb4-d9a2930b0ff3/stats?startAt=0000000000&endAt=${now}${keyUrl}`, {
        method: "GET",
        headers: headerList
      })

      if (!res.ok) {
        throw new Error(`HTTP error! status: ${res.status}`)
      }

      return await res.json()
    } catch (error) {
      console.error('Umami Analytics: Failed to fetch data', error)
      throw error
    }
  }

  const insertData = async () => {
    try {
      if (GLOBAL_CONFIG_SITE.pageType === 'post' && config.page_pv) {
        const pagePV = document.getElementById('umamiPV')
        if (pagePV) {
          const data = await getData(true)
          if (data && data.pageviews && typeof data.pageviews.value !== 'undefined') {
            pagePV.textContent = data.pageviews.value
          } else {
            console.warn('Umami Analytics: Invalid page view data received')
          }
        }
      }

      if (config.site_uv || config.site_pv) {
        const data = await getData(false)

        if (config.site_uv) {
          const siteUV = document.getElementById('umami-site-uv')
          if (siteUV && data && data.visitors && typeof data.visitors.value !== 'undefined') {
            siteUV.textContent = data.visitors.value
          } else if (siteUV) {
            console.warn('Umami Analytics: Invalid site UV data received')
          }
        }

        if (config.site_pv) {
          const sitePV = document.getElementById('umami-site-pv')
          if (sitePV && data && data.pageviews && typeof data.pageviews.value !== 'undefined') {
            sitePV.textContent = data.pageviews.value
          } else if (sitePV) {
            console.warn('Umami Analytics: Invalid site PV data received')
          }
        }
      }
    } catch (error) {
      console.error('Umami Analytics: Failed to insert data', error)
    }
  }

  btf.addGlobalFn('pjaxComplete', runTrack, 'umami_analytics_run_track')
  btf.addGlobalFn('pjaxComplete', insertData, 'umami_analytics_insert')


  loadUmamiJS()

  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', insertData)
  } else {
    setTimeout(insertData, 100)
  }
})()</script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.1"></script></div></div></body></html>