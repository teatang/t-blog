<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>RAG（检索增强生成）技术详解 | 1024 维度</title><meta name="author" content="TeaTang"><meta name="copyright" content="TeaTang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="RAG (Retrieval Augmented Generation)，即检索增强生成，是一种结合了检索系统与大型语言模型 (LLM) 的人工智能技术。它旨在提高 LLM 在回答问题、生成文本时的准确性、及时性和事实可靠性，尤其是在处理特定领域知识、最新信息或内部数据时。RAG 通过在生成答案之前，从外部知识库中检索相关信息，并将这些信息作为上下文提供给 LLM，从而“增强”其生成能力。  核">
<meta property="og:type" content="article">
<meta property="og:title" content="RAG（检索增强生成）技术详解">
<meta property="og:url" content="https://blog.tbf1211.xx.kg/82498674876b/index.html">
<meta property="og:site_name" content="1024 维度">
<meta property="og:description" content="RAG (Retrieval Augmented Generation)，即检索增强生成，是一种结合了检索系统与大型语言模型 (LLM) 的人工智能技术。它旨在提高 LLM 在回答问题、生成文本时的准确性、及时性和事实可靠性，尤其是在处理特定领域知识、最新信息或内部数据时。RAG 通过在生成答案之前，从外部知识库中检索相关信息，并将这些信息作为上下文提供给 LLM，从而“增强”其生成能力。  核">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.tbf1211.xx.kg/img/cover/default_cover-22.jpg">
<meta property="article:published_time" content="2025-04-30T22:24:00.000Z">
<meta property="article:modified_time" content="2026-02-02T09:49:14.613Z">
<meta property="article:author" content="TeaTang">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.tbf1211.xx.kg/img/cover/default_cover-22.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RAG（检索增强生成）技术详解",
  "url": "https://blog.tbf1211.xx.kg/82498674876b/",
  "image": "https://blog.tbf1211.xx.kg/img/cover/default_cover-22.jpg",
  "datePublished": "2025-04-30T22:24:00.000Z",
  "dateModified": "2026-02-02T09:49:14.613Z",
  "author": [
    {
      "@type": "Person",
      "name": "TeaTang",
      "url": "https://blog.tbf1211.xx.kg"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon-1.ico"><link rel="canonical" href="https://blog.tbf1211.xx.kg/82498674876b/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><meta name="google-site-verification" content="NdIUXAOVyGnnBhcrip0ksCawbdAzT0hlBZDE9u4jx6k"/><meta name="msvalidate.01" content="567E47D75E8DCF1282B9623AD914701E"/><meta name="baidu-site-verification" content="code-pE5rnuxcfD"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.9/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":true,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":150,"languages":{"author":"作者: TeaTang","link":"链接: ","source":"来源: 1024 维度","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'RAG（检索增强生成）技术详解',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="preconnect" href="https://jsd.012700.xyz"><link href="/self/btf.css" rel="stylesheet"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="1024 维度" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/loading.gif" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">538</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">229</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">84</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 我的轨迹</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/2023/"><i class="fa-fw fa-solid fa-bug"></i><span> 2023</span></a></li><li><a class="site-page child" href="/archives/2024/"><i class="fa-fw fa-solid fa-code"></i><span> 2024</span></a></li><li><a class="site-page child" href="/archives/2025/"><i class="fa-fw fa-solid fa-network-wired"></i><span> 2025</span></a></li><li><a class="site-page child" href="/archives/2026/"><i class="fa-fw fa-solid fa-code-branch"></i><span> 2026</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa-solid fa-calendar-days"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/img/cover/default_cover-22.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">1024 维度</span></a><a class="nav-page-title" href="/"><span class="site-name">RAG（检索增强生成）技术详解</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 我的轨迹</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/2023/"><i class="fa-fw fa-solid fa-bug"></i><span> 2023</span></a></li><li><a class="site-page child" href="/archives/2024/"><i class="fa-fw fa-solid fa-code"></i><span> 2024</span></a></li><li><a class="site-page child" href="/archives/2025/"><i class="fa-fw fa-solid fa-network-wired"></i><span> 2025</span></a></li><li><a class="site-page child" href="/archives/2026/"><i class="fa-fw fa-solid fa-code-branch"></i><span> 2026</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa-solid fa-calendar-days"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">RAG（检索增强生成）技术详解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2025-04-30T22:24:00.000Z" title="发表于 2025-05-01 06:24:00">2025-05-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/LLM/">LLM</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>15分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><blockquote>
<p><strong>RAG (Retrieval Augmented Generation)</strong>，即<strong>检索增强生成</strong>，是一种结合了检索系统与大型语言模型 (LLM) 的人工智能技术。它旨在提高 LLM 在回答问题、生成文本时的准确性、及时性和事实可靠性，尤其是在处理特定领域知识、最新信息或内部数据时。RAG 通过在生成答案之前，从外部知识库中检索相关信息，并将这些信息作为上下文提供给 LLM，从而“增强”其生成能力。</p>
</blockquote>
<div class="note info flat"><p>核心思想：<strong>克服大语言模型在知识时效性、幻觉和领域特异性方面的局限性。它通过动态地从权威数据源检索相关、准确的事实依据，并以此为基础指导 LLM 进行生成，使得 LLM 的输出更加准确、可追溯且富含最新信息。</strong></p>
</div>

<hr>
<h2 id="一、为什么需要-RAG？大语言模型的局限性"><a href="#一、为什么需要-RAG？大语言模型的局限性" class="headerlink" title="一、为什么需要 RAG？大语言模型的局限性"></a>一、为什么需要 RAG？大语言模型的局限性</h2><p>大语言模型（LLMs）在处理自然语言任务方面展现出惊人的能力，但它们也存在一些固有的局限性，RAG 正是为了解决这些问题而生：</p>
<ol>
<li><p><strong>知识时效性与更新难题 (Knowledge Staleness)</strong></p>
<ul>
<li>LLM 的知识来源于其训练数据，这些数据在模型发布后就成为了静态的。它们无法获取最新的事件、实时数据或新形成的知识。</li>
<li>每次需要更新知识时，都可能需要对整个模型进行成本高昂的再训练或微调。</li>
</ul>
</li>
<li><p><strong>幻觉 (Hallucinations) 与事实错误</strong></p>
<ul>
<li>LLM 可能会生成听起来合理但实际上是虚构、不准确或与事实不符的信息，即“幻觉”。这源于其生成模式而非对事实的严格遵守。</li>
<li>在没有明确证据时，LLM 倾向于“编造”答案。</li>
</ul>
</li>
<li><p><strong>知识边界与特定领域限制 (Knowledge Boundary)</strong></p>
<ul>
<li>LLM 无法访问训练数据之外的特定领域知识、企业内部文档或个人私有信息。</li>
<li>对于专业性极强或隐私敏感的场景，LLM 缺乏必要的背景知识。</li>
</ul>
</li>
<li><p><strong>可解释性差 (Lack of Explainability)</strong></p>
<ul>
<li>用户难以追踪 LLM 输出的答案是基于何种“知识”或“事实”得到的，使得模型缺乏透明度和可信度。</li>
</ul>
</li>
<li><p><strong>计算与存储成本高昂</strong></p>
<ul>
<li>训练和部署大型 LLM 需要巨大的计算资源和存储空间。为特定任务微调 LLM 依然成本不菲。</li>
</ul>
</li>
</ol>
<p>RAG 技术通过引入一个外部的、可扩展的知识检索机制，有效地缓解了这些问题。</p>
<h2 id="二、RAG-的工作原理"><a href="#二、RAG-的工作原理" class="headerlink" title="二、RAG 的工作原理"></a>二、RAG 的工作原理</h2><p>RAG 的核心思想是将<strong>检索 (Retrieval)</strong> 和<strong>生成 (Generation)</strong> 两个阶段紧密结合。其基本工作流程如下：</p>
<ol>
<li><strong>用户查询 (User Query)</strong>：用户提出一个问题或请求。</li>
<li><strong>检索阶段 (Retrieval Phase)</strong>：<ul>
<li>系统首先分析用户查询的意图。</li>
<li>然后，利用这个查询作为检索条件，在一个预先构建好的<strong>外部知识库 (External Knowledge Base)</strong> 中搜索并提取出最相关的文档、段落或知识片段。</li>
</ul>
</li>
<li><strong>增强阶段 (Augmentation Phase)</strong>：<ul>
<li>将检索到的相关信息（作为“上下文”）与用户的原始查询拼接起来，形成一个<strong>增强型提示词 (Augmented Prompt)</strong>。</li>
<li>这个增强型提示词包含了 LLM 生成答案所需的所有相关背景知识。</li>
</ul>
</li>
<li><strong>生成阶段 (Generation Phase)</strong>：<ul>
<li>将增强型提示词输入给大型语言模型 (LLM)。</li>
<li>LLM 基于这些新鲜的、精确的上下文信息，以及自身固有的语言理解和生成能力，来产生最终的答案。</li>
</ul>
</li>
</ol>
<p>通过这个过程，LLM 不再仅仅依赖其内部参数中固化的知识，而是能够动态地获取和利用外部世界的最新、最准确的信息。</p>
<div class="mermaid-wrap"><pre class="mermaid-src" data-config="{}" hidden>
    graph TD
    A[用户查询] --&gt; B{检索器 Searcher}
    B --&gt; C[&quot;外部知识库 &lt;br&#x2F;&gt;(文档 &#x2F; 数据库 &#x2F; 向量存储)&quot;]
    C --&gt; D[检索到相关上下文]
    D --&gt; E[&quot;增强型提示词 &lt;br&#x2F;&gt;(用户查询 + 上下文)&quot;]
    E --&gt; F{大语言模型 LLM}
    F --&gt; G[最终答案]
  </pre></div>

<h2 id="三、RAG-系统的核心组件"><a href="#三、RAG-系统的核心组件" class="headerlink" title="三、RAG 系统的核心组件"></a>三、RAG 系统的核心组件</h2><p>一个完整的 RAG 系统通常由以下关键组件构成：</p>
<h3 id="3-1-外部知识源-External-Knowledge-Base"><a href="#3-1-外部知识源-External-Knowledge-Base" class="headerlink" title="3.1 外部知识源 (External Knowledge Base)"></a>3.1 外部知识源 (External Knowledge Base)</h3><p>这是 RAG 机制获取事实依据的源头。它可以是：</p>
<ul>
<li><strong>结构化数据</strong>：如关系型数据库、知识图谱。</li>
<li><strong>半结构化数据</strong>：如维基百科、JSON、XML 文件。</li>
<li><strong>非结构化数据</strong>：如大量文本文件 (PDF, Word, TXT)、网页内容、内部文档库、学术论文等。<br>选择高质量、权威和领域相关的知识源是 RAG 系统成功的基石。</li>
</ul>
<h3 id="3-2-索引模块-Indexing-Module-知识库准备阶段"><a href="#3-2-索引模块-Indexing-Module-知识库准备阶段" class="headerlink" title="3.2 索引模块 (Indexing Module) &#x2F; 知识库准备阶段"></a>3.2 索引模块 (Indexing Module) &#x2F; 知识库准备阶段</h3><p>在进行检索之前，需要对外部知识源进行预处理，使其能够被高效地搜索。</p>
<ol>
<li><p><strong>文档加载器 (Document Loaders)</strong>：</p>
<ul>
<li>作用：从各种来源（文件系统、URL、数据库等）加载原始文档。</li>
<li>示例：<code>PyPDFLoader</code>、<code>UnstructuredHTMLLoader</code>、<code>WebBaseLoader</code> 等。</li>
</ul>
</li>
<li><p><strong>分块策略 (Chunking Strategy)</strong>：</p>
<ul>
<li>作用：将长文档切分成大小适中、语义完整的<strong>文本块 (chunks)</strong>。这是检索性能的关键。</li>
<li>常见策略：<ul>
<li><strong>固定大小分块 (Fixed-size Chunking)</strong>：按字符数或 Token 数切割，可能导致语义割裂。</li>
<li><strong>递归字符分块 (RecursiveCharacterTextSplitter)</strong>：尝试保留语义结构，先按段落、再按句子等方式切割。</li>
<li><strong>语义分块 (Semantic Chunking)</strong>：利用嵌入模型识别语义边界。</li>
<li><strong>基于标题&#x2F;结构分块 (Header&#x2F;Markdown-based Chunking)</strong>：利用文档结构（如Markdown标题）进行分块。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>嵌入模型 (Embedding Model)</strong>：</p>
<ul>
<li>作用：将每个文本块（以及用户查询）转换成一个高维的<strong>向量表示 (Vector Embedding)</strong>。这些向量捕获了文本的语义信息。</li>
<li>示例：<code>OpenAIEmbeddings</code>、<code>SentenceTransformers</code> (如 <code>all-MiniLM-L6-v2</code>)、<code>CohereEmbeddings</code>、或针对特定语言&#x2F;领域训练的私有模型。</li>
</ul>
</li>
<li><p><strong>向量数据库&#x2F;存储 (Vector Database &#x2F; Store)</strong>：</p>
<ul>
<li>作用：存储所有文本块的向量嵌入，以及对应的原始文本块内容。它能够根据查询向量高效地查找相似的文本块。</li>
<li>示例：<ul>
<li><strong>开源本地</strong>：<code>Chroma</code>、<code>Faiss</code> (Facebook AI Similarity Search)。</li>
<li><strong>开源分布式</strong>：<code>Milvus</code>、<code>Qdrant</code>、<code>Weaviate</code>。</li>
<li><strong>商业云服务</strong>：<code>Pinecone</code>、<code>Redis</code> (with RediSearch)。</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> PyPDFLoader</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 文档加载</span></span><br><span class="line"><span class="comment"># 假设你有一个名为 &quot;example.pdf&quot; 的文件</span></span><br><span class="line"><span class="comment"># loader = PyPDFLoader(&quot;example.pdf&quot;)</span></span><br><span class="line"><span class="comment"># docs = loader.load()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者使用一个简单的文本作为示例</span></span><br><span class="line">docs = [&#123;<span class="string">&quot;page_content&quot;</span>: <span class="string">&quot;RAG技术是检索增强生成的缩写，它结合了检索系统和大型语言模型。RAG旨在提高LLM在回答问题时的准确性。&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;page_content&quot;</span>: <span class="string">&quot;LLM常常出现幻觉，即生成不准确或虚构的信息。RAG可以通过提供外部知识来解决这个问题。&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;page_content&quot;</span>: <span class="string">&quot;外部知识库的准备包括文档加载、分块、嵌入和存储到向量数据库。这是一个核心步骤。&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;page_content&quot;</span>: <span class="string">&quot;LangChain提供了丰富的工具来构建RAG应用程序，包括各种加载器、文本分割器和向量存储集成。&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;page_content&quot;</span>: <span class="string">&quot;高效的分块策略对RAG系统的性能至关重要。例如，递归字符分割器可以很好地处理长文档。&quot;</span>&#125;]</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2. 分块</span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">200</span>,    <span class="comment"># 每个文本块的最大字符数</span></span><br><span class="line">    chunk_overlap=<span class="number">20</span>,  <span class="comment"># 文本块之间重叠的字符数</span></span><br><span class="line">    length_function=<span class="built_in">len</span>,</span><br><span class="line">    add_start_index=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">chunks = []</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:</span><br><span class="line">    split_docs = text_splitter.create_documents([doc[<span class="string">&quot;page_content&quot;</span>]])</span><br><span class="line">    <span class="keyword">for</span> s_doc <span class="keyword">in</span> split_docs:</span><br><span class="line">        chunks.append(s_doc)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;原始文档数量: <span class="subst">&#123;<span class="built_in">len</span>(docs)&#125;</span>, 切分后文本块数量: <span class="subst">&#123;<span class="built_in">len</span>(chunks)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># print(f&quot;第一个文本块: &#123;chunks[0].page_content&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 嵌入与向量存储 (需要设置 OPENAI_API_KEY)</span></span><br><span class="line"><span class="comment"># os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;sk-...&quot; </span></span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将文本块及其嵌入存储到 Chroma 向量数据库 (内存版)</span></span><br><span class="line"><span class="comment"># 也可以指定persist_directory保存到磁盘</span></span><br><span class="line">vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;文本块已嵌入并存储到向量数据库。&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="3-3-检索器-Retriever"><a href="#3-3-检索器-Retriever" class="headerlink" title="3.3 检索器 (Retriever)"></a>3.3 检索器 (Retriever)</h3><p>检索器负责根据用户查询，从向量数据库中获取最相关的文本块。</p>
<ol>
<li><p><strong>向量相似度搜索 (Vector Similarity Search)</strong>：</p>
<ul>
<li>机制：将用户查询转换为向量，然后在向量数据库中寻找与查询向量距离最近（即最相似）的文本块向量。</li>
<li>常用距离指标：余弦相似度 (Cosine Similarity)、欧氏距离 (Euclidean Distance)、内积 (Dot Product)。</li>
<li>示例：<code>vectorstore.as_retriever(search_kwargs=&#123;&quot;k&quot;: 3&#125;)</code> 会返回最相似的 k 个文本块。</li>
</ul>
</li>
<li><p><strong>关键词搜索 (Keyword Search)</strong>：</p>
<ul>
<li>机制：基于传统的文本匹配算法，如 BM25、TF-IDF，寻找包含查询关键词的文档。</li>
<li>优点：对于精确匹配的关键词查询非常有效，且不受嵌入模型质量影响。</li>
</ul>
</li>
<li><p><strong>混合搜索 (Hybrid Search)</strong>：</p>
<ul>
<li>机制：结合向量搜索和关键词搜索的优点，通常能获得更鲁棒的检索效果。</li>
<li>例如：先用关键词搜索缩小范围，再对结果进行向量相似度重排。</li>
</ul>
</li>
</ol>
<h3 id="3-4-生成器-Generator-LLM"><a href="#3-4-生成器-Generator-LLM" class="headerlink" title="3.4 生成器 (Generator &#x2F; LLM)"></a>3.4 生成器 (Generator &#x2F; LLM)</h3><p>这是 RAG 系统的最终环节，负责根据增强型提示词生成答案。</p>
<ol>
<li><p><strong>大语言模型 (LLM)</strong>：</p>
<ul>
<li>选择：根据需求选择合适的 LLM 模型，如 <code>GPT-4o</code>、<code>GPT-3.5-turbo</code>、<code>Claude</code>、<code>Llama</code> 等。</li>
<li>能力：模型需要具备强大的文本理解、逻辑推理和文本生成能力。</li>
</ul>
</li>
<li><p><strong>提示词工程 (Prompt Engineering)</strong>：</p>
<ul>
<li>作用：精心设计传递给 LLM 的增强型提示词，以最大化 LLM 利用检索信息的效率和生成高质量答案。</li>
<li>通常结构：<code>[系统指令] + [检索到的上下文] + [用户原始查询] + [输出格式要求]</code></li>
<li>示例：<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">你是一个知识渊博的助手。请根据下方提供的上下文信息，简洁清晰地回答用户的问题。</span><br><span class="line">如果上下文没有提供足够的信息，请说明你无法回答。</span><br><span class="line"></span><br><span class="line">上下文:</span><br><span class="line">&#123;context&#125;</span><br><span class="line"></span><br><span class="line">用户问题:</span><br><span class="line">&#123;question&#125;</span><br><span class="line"></span><br><span class="line">请根据上下文回答。</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables <span class="keyword">import</span> RunnablePassthrough</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 检索器</span></span><br><span class="line">retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">2</span>&#125;) <span class="comment"># 检索最相关的2个文本块</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;检索器已准备就绪。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 生成器 (LLM)</span></span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;gpt-4o&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 提示词工程</span></span><br><span class="line">prompt_template = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;&quot;&quot;你是一个知识渊博的助手。请根据下方提供的上下文信息，简洁清晰地回答用户的问题。</span></span><br><span class="line"><span class="string">    如果上下文没有提供足够的信息，请说明你无法回答，不要编造信息。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    上下文:</span></span><br><span class="line"><span class="string">    &#123;context&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    用户问题:</span></span><br><span class="line"><span class="string">    &#123;question&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    请根据上下文回答：</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建 RAG Chain (使用 LangChain Expression Language)</span></span><br><span class="line">rag_chain = (</span><br><span class="line">    &#123;<span class="string">&quot;context&quot;</span>: retriever, <span class="string">&quot;question&quot;</span>: RunnablePassthrough()&#125; <span class="comment"># 检索上下文，用户问题直接传入</span></span><br><span class="line">    | prompt_template</span><br><span class="line">    | llm</span><br><span class="line">    | StrOutputParser() <span class="comment"># 将LLM的输出解析为字符串</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 用户查询与生成答案</span></span><br><span class="line">user_question = <span class="string">&quot;RAG 技术是什么？它能解决什么问题？&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n用户问题: <span class="subst">&#123;user_question&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n---开始 RAG 检索与生成---&quot;</span>)</span><br><span class="line">response = rag_chain.invoke(user_question)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n---RAG 生成的答案---&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"></span><br><span class="line">user_question_2 = <span class="string">&quot;什么是地球的引力？&quot;</span> <span class="comment"># 故意提问知识库中没有的信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n用户问题: <span class="subst">&#123;user_question_2&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n---开始 RAG 检索与生成---&quot;</span>)</span><br><span class="line">response_2 = rag_chain.invoke(user_question_2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n---RAG 生成的答案---&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response_2)</span><br></pre></td></tr></table></figure>

<h2 id="四、RAG-的类型与演进-Architectures-and-Evolution"><a href="#四、RAG-的类型与演进-Architectures-and-Evolution" class="headerlink" title="四、RAG 的类型与演进 (Architectures and Evolution)"></a>四、RAG 的类型与演进 (Architectures and Evolution)</h2><p>RAG 技术并非一成不变，它在不断演进，以解决基本的 RAG 架构中存在的挑战。</p>
<h3 id="4-1-Naive-RAG-基本-RAG"><a href="#4-1-Naive-RAG-基本-RAG" class="headerlink" title="4.1 Naïve RAG (基本 RAG)"></a>4.1 Naïve RAG (基本 RAG)</h3><ul>
<li>即上述描述的基础工作流：查询 -&gt; 检索 -&gt; 增强 -&gt; 生成。</li>
<li>优点：实现简单，对 LLM 能力要求相对较低。</li>
<li>缺点：检索质量对最终答案影响巨大，可能面临“上下文太长”、“检索噪音”等问题。</li>
</ul>
<h3 id="4-2-Advanced-RAG-高级-RAG-优化的-RAG"><a href="#4-2-Advanced-RAG-高级-RAG-优化的-RAG" class="headerlink" title="4.2 Advanced RAG (高级 RAG &#x2F; 优化的 RAG)"></a>4.2 Advanced RAG (高级 RAG &#x2F; 优化的 RAG)</h3><p>着眼于优化检索和增强的各个环节，以提高 RAG 系统的整体性能。</p>
<ol>
<li><p><strong>查询转换 (Query Transformation)</strong></p>
<ul>
<li><strong>查询重写 (Query Rewriting)</strong>：将原始用户查询进行改写，使其更适合检索。例如，将复杂查询分解为子查询。</li>
<li><strong>查询扩充 (Query Expansion)</strong>：添加同义词、相关概念等，增加检索的召回率。</li>
<li><strong>查询分解 (Query Decomposition)</strong>：将多跳或复杂问题分解为一系列简单的子问题，分别检索。</li>
</ul>
</li>
<li><p><strong>重排 (Re-ranking)</strong></p>
<ul>
<li>在初始检索器返回一组文档后，使用更复杂的模型（通常是小型语言模型或专门训练的排序模型）对这些文档进行二次排序。</li>
<li>目的：过滤掉不相关的文档，提升最相关文档的排名，减少 LLM 上下文中的噪音。</li>
</ul>
</li>
<li><p><strong>上下文压缩 (Contextual Compression)</strong></p>
<ul>
<li>从检索到的长文档中提取最关键的信息片段，再将其传递给 LLM。</li>
<li>方法：使用 LLM 自身进行摘要，或通过关键句提取、信息浓缩等技术。</li>
<li>目的：减少 LLM 输入 Token 数量，降低成本，提高 LLM 对核心信息的关注度。</li>
</ul>
</li>
<li><p><strong>多跳检索 (Multi-hop Retrieval)</strong></p>
<ul>
<li>对于需要多步推理的问题 (例如 “X 的创始人出生在哪里？”)，RAG 系统可能需要进行多次检索。</li>
<li>第一次检索找到 “X 的创始人”，第二次检索再根据创始人的信息找到 “出生地”。</li>
<li>这通常涉及一个代理 (Agent) 决定何时以及如何进行下一次检索。</li>
</ul>
</li>
<li><p><strong>混合检索 (Hybrid Retrieval)</strong></p>
<ul>
<li>结合向量搜索和关键词搜索的优点，在不同场景下各取所长。</li>
</ul>
</li>
<li><p><strong>基于代理的 RAG (Agentic RAG)</strong></p>
<ul>
<li>引入一个 LLM 驱动的代理，让它在检索和生成之间进行动态决策。</li>
<li>代理可以决定：是否需要检索？使用哪个工具（不同的检索器或API）？检索什么？检索结果是否足够？是否需要迭代查询或进行多次推理？</li>
</ul>
</li>
</ol>
<h3 id="4-3-知识图谱与-RAG-结合"><a href="#4-3-知识图谱与-RAG-结合" class="headerlink" title="4.3 知识图谱与 RAG 结合"></a>4.3 知识图谱与 RAG 结合</h3><ul>
<li>将结构化的知识图谱作为 RAG 的外部知识库。</li>
<li>检索时，不仅返回文本片段，还可以返回知识图谱中的实体、关系和路径，为 LLM 提供更精准、结构化的事实上下文。</li>
<li>这种结合能有效提升复杂推理能力和答案的准确性。</li>
</ul>
<h2 id="五、RAG-的优缺点"><a href="#五、RAG-的优缺点" class="headerlink" title="五、RAG 的优缺点"></a>五、RAG 的优缺点</h2><h3 id="5-1-优点："><a href="#5-1-优点：" class="headerlink" title="5.1 优点："></a>5.1 优点：</h3><ol>
<li><strong>提高事实准确性，减少幻觉</strong>：LLM 能够基于实际证据而非记忆或猜测生成答案。</li>
<li><strong>处理新知识和特定领域知识</strong>：轻松更新外部知识库即可使 LLM 掌握最新信息，无需重新训练。</li>
<li><strong>知识来源可追溯，提高可解释性</strong>：可以展示检索到的原始文档或片段，增强用户对答案的信任。</li>
<li><strong>降低模型训练&#x2F;微调成本</strong>：无需对 LLM 进行大规模微调即可适应新领域或新数据。</li>
<li><strong>实现数据隐私和安全</strong>：敏感或私有数据可以存储在受控的知识库中，并通过权限管理访问。</li>
</ol>
<h3 id="5-2-缺点："><a href="#5-2-缺点：" class="headerlink" title="5.2 缺点："></a>5.2 缺点：</h3><ol>
<li><strong>检索质量直接影响生成质量</strong>：如果检索到的信息不相关、不准确或包含噪音，LLM 可能会生成错误答案（“垃圾进，垃圾出”）。</li>
<li><strong>知识库的构建和维护成本</strong>：需要投入资源去收集、清洗、分块和嵌入文档，并持续更新知识库。</li>
<li><strong>复杂查询处理仍有挑战</strong>：对于需要多跳推理、聚合或深入分析的复杂问题，RAG 系统的设计更具挑战性。</li>
<li><strong>上下文窗口限制</strong>：即使有 RAG，检索到的上下文仍可能过长，超出 LLM 的输入 Token 限制。需要优化分块和压缩策略。</li>
<li><strong>效率&#x2F;延迟问题</strong>：引入检索环节会增加生成答案的时间，影响实时性应用。</li>
</ol>
<h2 id="六、RAG-与微调-Fine-tuning-的比较与结合"><a href="#六、RAG-与微调-Fine-tuning-的比较与结合" class="headerlink" title="六、RAG 与微调 (Fine-tuning) 的比较与结合"></a>六、RAG 与微调 (Fine-tuning) 的比较与结合</h2><p>RAG 和微调（Fine-tuning）是增强 LLM 性能的两种主要方法，它们解决的问题和作用机制不同，但可以互补。</p>
<h3 id="6-1-微调-Fine-tuning"><a href="#6-1-微调-Fine-tuning" class="headerlink" title="6.1 微调 (Fine-tuning)"></a>6.1 微调 (Fine-tuning)</h3><ul>
<li><strong>作用</strong>：通过在特定任务或特定领域数据上训练 LLM，改变模型的内部参数，使其更好地适应某个风格、任务或数据分布。它更新的是模型“通用知识”的权重分布和行为模式。</li>
<li><strong>适用场景</strong>：<ul>
<li>让模型学习新的<strong>格式</strong>或<strong>输出风格</strong>。</li>
<li>提高模型对特定类型指令的<strong>遵循能力</strong>。</li>
<li>调整模型生成内容的<strong>语气、创造性</strong>。</li>
<li>对模型进行<strong>能力引导</strong>（如编程、摘要）。</li>
</ul>
</li>
<li><strong>成本</strong>：通常需要大量的训练数据和较高的计算资源。</li>
</ul>
<h3 id="6-2-RAG-检索增强生成"><a href="#6-2-RAG-检索增强生成" class="headerlink" title="6.2 RAG (检索增强生成)"></a>6.2 RAG (检索增强生成)</h3><ul>
<li><strong>作用</strong>：为 LLM 提供<strong>最新、外部或特定领域的事实性知识</strong>作为上下文，而不改变模型本身的参数。它更新的是模型“事实知识”的来源。</li>
<li><strong>适用场景</strong>：<ul>
<li>需要回答最新的事实信息。</li>
<li>需要访问私有、企业内部或特定领域的知识。</li>
<li>要求答案可追溯来源。</li>
<li>避免幻觉，确保事实准确性。</li>
</ul>
</li>
<li><strong>成本</strong>：主要在于构建和维护知识库及检索系统。</li>
</ul>
<h3 id="6-3-结合使用"><a href="#6-3-结合使用" class="headerlink" title="6.3 结合使用"></a>6.3 结合使用</h3><p>RAG 和微调不是互斥的，而是<strong>高度互补</strong>的。最佳实践通常是将两者结合：</p>
<ol>
<li><strong>微调 LLM</strong>：使其更好地理解用户的意图、处理长上下文、以及更有效地利用检索到的信息。例如，可以微调 LLM，使其在上下文不确凿时更倾向于表达“我不知道”。</li>
<li><strong>RAG 增强</strong>：提供最新的、特定领域的、可追溯的事实性内容。</li>
</ol>
<p>通过结合，可以获得一个既能遵循指令和风格（微调），又能提供最新、准确事实（RAG）的强大系统。</p>
<h2 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a>七、总结</h2><p>RAG 技术已经成为大语言模型时代解决知识时效性、幻觉和领域特异性难题的强大范式。它通过动态地从外部知识库中检索信息来增强 LLM 的生成能力，使得 LLM 的输出更加准确、可信和可追溯。</p>
<p>从朴素 RAG 到高级 RAG，再到与知识图谱和LLM微调的深度融合，RAG 的发展展现出其巨大的潜力和灵活性。随着 AI 技术的不断进步，我们可以预见 RAG 将在智能问答、内容创作、决策支持、教育等多个领域发挥越来越核心的作用，成为构建可靠、高效、智能 AI 应用的关键技术。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.tbf1211.xx.kg">TeaTang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.tbf1211.xx.kg/82498674876b/">https://blog.tbf1211.xx.kg/82498674876b/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.tbf1211.xx.kg" target="_blank">1024 维度</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/img/cover/default_cover-22.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/0998285408b6/" title="Agentic RAG (智能体RAG) 详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-10.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Agentic RAG (智能体RAG) 详解</div></div><div class="info-2"><div class="info-item-1"> Agentic RAG (智能体检索增强生成) 是在传统 RAG (Retrieval Augmented Generation) 范式基础上的一次重大演进。它将大型语言模型 (LLM) 的推理能力与AI 智能体 (Agent) 的规划、工具使用和自我反思能力相结合，以更智能、更动态的方式执行信息检索和内容生成。传统 RAG 主要关注在检索到相关信息后直接由 LLM 进行生成，而 Agentic RAG 则通过引入智能体层，使得检索过程、生成过程甚至整个解决问题的流程都更加具有策略性、可控性和适应性。   一、背景：从 RAG 到 Agentic RAG1.1 传统 RAG 的局限性Retrieval Augmented Generation (RAG) 是一种将 LLM 的生成能力与外部知识检索系统相结合的技术。当用户提出问题时，RAG 系统会首先从一个大型的、通常是向量化的知识库中检索出最相关的文档片段，然后将这些片段与用户问题一并通过 Prompt 喂给 LLM，让 LLM 基于这些检索到的信息生成回答。 传统 RAG 带来了显著的性能提升，特别是在处理事实性问题和减少幻...</div></div></div></a><a class="pagination-related" href="/66853900b34d/" title="提示词模板详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-18.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">提示词模板详解</div></div><div class="info-2"><div class="info-item-1"> 提示词模板 (Prompt Template) 是一种精心设计的结构化文本框架，旨在将人类意图转化为大型语言模型 (LLM) 最能理解和高效执行的指令集。它通过明确角色、设定目标、注入约束、提供上下文和示例，系统性地优化 AI 交互，确保输出的一致性、准确性和高质量。  核心思想：将编程思维应用于提示工程，用模板封装智慧，让 AI 成为可预测、高效率的智能伙伴。 优秀的提示词模板是 AI 时代“代码即文档，文档即代码”理念在人机协作层面的体现。    一、优秀提示词模板的核心特征一个卓越的提示词模板，如同高质量的软件架构，具备以下关键特征：  明确的角色与目标 (Clear Role &amp; Objective)：AI 被赋予清晰的身份（如“首席软件架构师”、“精英提示工程师”）和单义的任务目标。 严谨的硬约束 (Rigorous Hard Constraints)：使用强制性语言（“必须”、“不得”、“禁止”）定义输出格式、内容、行为边界，确保可判定性。 结构化输出规范 (Structured Output Specification)：通过 Markdown、JSON、...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/0998285408b6/" title="Agentic RAG (智能体RAG) 详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-10.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-02</div><div class="info-item-2">Agentic RAG (智能体RAG) 详解</div></div><div class="info-2"><div class="info-item-1"> Agentic RAG (智能体检索增强生成) 是在传统 RAG (Retrieval Augmented Generation) 范式基础上的一次重大演进。它将大型语言模型 (LLM) 的推理能力与AI 智能体 (Agent) 的规划、工具使用和自我反思能力相结合，以更智能、更动态的方式执行信息检索和内容生成。传统 RAG 主要关注在检索到相关信息后直接由 LLM 进行生成，而 Agentic RAG 则通过引入智能体层，使得检索过程、生成过程甚至整个解决问题的流程都更加具有策略性、可控性和适应性。   一、背景：从 RAG 到 Agentic RAG1.1 传统 RAG 的局限性Retrieval Augmented Generation (RAG) 是一种将 LLM 的生成能力与外部知识检索系统相结合的技术。当用户提出问题时，RAG 系统会首先从一个大型的、通常是向量化的知识库中检索出最相关的文档片段，然后将这些片段与用户问题一并通过 Prompt 喂给 LLM，让 LLM 基于这些检索到的信息生成回答。 传统 RAG 带来了显著的性能提升，特别是在处理事实性问题和减少幻...</div></div></div></a><a class="pagination-related" href="/bfcc84247c6a/" title="智能体 (Agent) 详解：深入 LangChain 开发实践"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-31.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-11</div><div class="info-item-2">智能体 (Agent) 详解：深入 LangChain 开发实践</div></div><div class="info-2"><div class="info-item-1"> 智能体 (Agent) 是人工智能领域中的一个核心概念，特指能够感知环境、进行决策并采取行动以实现特定目标或利益的实体。在当前的技术浪潮中，特别是随着大语言模型 (LLM) 的突破，智能体这一概念被赋予了新的活力和强大的实现路径。基于 LLM 的智能体能够理解复杂的指令、规划任务、执行外部工具并进行自我反思，从而展现出接近自主解决问题的能力。  核心思想：智能体是一个自主运行的系统，它通过感知 (Perception)、思考 (Thought&#x2F;Planning)、行动 (Action) 和反馈 (Feedback&#x2F;Memory) 的闭环循环，在动态环境中追求并实现预设目标。Python 中的 LangChain 库提供了一套强大的工具和框架，用于快速构建和部署基于 LLM 的智能体，使其能够与各种外部资源和工具交互。   一、智能体的基本概念1.1 什么是智能体？在广义的人工智能领域，智能体是一个能够自主地运作以影响其所处环境的实体。其核心能力体现在以下循环：  感知 (Perception)：接收来自环境的信息（传感器输入，如文本、图像、数据）。 思考&#...</div></div></div></a><a class="pagination-related" href="/2ef7cb8bd831/" title="LangChain Text Splitters 详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-10.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-03</div><div class="info-item-2">LangChain Text Splitters 详解</div></div><div class="info-2"><div class="info-item-1"> LangChain Text Splitters 是 LangChain 框架中的一个核心模块，用于将长文档或文本智能地分割成更小、更易于管理和处理的块 (chunks)。这个过程对于大语言模型 (LLM) 相关的应用至关重要，特别是当处理的文本长度超出 LLM 的上下文窗口限制时。  核心思想：将长文本分割成大小适中、语义连贯且包含一定重叠的块，以便 LLM 能够有效处理这些块，同时保持上下文完整性。LangChain 提供多种具有不同策略的 Text Splitters，以适应不同的文本结构和应用场景。   一、为什么需要 Text Splitters？在构建基于 LLM 的应用程序（尤其是问答 RAG (Retrieval Augmented Generation) 系统、文档摘要、聊天机器人等）时，我们经常遇到以下问题：  LLM 上下文窗口限制 (Context Window Limit)：大语言模型（如 GPT-3.5, GPT-4, Llama）通常有一个固定的最大输入长度。如果输入文本太长，会超出这个限制，导致模型无法处理。 性能和成本：即使模型支持很长的上下文...</div></div></div></a><a class="pagination-related" href="/30bb7c0cff3b/" title="Transformer 模型深度详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-04.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-14</div><div class="info-item-2">Transformer 模型深度详解</div></div><div class="info-2"><div class="info-item-1"> Transformer 模型由 Google Brain 团队在 2017 年的论文 “Attention Is All You Need” 中提出。它彻底改变了自然语言处理 (NLP) 领域，并成为了当前大语言模型 (LLM) 的基石。Transformer 模型以其强大的并行计算能力和卓越的长距离依赖建模能力，取代了传统的循环神经网络 (RNN) 和长短期记忆网络 (LSTM) 结构，成为了序列建模任务的主流架构。  核心思想：Transformer 放弃了传统的循环和卷积结构，完全依赖于注意力机制 (Attention Mechanism)来捕捉输入序列中的依赖关系。通过精心设计的自注意力 (Self-Attention) 机制，模型能够同时关注输入序列中的所有位置，从而实现高效的并行计算和对任意距离依赖的有效建模。   一、为什么需要 Transformer？在 Transformer 出现之前，RNN 及其变体 (如 LSTM 和 GRU) 是序列建模任务的主流。然而，它们存在一些固有的局限性：  顺序依赖：RNN 必须顺序地处理序列中的每个元素，后一个元素的计算依赖...</div></div></div></a><a class="pagination-related" href="/4b8301cdd035/" title="向量数据库 (Vector Database) 详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-03.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-03</div><div class="info-item-2">向量数据库 (Vector Database) 详解</div></div><div class="info-2"><div class="info-item-1"> 向量数据库 (Vector Database &#x2F; Vector Store) 是一种专门设计用于高效存储、管理和检索向量嵌入 (Vector Embeddings) 的数据库。这些向量嵌入是高维的数值表示，由机器学习模型生成，能够捕捉文本、图像、音频或其他复杂数据的语义信息。向量数据库的核心能力在于通过计算向量之间的相似度 (Similarity) 来进行快速搜索，而非传统的精确匹配。  核心思想：将非结构化数据转化为机器可理解的低维或高维向量表示（嵌入），并在此基础上实现基于语义相似度的快速检索。它解决了传统数据库在处理语义搜索、推荐系统、多模态数据匹配等场景下的局限性。   一、什么是向量 (Vector)？在深入了解向量数据库之前，我们必须先理解“向量”这个核心概念。 1.1 向量的数学定义在数学和物理中，向量 (Vector) 是一个具有大小 (Magnitude) 和方向 (Direction) 的量。它可以被表示为一个有序的数值列表。  一维向量：一个标量，如 [5]。 二维向量：表示平面上的一个点或从原点指向该点的箭头，如 [x, y]。例如，[3, 4...</div></div></div></a><a class="pagination-related" href="/9a400d225757/" title="对话模型与非对话模型详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-08.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-26</div><div class="info-item-2">对话模型与非对话模型详解</div></div><div class="info-2"><div class="info-item-1"> 在大型语言模型 (LLM) 的领域中，”对话模型” (Chat Models) 和 “非对话模型” (或称为 “文本模型” Text Models) 是两种基本但又有所区别的模型范式，它们在设计、训练数据、输入&#x2F;输出格式以及最佳应用场景上存在差异。理解这两种模型的区别是有效利用 LLM 进行开发的关键。  核心思想：对话模型优化用于多轮、上下文感知的交互，通过消息列表进行输入输出；非对话模型则擅长单次、直接的文本指令处理，通过字符串进行输入输出。    一、非对话模型 (Text Models &#x2F; LLMs)非对话模型是早期和传统的大型语言模型形式，它们通常设计为接收一个单一的字符串作为输入（通常称为 “prompt”），并生成一个单一的字符串作为输出。虽然这些模型也能在一定程度上处理对话，但通常需要通过在单次 Prompt 中手动构建对话历史来模拟。 1.1 特点 字符串输入&#x2F;输出：输入是一个字符串，输出也是一个字符串。 输入示例：&quot;把以下文本总结一下：[文本内容]&quot; 输出示例：&quot;这是一段总结后的文本。&quot; ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/loading.gif" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">TeaTang</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">538</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">229</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">84</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/teatang"><i class="fab fa-github"></i><span>GitHub主页</span></a><div class="card-info-social-icons"><a class="social-icon" href="mailto:tea.tang1211@gmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">网站更多功能即将上线，敬请期待！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-RAG%EF%BC%9F%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-text">一、为什么需要 RAG？大语言模型的局限性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81RAG-%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-text">二、RAG 的工作原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81RAG-%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="toc-text">三、RAG 系统的核心组件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86%E6%BA%90-External-Knowledge-Base"><span class="toc-text">3.1 外部知识源 (External Knowledge Base)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%B4%A2%E5%BC%95%E6%A8%A1%E5%9D%97-Indexing-Module-%E7%9F%A5%E8%AF%86%E5%BA%93%E5%87%86%E5%A4%87%E9%98%B6%E6%AE%B5"><span class="toc-text">3.2 索引模块 (Indexing Module) &#x2F; 知识库准备阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%A3%80%E7%B4%A2%E5%99%A8-Retriever"><span class="toc-text">3.3 检索器 (Retriever)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E7%94%9F%E6%88%90%E5%99%A8-Generator-LLM"><span class="toc-text">3.4 生成器 (Generator &#x2F; LLM)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81RAG-%E7%9A%84%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%BC%94%E8%BF%9B-Architectures-and-Evolution"><span class="toc-text">四、RAG 的类型与演进 (Architectures and Evolution)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Naive-RAG-%E5%9F%BA%E6%9C%AC-RAG"><span class="toc-text">4.1 Naïve RAG (基本 RAG)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Advanced-RAG-%E9%AB%98%E7%BA%A7-RAG-%E4%BC%98%E5%8C%96%E7%9A%84-RAG"><span class="toc-text">4.2 Advanced RAG (高级 RAG &#x2F; 优化的 RAG)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E4%B8%8E-RAG-%E7%BB%93%E5%90%88"><span class="toc-text">4.3 知识图谱与 RAG 结合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81RAG-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-text">五、RAG 的优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E4%BC%98%E7%82%B9%EF%BC%9A"><span class="toc-text">5.1 优点：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E7%BC%BA%E7%82%B9%EF%BC%9A"><span class="toc-text">5.2 缺点：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81RAG-%E4%B8%8E%E5%BE%AE%E8%B0%83-Fine-tuning-%E7%9A%84%E6%AF%94%E8%BE%83%E4%B8%8E%E7%BB%93%E5%90%88"><span class="toc-text">六、RAG 与微调 (Fine-tuning) 的比较与结合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E5%BE%AE%E8%B0%83-Fine-tuning"><span class="toc-text">6.1 微调 (Fine-tuning)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-RAG-%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90"><span class="toc-text">6.2 RAG (检索增强生成)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8"><span class="toc-text">6.3 结合使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%80%BB%E7%BB%93"><span class="toc-text">七、总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/f81355a662b8/" title="ECMAScript ShadowRealm 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-28.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ECMAScript ShadowRealm 详解"/></a><div class="content"><a class="title" href="/f81355a662b8/" title="ECMAScript ShadowRealm 详解">ECMAScript ShadowRealm 详解</a><time datetime="2026-02-01T22:24:00.000Z" title="发表于 2026-02-02 06:24:00">2026-02-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/8fc7e3e72510/" title="前端渲染模式：CSR, SSR, SSG, ISR, DPR 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-21.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="前端渲染模式：CSR, SSR, SSG, ISR, DPR 详解"/></a><div class="content"><a class="title" href="/8fc7e3e72510/" title="前端渲染模式：CSR, SSR, SSG, ISR, DPR 详解">前端渲染模式：CSR, SSR, SSG, ISR, DPR 详解</a><time datetime="2026-01-27T22:24:00.000Z" title="发表于 2026-01-28 06:24:00">2026-01-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/5341a0037256/" title="CSS-in-JS 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-14.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CSS-in-JS 详解"/></a><div class="content"><a class="title" href="/5341a0037256/" title="CSS-in-JS 详解">CSS-in-JS 详解</a><time datetime="2026-01-25T22:24:00.000Z" title="发表于 2026-01-26 06:24:00">2026-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/0b52cb819619/" title="Git 核心对象：Commit, Tree, Blob 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-17.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Git 核心对象：Commit, Tree, Blob 详解"/></a><div class="content"><a class="title" href="/0b52cb819619/" title="Git 核心对象：Commit, Tree, Blob 详解">Git 核心对象：Commit, Tree, Blob 详解</a><time datetime="2026-01-21T22:24:00.000Z" title="发表于 2026-01-22 06:24:00">2026-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/1d2a942bda1e/" title="Terraform 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-31.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Terraform 详解"/></a><div class="content"><a class="title" href="/1d2a942bda1e/" title="Terraform 详解">Terraform 详解</a><time datetime="2026-01-19T22:24:00.000Z" title="发表于 2026-01-20 06:24:00">2026-01-20</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/cover/default_cover-22.jpg);"><div class="footer-flex"><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">我的轨迹</div><div class="footer-flex-content"><a href="/archives/2023/" target="_blank" title="🆕 2023">🆕 2023</a><a href="/archives/2024/" target="_blank" title="🆒 2024">🆒 2024</a><a href="/archives/2025/" target="_blank" title="👨‍👩‍👦 2025">👨‍👩‍👦 2025</a><a href="/archives/2026/" target="_blank" title="🆙 2026">🆙 2026</a></div></div></div><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">维度</div><div class="footer-flex-content"><a href="/categories/" target="_blank" title="📁 分类">📁 分类</a><a href="/tags/" target="_blank" title="🔖 标签">🔖 标签</a><a href="/categories/" target="_blank" title="📽️ 时间线">📽️ 时间线</a></div></div></div><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">其他</div><div class="footer-flex-content"><a href="/shuoshuo" target="_blank" title="💬 说说">💬 说说</a></div></div></div></div><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2023 - 2026 By TeaTang</span><span class="framework-info"><span class="footer-separator">|</span><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.9/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const parseViewBox = viewBox => {
    if (!viewBox) return null
    const parts = viewBox.trim().split(/[\s,]+/).map(n => Number(n))
    if (parts.length !== 4 || parts.some(n => Number.isNaN(n))) return null
    return parts
  }

  const getSvgViewBox = svg => {
    const attr = parseViewBox(svg.getAttribute('viewBox'))
    if (attr) return attr

    // Fallback: use bbox to build a viewBox
    try {
      const bbox = svg.getBBox()
      if (bbox && bbox.width && bbox.height) return [bbox.x, bbox.y, bbox.width, bbox.height]
    } catch (e) {
      // getBBox may fail on some edge cases; ignore
    }

    const w = Number(svg.getAttribute('width')) || 0
    const h = Number(svg.getAttribute('height')) || 0
    if (w > 0 && h > 0) return [0, 0, w, h]
    return [0, 0, 100, 100]
  }

  const setSvgViewBox = (svg, vb) => {
    svg.setAttribute('viewBox', `${vb[0]} ${vb[1]} ${vb[2]} ${vb[3]}`)
  }

  const clamp = (v, min, max) => Math.max(min, Math.min(max, v))

  const openSvgInNewTab = ({ source, initViewBox }) => {
    const getClonedSvg = () => {
      if (typeof source === 'string') {
        const template = document.createElement('template')
        template.innerHTML = source.trim()
        const svg = template.content.querySelector('svg')
        return svg ? svg.cloneNode(true) : null
      }
      if (source && typeof source.cloneNode === 'function') {
        return source.cloneNode(true)
      }
      return null
    }

    const clone = getClonedSvg()
    if (!clone) return
    if (initViewBox && initViewBox.length === 4) {
      clone.setAttribute('viewBox', initViewBox.join(' '))
    }
    if (!clone.getAttribute('xmlns')) clone.setAttribute('xmlns', 'http://www.w3.org/2000/svg')
    if (!clone.getAttribute('xmlns:xlink') && clone.outerHTML.includes('xlink:')) {
      clone.setAttribute('xmlns:xlink', 'http://www.w3.org/1999/xlink')
    }
    // inject background to match current theme
    const isDark = document.documentElement.getAttribute('data-theme') === 'dark'
    const bg = getComputedStyle(document.body).backgroundColor || (isDark ? '#1e1e1e' : '#ffffff')
    if (!clone.style.background) clone.style.background = bg

    const serializer = new XMLSerializer()
    const svgSource = serializer.serializeToString(clone)
    const htmlSource = `<!doctype html><html><head><meta charset="utf-8" />
      <style>
        html, body { width: 100%; height: 100%; margin: 0; display: flex; align-items: center; justify-content: center; background: ${bg}; }
        svg { max-width: 100%; max-height: 100%; height: auto; width: auto; }
      </style>
      </head><body>${svgSource}</body></html>`
    const blob = new Blob([htmlSource], { type: 'text/html;charset=utf-8' })
    const url = URL.createObjectURL(blob)
    window.open(url, '_blank', 'noopener')
    setTimeout(() => URL.revokeObjectURL(url), 30000)
  }

  const attachMermaidViewerButton = wrap => {
    let btn = wrap.querySelector('.mermaid-open-btn')
    if (!btn) {
      btn = document.createElement('button')
      btn.type = 'button'
      btn.className = 'mermaid-open-btn'
      wrap.appendChild(btn)
    }

    btn.innerHTML = '<i class="fa fa-search fa-fw" aria-hidden="true"></i>'

    if (!btn.__mermaidViewerBound) {
      btn.addEventListener('click', e => {
        e.preventDefault()
        e.stopPropagation()
        const svg = wrap.__mermaidOriginalSvg || wrap.querySelector('svg')
        if (!svg) return
        const initViewBox = wrap.__mermaidInitViewBox
        if (typeof svg === 'string') {
          openSvgInNewTab({ source: svg, initViewBox })
          return
        }
        openSvgInNewTab({ source: svg, initViewBox })
      })
      btn.__mermaidViewerBound = true
    }
  }

  // Zoom around a point (px, py) in the SVG viewport (in viewBox coordinates)
  const zoomAtPoint = (vb, factor, px, py) => {
    const w = vb[2] * factor
    const h = vb[3] * factor
    const nx = px - (px - vb[0]) * factor
    const ny = py - (py - vb[1]) * factor
    return [nx, ny, w, h]
  }

  const initMermaidGestures = wrap => {
    const svg = wrap.querySelector('svg')
    if (!svg) return

    // Ensure viewBox exists so gestures always work
    const initVb = getSvgViewBox(svg)
    wrap.__mermaidInitViewBox = initVb
    wrap.__mermaidCurViewBox = initVb.slice()
    setSvgViewBox(svg, initVb)

    // Avoid binding multiple times on themeChange/pjax
    if (wrap.__mermaidGestureBound) return
    wrap.__mermaidGestureBound = true

    // Helper: map client (viewport) coordinate -> viewBox coordinate
    const clientToViewBox = (clientX, clientY) => {
      const rect = svg.getBoundingClientRect()
      const vb = wrap.__mermaidCurViewBox || getSvgViewBox(svg)
      const x = vb[0] + (clientX - rect.left) * (vb[2] / rect.width)
      const y = vb[1] + (clientY - rect.top) * (vb[3] / rect.height)
      return { x, y, rect, vb }
    }

    const state = {
      pointers: new Map(),
      startVb: null,
      startDist: 0,
      startCenter: null
    }

    const clampVb = vb => {
      const init = wrap.__mermaidInitViewBox || vb
      const minW = init[2] * 0.1
      const maxW = init[2] * 10
      const minH = init[3] * 0.1
      const maxH = init[3] * 10
      vb[2] = clamp(vb[2], minW, maxW)
      vb[3] = clamp(vb[3], minH, maxH)
      return vb
    }

    const setCurVb = vb => {
      vb = clampVb(vb)
      wrap.__mermaidCurViewBox = vb
      setSvgViewBox(svg, vb)
    }

    const onPointerDown = e => {
      // Allow only primary button for mouse
      if (e.pointerType === 'mouse' && e.button !== 0) return
      svg.setPointerCapture(e.pointerId)
      state.pointers.set(e.pointerId, { x: e.clientX, y: e.clientY })

      if (state.pointers.size === 1) {
        state.startVb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
      } else if (state.pointers.size === 2) {
        const pts = [...state.pointers.values()]
        const dx = pts[0].x - pts[1].x
        const dy = pts[0].y - pts[1].y
        state.startDist = Math.hypot(dx, dy)
        state.startVb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
        state.startCenter = { x: (pts[0].x + pts[1].x) / 2, y: (pts[0].y + pts[1].y) / 2 }
      }
    }

    const onPointerMove = e => {
      if (!state.pointers.has(e.pointerId)) return
      state.pointers.set(e.pointerId, { x: e.clientX, y: e.clientY })

      // Pan with 1 pointer
      if (state.pointers.size === 1 && state.startVb) {
        const p = [...state.pointers.values()][0]
        const prev = { x: e.clientX - e.movementX, y: e.clientY - e.movementY }
        // movementX/Y unreliable on touch, compute from stored last position
        const last = wrap.__mermaidLastSinglePointer || p
        const dxClient = p.x - last.x
        const dyClient = p.y - last.y
        wrap.__mermaidLastSinglePointer = p

        const { rect } = clientToViewBox(p.x, p.y)
        const vb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
        const dx = dxClient * (vb[2] / rect.width)
        const dy = dyClient * (vb[3] / rect.height)
        setCurVb([vb[0] - dx, vb[1] - dy, vb[2], vb[3]])
        return
      }

      // Pinch zoom with 2 pointers
      if (state.pointers.size === 2 && state.startVb && state.startDist > 0) {
        const pts = [...state.pointers.values()]
        const dx = pts[0].x - pts[1].x
        const dy = pts[0].y - pts[1].y
        const dist = Math.hypot(dx, dy)
        if (!dist) return
        const factor = state.startDist / dist // dist bigger => zoom in (viewBox smaller)

        const cx = (pts[0].x + pts[1].x) / 2
        const cy = (pts[0].y + pts[1].y) / 2
        const centerClient = { x: cx, y: cy }

        const pxy = clientToViewBox(centerClient.x, centerClient.y)
        const cpx = pxy.x
        const cpy = pxy.y

        const vb = zoomAtPoint(state.startVb, factor, cpx, cpy)
        setCurVb(vb)
      }
    }

    const onPointerUpOrCancel = e => {
      state.pointers.delete(e.pointerId)
      if (state.pointers.size === 0) {
        state.startVb = null
        state.startDist = 0
        state.startCenter = null
        wrap.__mermaidLastSinglePointer = null
      } else if (state.pointers.size === 1) {
        // reset single pointer baseline to avoid jump
        wrap.__mermaidLastSinglePointer = [...state.pointers.values()][0]
      }
    }

    // Wheel zoom (mouse/trackpad)
    const onWheel = e => {
      // ctrlKey on mac trackpad pinch; we treat both as zoom
      e.preventDefault()
      const delta = e.deltaY
      const zoomFactor = delta > 0 ? 1.1 : 0.9
      const { x, y } = clientToViewBox(e.clientX, e.clientY)
      const vb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
      setCurVb(zoomAtPoint(vb, zoomFactor, x, y))
    }

    const onDblClick = () => {
      const init = wrap.__mermaidInitViewBox
      if (!init) return
      wrap.__mermaidCurViewBox = init.slice()
      setSvgViewBox(svg, init)
    }

    svg.addEventListener('pointerdown', onPointerDown)
    svg.addEventListener('pointermove', onPointerMove)
    svg.addEventListener('pointerup', onPointerUpOrCancel)
    svg.addEventListener('pointercancel', onPointerUpOrCancel)
    svg.addEventListener('wheel', onWheel, { passive: false })
    svg.addEventListener('dblclick', onDblClick)
  }

  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild

      // Clear old render (themeChange/pjax will rerun)
      const oldSvg = item.querySelector('svg')
      if (oldSvg) oldSvg.remove()
      item.__mermaidGestureBound = false

      const config = mermaidSrc.dataset.config ? JSON.parse(mermaidSrc.dataset.config) : {}
      if (!config.theme) {
        config.theme = theme
      }
      const mermaidThemeConfig = `%%{init: ${JSON.stringify(config)}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
        if (false) initMermaidGestures(item)
        item.__mermaidOriginalSvg = svg
        if (true) attachMermaidViewerButton(item)
      }


      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const applyThemeDefaultsConfig = theme => {
    if (theme === 'dark-mode') {
      Chart.defaults.color = "rgba(255, 255, 255, 0.8)"
      Chart.defaults.borderColor = "rgba(255, 255, 255, 0.2)"
      Chart.defaults.scale.ticks.backdropColor = "transparent"
    } else {
      Chart.defaults.color = "rgba(0, 0, 0, 0.8)"
      Chart.defaults.borderColor = "rgba(0, 0, 0, 0.1)"
      Chart.defaults.scale.ticks.backdropColor = "transparent"
    }
  }

  // Recursively traverse the config object and automatically apply theme-specific color schemes
  const applyThemeConfig = (obj, theme) => {
    if (typeof obj !== 'object' || obj === null) return

    Object.keys(obj).forEach(key => {
      const value = obj[key]
      // If the property is an object and has theme-specific options, apply them
      if (typeof value === 'object' && value !== null) {
        if (value[theme]) {
          obj[key] = value[theme] // Apply the value for the current theme
        } else {
          // Recursively process child objects
          applyThemeConfig(value, theme)
        }
      }
    })
  }

  const runChartJS = ele => {
    window.loadChartJS = true

    Array.from(ele).forEach((item, index) => {
      const chartSrc = item.firstElementChild
      const chartID = item.getAttribute('data-chartjs-id') || ('chartjs-' + index) // Use custom ID or default ID
      const width = item.getAttribute('data-width')
      const existingCanvas = document.getElementById(chartID)

      // If a canvas already exists, remove it to avoid rendering duplicates
      if (existingCanvas) {
          existingCanvas.parentNode.remove()
      }

      const chartDefinition = chartSrc.textContent
      const canvas = document.createElement('canvas')
      canvas.id = chartID

      const div = document.createElement('div')
      div.className = 'chartjs-wrap'

      if (width) {
        div.style.width = width
      }

      div.appendChild(canvas)
      chartSrc.insertAdjacentElement('afterend', div)

      const ctx = document.getElementById(chartID).getContext('2d')

      const config = JSON.parse(chartDefinition)

      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark-mode' : 'light-mode'

      // Set default styles (initial setup)
      applyThemeDefaultsConfig(theme)

      // Automatically traverse the config and apply dual-mode color schemes
      applyThemeConfig(config, theme)

      new Chart(ctx, config)
    })
  }

  const loadChartJS = () => {
    const chartJSEle = document.querySelectorAll('#article-container .chartjs-container')
    if (chartJSEle.length === 0) return

    window.loadChartJS ? runChartJS(chartJSEle) : btf.getScript('https://cdn.jsdelivr.net/npm/chart.js@4.5.1/dist/chart.umd.min.js').then(() => runChartJS(chartJSEle))
  }

  // Listen for theme change events
  btf.addGlobalFn('themeChange', loadChartJS, 'chartjs')
  btf.addGlobalFn('encrypt', loadChartJS, 'chartjs')

  window.pjax ? loadChartJS() : document.addEventListener('DOMContentLoaded', loadChartJS)
})()</script></div><script data-pjax src="/self/btf.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="ture"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,200,200" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js" defer="defer"></script><script>document.addEventListener('DOMContentLoaded', () => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => {
      try {
        fn()
      } catch (err) {
        console.debug('Pjax callback failed:', err)
      }
    })
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      true
        ? pjax.loadUrl('/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})</script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.4"></script></div></div></body></html>