<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Python Beautiful Soup详解：高效网页数据抓取与解析利器 | 1024 维度</title><meta name="author" content="TeaTang"><meta name="copyright" content="TeaTang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Beautiful Soup 是一个 Python 库，用于从 HTML 或 XML 文件中提取数据。它通过解析文档并提供用于导航、搜索和修改解析树的 Pythonic 接口，将复杂的 HTML&#x2F;XML 文档转化为易于处理的数据结构。Beautiful Soup 与 requests 等 HTTP 库结合使用，是构建网络爬虫进行数据抓取的强大工具。  核心思想：Beautiful So">
<meta property="og:type" content="article">
<meta property="og:title" content="Python Beautiful Soup详解：高效网页数据抓取与解析利器">
<meta property="og:url" content="https://blog.tbf1211.xx.kg/06bc4d655ced/index.html">
<meta property="og:site_name" content="1024 维度">
<meta property="og:description" content="Beautiful Soup 是一个 Python 库，用于从 HTML 或 XML 文件中提取数据。它通过解析文档并提供用于导航、搜索和修改解析树的 Pythonic 接口，将复杂的 HTML&#x2F;XML 文档转化为易于处理的数据结构。Beautiful Soup 与 requests 等 HTTP 库结合使用，是构建网络爬虫进行数据抓取的强大工具。  核心思想：Beautiful So">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.tbf1211.xx.kg/img/cover/default_cover-30.jpg">
<meta property="article:published_time" content="2023-06-08T22:24:00.000Z">
<meta property="article:modified_time" content="2026-01-29T10:03:28.081Z">
<meta property="article:author" content="TeaTang">
<meta property="article:tag" content="2023">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="HTML">
<meta property="article:tag" content="网络爬虫">
<meta property="article:tag" content="Beautiful Soup">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.tbf1211.xx.kg/img/cover/default_cover-30.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Python Beautiful Soup详解：高效网页数据抓取与解析利器",
  "url": "https://blog.tbf1211.xx.kg/06bc4d655ced/",
  "image": "https://blog.tbf1211.xx.kg/img/cover/default_cover-30.jpg",
  "datePublished": "2023-06-08T22:24:00.000Z",
  "dateModified": "2026-01-29T10:03:28.081Z",
  "author": [
    {
      "@type": "Person",
      "name": "TeaTang",
      "url": "https://blog.tbf1211.xx.kg"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon-1.ico"><link rel="canonical" href="https://blog.tbf1211.xx.kg/06bc4d655ced/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><meta name="google-site-verification" content="NdIUXAOVyGnnBhcrip0ksCawbdAzT0hlBZDE9u4jx6k"/><meta name="msvalidate.01" content="567E47D75E8DCF1282B9623AD914701E"/><meta name="baidu-site-verification" content="code-pE5rnuxcfD"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.9/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":true,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":150,"languages":{"author":"作者: TeaTang","link":"链接: ","source":"来源: 1024 维度","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Python Beautiful Soup详解：高效网页数据抓取与解析利器',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="preconnect" href="https://jsd.012700.xyz"><link href="/self/btf.css" rel="stylesheet"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="1024 维度" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/loading.gif" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">533</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">229</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">84</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 我的轨迹</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/2023/"><i class="fa-fw fa-solid fa-bug"></i><span> 2023</span></a></li><li><a class="site-page child" href="/archives/2024/"><i class="fa-fw fa-solid fa-code"></i><span> 2024</span></a></li><li><a class="site-page child" href="/archives/2025/"><i class="fa-fw fa-solid fa-network-wired"></i><span> 2025</span></a></li><li><a class="site-page child" href="/archives/2026/"><i class="fa-fw fa-solid fa-code-branch"></i><span> 2026</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa-solid fa-calendar-days"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/img/cover/default_cover-30.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">1024 维度</span></a><a class="nav-page-title" href="/"><span class="site-name">Python Beautiful Soup详解：高效网页数据抓取与解析利器</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 我的轨迹</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/2023/"><i class="fa-fw fa-solid fa-bug"></i><span> 2023</span></a></li><li><a class="site-page child" href="/archives/2024/"><i class="fa-fw fa-solid fa-code"></i><span> 2024</span></a></li><li><a class="site-page child" href="/archives/2025/"><i class="fa-fw fa-solid fa-network-wired"></i><span> 2025</span></a></li><li><a class="site-page child" href="/archives/2026/"><i class="fa-fw fa-solid fa-code-branch"></i><span> 2026</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa-solid fa-calendar-days"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Python Beautiful Soup详解：高效网页数据抓取与解析利器</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2023-06-08T22:24:00.000Z" title="发表于 2023-06-09 06:24:00">2023-06-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/%E5%BA%93/">库</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">3.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><blockquote>
<p><strong>Beautiful Soup</strong> 是一个 Python 库，用于从 HTML 或 XML 文件中<strong>提取数据</strong>。它通过解析文档并提供用于导航、搜索和修改解析树的 Pythonic 接口，将复杂的 HTML&#x2F;XML 文档转化为易于处理的数据结构。Beautiful Soup 与 <code>requests</code> 等 HTTP 库结合使用，是构建网络爬虫进行数据抓取的强大工具。</p>
</blockquote>
<div class="note info flat"><p>核心思想：Beautiful Soup 将杂乱的 HTML&#x2F;XML 文档“煲成一锅美味的汤”，让你能够轻松地在其中挑选出你需要的数据元素，如同在厨房里筛选食材一样简单。</p>
</div>
<hr>
<h2 id="一、为什么需要-Beautiful-Soup？"><a href="#一、为什么需要-Beautiful-Soup？" class="headerlink" title="一、为什么需要 Beautiful Soup？"></a>一、为什么需要 Beautiful Soup？</h2><p>在网络上，大量有价值的信息以 HTML 页面的形式存在。如果我们需要从这些页面中获取结构化数据（例如，产品信息、新闻标题、评论内容），直接操作原始的 HTML 字符串是非常困难和脆弱的。传统的字符串查找和正则表达式虽然可行，但存在以下问题：</p>
<ul>
<li><strong>HTML 结构复杂</strong>：HTML 标签嵌套层级深，结构不规则，使用正则表达式难以精确匹配。</li>
<li><strong>HTML 容错性</strong>：浏览器会自动纠正不规范的 HTML 结构，但正则表达式无法处理这种容错性。</li>
<li><strong>维护性差</strong>：网页结构一旦改变，正则表达式需要大量修改，维护成本高。</li>
<li><strong>代码可读性差</strong>：复杂的正则表达式难以理解和调试。</li>
</ul>
<p>Beautiful Soup 提供了一个优雅的解决方案：</p>
<ul>
<li><strong>容错性强</strong>：能够处理格式不规范的 HTML 文档，就像浏览器一样。</li>
<li><strong>强大的解析器</strong>：支持多种解析器（如 <code>html.parser</code>, <code>lxml</code>, <code>html5lib</code>），可以根据需求选择。</li>
<li><strong>简单直观的 API</strong>：提供 Python 对象 (<code>Tag</code>, <code>NavigableString</code>, <code>BeautifulSoup</code>) 来表示 HTML 结构，通过 <code>.</code> 属性和 <code>.find()</code>, <code>.find_all()</code> 等方法轻松导航和搜索。</li>
<li><strong>易于数据提取</strong>：方便地获取标签的属性、文本内容。</li>
</ul>
<h2 id="二、安装-Beautiful-Soup"><a href="#二、安装-Beautiful-Soup" class="headerlink" title="二、安装 Beautiful Soup"></a>二、安装 Beautiful Soup</h2><p>Beautiful Soup 库名为 <code>beautifulsoup4</code>（因为它是第四个版本）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure>

<p>此外，你可能还需要安装一个 LXML 解析器（推荐，速度快，功能强）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure>

<p>或者 <code>html5lib</code> (浏览器级别的容错性):</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install html5lib</span><br></pre></td></tr></table></figure>

<h2 id="三、基本使用：创建-Beautiful-Soup-对象"><a href="#三、基本使用：创建-Beautiful-Soup-对象" class="headerlink" title="三、基本使用：创建 Beautiful Soup 对象"></a>三、基本使用：创建 Beautiful Soup 对象</h2><p>首先，你需要获取网页的 HTML 内容（通常使用 <code>requests</code> 库），然后将其传给 Beautiful Soup 构造函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: 获取 HTML 内容</span></span><br><span class="line">url = <span class="string">&quot;https://www.example.com&quot;</span> <span class="comment"># 替换为你想抓取的实际网页</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    response.raise_for_status() <span class="comment"># 检查请求是否成功</span></span><br><span class="line">    html_content = response.text</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.HTTPError <span class="keyword">as</span> errh:</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;Http Error:&quot;</span>,errh)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> errc:</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;Error Connecting:&quot;</span>,errc)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.Timeout <span class="keyword">as</span> errt:</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;Timeout Error:&quot;</span>,errt)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> err:</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;OOps: Something Else&quot;</span>,err)</span><br><span class="line">    html_content = <span class="string">&quot;&quot;</span> <span class="comment"># 如果请求失败，将内容设为空</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2: 创建 Beautiful Soup 对象</span></span><br><span class="line"><span class="comment"># 使用 &#x27;lxml&#x27; 解析器 (推荐)</span></span><br><span class="line">soup = BeautifulSoup(html_content, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以使用 Python 内置的 &#x27;html.parser&#x27;</span></span><br><span class="line"><span class="comment"># soup = BeautifulSoup(html_content, &#x27;html.parser&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者 &#x27;html5lib&#x27; (如果遇到极其残缺不全的 HTML)</span></span><br><span class="line"><span class="comment"># soup = BeautifulSoup(html_content, &#x27;html5lib&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Beautiful Soup 对象类型: <span class="subst">&#123;<span class="built_in">type</span>(soup)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;网页标题: <span class="subst">&#123;soup.title.string&#125;</span>&quot;</span>) <span class="comment"># 直接访问 &lt;title&gt; 标签并获取其文本内容</span></span><br></pre></td></tr></table></figure>

<h2 id="四、Beautiful-Soup-的四大对象类型"><a href="#四、Beautiful-Soup-的四大对象类型" class="headerlink" title="四、Beautiful Soup 的四大对象类型"></a>四、Beautiful Soup 的四大对象类型</h2><p>Beautiful Soup 将复杂的 HTML 文档解析成以下四种对象：</p>
<ol>
<li><p><strong><code>BeautifulSoup</code> 对象</strong>：表示整个文档，是解析后的根节点。</p>
<ul>
<li><code>soup</code> 对象本身。</li>
</ul>
</li>
<li><p><strong><code>Tag</code> 对象</strong>：表示 HTML&#x2F;XML 文档中的一个标签，如 <code>&lt;p&gt;</code>, <code>&lt;a&gt;</code>, <code>&lt;div&gt;</code>。</p>
<ul>
<li><code>soup.title</code>, <code>soup.a</code></li>
</ul>
</li>
<li><p><strong><code>NavigableString</code> 对象</strong>：表示标签中的文本内容，但不包含任何标签。</p>
<ul>
<li><code>soup.title.string</code></li>
</ul>
</li>
<li><p><strong><code>Comment</code> 对象</strong>：表示文档中的注释。</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">html_doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;My Home Page&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">    &lt;!-- 这是个注释 --&gt;</span></span><br><span class="line"><span class="string">    &lt;p class=&quot;story&quot;&gt;</span></span><br><span class="line"><span class="string">        Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">        &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">        &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">        &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">        and they lived at the bottom of a well.</span></span><br><span class="line"><span class="string">    &lt;/p&gt;</span></span><br><span class="line"><span class="string">    &lt;p&gt;...&lt;a href=&quot;http://example.com/test&quot;&gt;Test Link&lt;/a&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;/body&gt;&lt;/html&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">soup_example = BeautifulSoup(html_doc, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># BeautifulSoup 对象</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;BeautifulSoup 对象示例: <span class="subst">&#123;<span class="built_in">type</span>(soup_example)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tag 对象</span></span><br><span class="line">title_tag = soup_example.title</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nTitle Tag 对象示例:\n类型: <span class="subst">&#123;<span class="built_in">type</span>(title_tag)&#125;</span>\nTag 名: <span class="subst">&#123;title_tag.name&#125;</span>\nTag 属性: <span class="subst">&#123;title_tag.attrs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># &lt;title&gt;My Home Page&lt;/title&gt;</span></span><br><span class="line"></span><br><span class="line">a_tag = soup_example.a <span class="comment"># 找到第一个 &lt;a&gt; 标签</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n第一个 A Tag 对象示例:\n类型: <span class="subst">&#123;<span class="built_in">type</span>(a_tag)&#125;</span>\nTag 名: <span class="subst">&#123;a_tag.name&#125;</span>\nTag 属性: <span class="subst">&#123;a_tag.attrs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># NavigableString 对象</span></span><br><span class="line">title_string = title_tag.string</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nNavigableString 对象示例:\n类型: <span class="subst">&#123;<span class="built_in">type</span>(title_string)&#125;</span>\n文本内容: <span class="subst">&#123;title_string&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># My Home Page</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Comment 对象</span></span><br><span class="line">comment = soup_example.body.string <span class="comment"># 直接访问可能不是 Comment，需要遍历</span></span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> soup_example.body.contents:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(element, <span class="built_in">type</span>(soup_example.comment)): <span class="comment"># 判断是否是 Comment 类型</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\nComment 对象示例:\n类型: <span class="subst">&#123;<span class="built_in">type</span>(element)&#125;</span>\n注释内容: <span class="subst">&#123;element&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># 这是个注释</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h2 id="五、导航文档树-Navigating-the-Tree"><a href="#五、导航文档树-Navigating-the-Tree" class="headerlink" title="五、导航文档树 (Navigating the Tree)"></a>五、导航文档树 (Navigating the Tree)</h2><p>Beautiful Soup 提供了多种方式来遍历和查找 HTML 元素。</p>
<h3 id="5-1-通过标签名直接访问"><a href="#5-1-通过标签名直接访问" class="headerlink" title="5.1 通过标签名直接访问"></a>5.1 通过标签名直接访问</h3><p>你可以像访问对象的属性一样访问标签名。这会返回找到的第一个同名标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Head 标签: <span class="subst">&#123;soup.head&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Body 标签: <span class="subst">&#123;soup.body&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;第一个 P 标签: <span class="subst">&#123;soup.p&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-2-contents-和-children"><a href="#5-2-contents-和-children" class="headerlink" title="5.2 contents 和 children"></a>5.2 <code>contents</code> 和 <code>children</code></h3><ul>
<li><code>contents</code>：将子节点作为列表返回，包括 <code>NavigableString</code> 和 <code>Tag</code>。</li>
<li><code>children</code>：返回一个生成器，可迭代地获取子节点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">body_tag = soup_example.body</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nBody 的所有子节点 (contents):\n<span class="subst">&#123;body_tag.contents&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># [u&#x27;\n&#x27;, &lt;!-- 这是个注释 --&gt;, u&#x27;\n&#x27;, &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;, u&#x27;\n&#x27;, &lt;p&gt;...&lt;/p&gt;, u&#x27;\n&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> body_tag.children:</span><br><span class="line">    <span class="keyword">if</span> child.name: <span class="comment"># 只打印 Tag 对象</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Body 的子标签: <span class="subst">&#123;child.name&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># p</span></span><br><span class="line"><span class="comment"># p</span></span><br></pre></td></tr></table></figure>

<h3 id="5-3-parent-和-parents"><a href="#5-3-parent-和-parents" class="headerlink" title="5.3 parent 和 parents"></a>5.3 <code>parent</code> 和 <code>parents</code></h3><ul>
<li><code>parent</code>：访问元素的父节点。</li>
<li><code>parents</code>：返回一个生成器，可迭代地获取所有祖先节点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a_tag = soup_example.a</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n第一个 A 标签的父节点: <span class="subst">&#123;a_tag.parent.name&#125;</span>&quot;</span>) <span class="comment"># p</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;第一个 A 标签的所有祖先节点:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> a_tag.parents:</span><br><span class="line">    <span class="keyword">if</span> parent.name:</span><br><span class="line">        <span class="built_in">print</span>(parent.name)</span><br><span class="line"><span class="comment"># p</span></span><br><span class="line"><span class="comment"># body</span></span><br><span class="line"><span class="comment"># html</span></span><br><span class="line"><span class="comment"># [document]</span></span><br></pre></td></tr></table></figure>

<h3 id="5-4-next-sibling-和-previous-sibling"><a href="#5-4-next-sibling-和-previous-sibling" class="headerlink" title="5.4 next_sibling 和 previous_sibling"></a>5.4 <code>next_sibling</code> 和 <code>previous_sibling</code></h3><ul>
<li><code>next_sibling</code>：访问当前节点的下一个兄弟节点。</li>
<li><code>previous_sibling</code>：访问当前节点的上一个兄弟节点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">link1 = soup_example.find(<span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>) <span class="comment"># 找到 id 为 link1 的标签</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n&#x27;Elsie&#x27; 链接的下一个兄弟节点: <span class="subst">&#123;link1.next_sibling&#125;</span>&quot;</span>) <span class="comment"># &#x27;, &#x27; (这是一个 NavigableString)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;&#x27;Elsie&#x27; 链接的下一个兄弟标签: <span class="subst">&#123;link1.next_sibling.next_sibling.name&#125;</span>&quot;</span>) <span class="comment"># a (这是 &#x27;Lacie&#x27; 链接)</span></span><br></pre></td></tr></table></figure>

<h2 id="六、搜索文档树-Searching-the-Tree"><a href="#六、搜索文档树-Searching-the-Tree" class="headerlink" title="六、搜索文档树 (Searching the Tree)"></a>六、搜索文档树 (Searching the Tree)</h2><p>这是 Beautiful Soup 最强大的功能，用于精确查找需要的元素。</p>
<h3 id="6-1-find-和-find-all"><a href="#6-1-find-和-find-all" class="headerlink" title="6.1 find() 和 find_all()"></a>6.1 <code>find()</code> 和 <code>find_all()</code></h3><ul>
<li><strong><code>find_all(name, attrs, recursive, text, limit, **kwargs)</code></strong>：查找所有符合条件的标签。<ul>
<li><code>name</code>：标签名 (e.g., ‘a’, ‘div’, [‘a’, ‘p’])。</li>
<li><code>attrs</code>：属性字典 (e.g., {‘class’: ‘sister’, ‘id’: ‘link1’})。</li>
<li><code>recursive</code>：是否递归查找子孙节点 (默认为 True)。</li>
<li><code>text</code>：查找文本内容。</li>
<li><code>limit</code>：限制返回结果的数量。</li>
</ul>
</li>
<li><strong><code>find(name, attrs, recursive, text, **kwargs)</code></strong>：与 <code>find_all</code> 相同，但只返回第一个符合条件的标签。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找所有 &lt;a&gt; 标签</span></span><br><span class="line">all_a_tags = soup_example.find_all(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n所有 &lt;a&gt; 标签数量: <span class="subst">&#123;<span class="built_in">len</span>(all_a_tags)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> all_a_tags:</span><br><span class="line">    <span class="built_in">print</span>(tag.get(<span class="string">&#x27;href&#x27;</span>), tag.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 class=&#x27;sister&#x27; 的 &lt;a&gt; 标签</span></span><br><span class="line">sister_links = soup_example.find_all(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&#x27;sister&#x27;</span>) <span class="comment"># class 是 Python 关键字，用 class_</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n所有 class=&#x27;sister&#x27; 的 &lt;a&gt; 标签:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> sister_links:</span><br><span class="line">    <span class="built_in">print</span>(link.get(<span class="string">&#x27;href&#x27;</span>), link.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 id=&#x27;link2&#x27; 的标签</span></span><br><span class="line">link2 = soup_example.find(<span class="built_in">id</span>=<span class="string">&#x27;link2&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nID 为 &#x27;link2&#x27; 的标签: <span class="subst">&#123;link2.string&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找所有文本内容为 &#x27;Tillie&#x27; 的标签</span></span><br><span class="line">tillie_tag = soup_example.find(string=<span class="string">&#x27;Tillie&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n文本内容为 &#x27;Tillie&#x27; 的标签: <span class="subst">&#123;tillie_tag.parent.name&#125;</span>&quot;</span>) <span class="comment"># parent 是 &lt;a&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找同时是 &#x27;p&#x27; 标签且 class=&#x27;story&#x27; 的元素</span></span><br><span class="line">story_p = soup_example.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;story&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nClass 为 &#x27;story&#x27; 的 P 标签:\n<span class="subst">&#123;story_p.prettify()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找包含特定字符串的标签</span></span><br><span class="line"><span class="comment"># 例如，查找 href 属性包含 &quot;example.com&quot; 的 &lt;a&gt; 标签</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">example_links = soup_example.find_all(<span class="string">&#x27;a&#x27;</span>, href=re.<span class="built_in">compile</span>(<span class="string">r&quot;example\.com&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nHref 包含 &#x27;example.com&#x27; 的链接:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> example_links:</span><br><span class="line">    <span class="built_in">print</span>(link.get(<span class="string">&#x27;href&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找同时满足多个属性的标签</span></span><br><span class="line">link_by_attrs = soup_example.find(<span class="string">&#x27;a&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;sister&#x27;</span>, <span class="string">&#x27;href&#x27;</span>: <span class="string">&#x27;http://example.com/lacie&#x27;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n按多个属性查找的链接: <span class="subst">&#123;link_by_attrs.string&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="6-2-CSS-选择器-select"><a href="#6-2-CSS-选择器-select" class="headerlink" title="6.2 CSS 选择器 (select())"></a>6.2 CSS 选择器 (<code>select()</code>)</h3><p>Beautiful Soup 支持使用 CSS 选择器来查找元素，这对于前端开发人员来说非常熟悉和方便。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找所有 p 标签</span></span><br><span class="line">all_p_tags = soup_example.select(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n通过 CSS 选择器查找所有 P 标签:\n<span class="subst">&#123;all_p_tags&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 class 为 sister 的 a 标签</span></span><br><span class="line">sister_a_tags = soup_example.select(<span class="string">&#x27;a.sister&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n通过 CSS 选择器查找 class=&#x27;sister&#x27; 的 A 标签:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> sister_a_tags:</span><br><span class="line">    <span class="built_in">print</span>(tag.string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 id 为 link3 的标签</span></span><br><span class="line">link3 = soup_example.select_one(<span class="string">&#x27;#link3&#x27;</span>) <span class="comment"># select_one 相当于 find</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n通过 CSS 选择器查找 ID 为 &#x27;link3&#x27; 的标签: <span class="subst">&#123;link3.string&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找 p 标签下的所有 a 标签</span></span><br><span class="line">p_a_tags = soup_example.select(<span class="string">&#x27;p a&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n查找 p 标签下的所有 a 标签:\n<span class="subst">&#123;p_a_tags&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结构化选择器: 查找父元素 p 并且 class 是 story 的 a 元素</span></span><br><span class="line">story_a_tags = soup_example.select(<span class="string">&#x27;p.story &gt; a&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n在 class=&#x27;story&#x27; 的 p 标签下的直接子 a 标签:\n<span class="subst">&#123;story_a_tags&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="七、提取数据"><a href="#七、提取数据" class="headerlink" title="七、提取数据"></a>七、提取数据</h2><p>一旦找到目标标签，就可以提取其属性或文本内容。</p>
<h3 id="7-1-获取标签属性"><a href="#7-1-获取标签属性" class="headerlink" title="7.1 获取标签属性"></a>7.1 获取标签属性</h3><p>标签的属性存储在 <code>.attrs</code> 字典中，也可以通过 <code>tag.get()</code> 方法获取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">link1 = soup_example.find(<span class="built_in">id</span>=<span class="string">&#x27;link1&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n链接属性 dict: <span class="subst">&#123;link1.attrs&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;链接的 href 属性: <span class="subst">&#123;link1[<span class="string">&#x27;href&#x27;</span>]&#125;</span>&quot;</span>) <span class="comment"># 字典方式访问</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;链接的 class 属性: <span class="subst">&#123;link1.get(<span class="string">&#x27;class&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;尝试获取不存在的属性 (返回 None): <span class="subst">&#123;link1.get(<span class="string">&#x27;data-foo&#x27;</span>)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="7-2-获取文本内容"><a href="#7-2-获取文本内容" class="headerlink" title="7.2 获取文本内容"></a>7.2 获取文本内容</h3><ul>
<li><code>tag.string</code>：如果标签只有一个子 NavigableString，则返回该字符串。如果包含多个子节点或子标签，则返回 None。</li>
<li><code>tag.text</code>：获取标签内所有文本内容的组合，包括子标签的文本，并去除多余空白。</li>
<li><code>tag.get_text()</code>：与 <code>tag.text</code> 类似，但提供了更多参数控制。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">title_tag = soup_example.title</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nTitle 标签的 string: <span class="subst">&#123;title_tag.string&#125;</span>&quot;</span>) <span class="comment"># My Home Page</span></span><br><span class="line"></span><br><span class="line">p_tag = soup_example.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;story&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;P 标签的 string: <span class="subst">&#123;p_tag.string&#125;</span>&quot;</span>) <span class="comment"># None (因为它有文本和多个 &lt;a&gt; 子标签)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;P 标签的 text (所有子标签文本): <span class="subst">&#123;p_tag.text&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="comment"># Elsie,</span></span><br><span class="line"><span class="comment"># Lacie and</span></span><br><span class="line"><span class="comment"># Tillie;</span></span><br><span class="line"><span class="comment"># and they lived at the bottom of a well.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;P 标签的 get_text(separator=&#x27;|&#x27;, strip=True):\n<span class="subst">&#123;p_tag.get_text(separator=<span class="string">&#x27;|&#x27;</span>, strip=<span class="literal">True</span>)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Once upon a time there were three little sisters;|and their names were|Elsie,|Lacie and|Tillie;|and they lived at the bottom of a well.</span></span><br></pre></td></tr></table></figure>

<h2 id="八、常见爬虫流程示例"><a href="#八、常见爬虫流程示例" class="headerlink" title="八、常见爬虫流程示例"></a>八、常见爬虫流程示例</h2><div class="mermaid-wrap"><pre class="mermaid-src" data-config="{}" hidden>
    sequenceDiagram
    participant User as 用户
    participant PythonScript as Python 脚本
    participant WebServer as 目标网站服务器

    User-&gt;&gt;PythonScript: 运行爬虫脚本
    PythonScript-&gt;&gt;WebServer: 1. 发送 HTTP 请求 (requests.get(url))
    WebServer-&gt;&gt;PythonScript: 2. 返回 HTML 响应
    PythonScript-&gt;&gt;PythonScript: 3. 使用 Beautiful Soup 解析 HTML (BeautifulSoup(html_content, &#39;lxml&#39;))
    PythonScript-&gt;&gt;PythonScript: 4. 遍历&#x2F;搜索解析树 (find_all(), select())
    PythonScript-&gt;&gt;PythonScript: 5. 提取所需数据 (tag.get(&#39;attr&#39;), tag.text)
    PythonScript-&gt;&gt;PythonScript: 6. 数据清洗与存储 (CSV&#x2F;JSON&#x2F;DB)
    PythonScript-&gt;&gt;User: 7. 提供抓取结果
  </pre></div>

<p><strong>示例：抓取网站导航栏链接</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_navigation_links</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        soup = BeautifulSoup(response.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 假设导航链接在 nav 标签中，并且是 ul &gt; li &gt; a 的结构</span></span><br><span class="line">        <span class="comment"># 这需要根据实际网页结构调整</span></span><br><span class="line">        nav_links = soup.select(<span class="string">&#x27;nav ul li a&#x27;</span>)</span><br><span class="line">      </span><br><span class="line">        links_data = []</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> nav_links:</span><br><span class="line">            text = link.text.strip()</span><br><span class="line">            href = link.get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> text <span class="keyword">and</span> href: <span class="comment"># 确保文本和链接都存在</span></span><br><span class="line">                links_data.append(&#123;<span class="string">&#x27;text&#x27;</span>: text, <span class="string">&#x27;href&#x27;</span>: href&#125;)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> links_data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;请求失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 抓取一个实际网站的例子 (例如，Python 官方文档首页的一部分)</span></span><br><span class="line"><span class="comment"># 注意：抓取任何网站前请查看其 robots.txt 和服务条款，遵守相关规定</span></span><br><span class="line">target_url = <span class="string">&quot;https://www.python.org/doc/&quot;</span></span><br><span class="line">nav_items = get_navigation_links(target_url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> nav_items:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n从 <span class="subst">&#123;target_url&#125;</span> 抓取的导航链接:&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> nav_items:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  文本: <span class="subst">&#123;item[<span class="string">&#x27;text&#x27;</span>]&#125;</span>, 链接: <span class="subst">&#123;item[<span class="string">&#x27;href&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n未能从 <span class="subst">&#123;target_url&#125;</span> 抓取导航链接。&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="九、安全性与注意事项"><a href="#九、安全性与注意事项" class="headerlink" title="九、安全性与注意事项"></a>九、安全性与注意事项</h2><ul>
<li><strong>遵守 <code>robots.txt</code></strong>：在爬取网站之前，务必检查网站的 <code>robots.txt</code> 文件，它声明了网站允许或禁止爬取的规则。</li>
<li><strong>频率限制</strong>：不要在短时间内向网站发送大量请求，这可能导致你的 IP 被封锁，甚至对网站服务器造成负担。</li>
<li><strong>用户代理 (User-Agent)</strong>：模拟浏览器请求头，防止被网站识别为爬虫。</li>
<li><strong>处理异常</strong>：网络请求和解析过程中都可能出现异常（如网络错误、页面结构变化），需要使用 <code>try-except</code> 块进行处理。</li>
<li><strong>异步抓取</strong>：对于大规模抓取，考虑使用 <code>httpx</code> 或 <code>aiohttp</code> 配合 <code>asyncio</code> 进行异步请求，提高效率。</li>
<li><strong>验证码&#x2F;反爬机制</strong>：高级的反爬虫机制（如验证码、JS 动态加载、数据加密等）可能需要更复杂的解决方案，如 Selenium (针对 JS 渲染) 或机器学习。</li>
<li><strong>法律与道德</strong>：尊重网站版权和隐私，不要抓取敏感数据，遵守当地法律法规。</li>
</ul>
<h2 id="十、总结与进阶"><a href="#十、总结与进阶" class="headerlink" title="十、总结与进阶"></a>十、总结与进阶</h2><p>Beautiful Soup 是 Python 爬虫入门和处理结构化数据提取的绝佳选择。它的 API 友好，易于学习，并且能够很好地处理不规范的 HTML。</p>
<p><strong>进阶方向：</strong></p>
<ul>
<li><strong>与 <code>Requests</code> 库深度结合</strong>：学习如何处理会话 (Session)、Cookies、代理、头部信息等。</li>
<li><strong>动态网页抓取 (<code>Selenium</code>)</strong>：对于 JavaScript 动态渲染的网页，Beautiful Soup 无法直接获取渲染后的内容，需要结合 Selenium 自动化浏览器。</li>
<li><strong>Scrapy 框架</strong>：对于更复杂、大规模的爬虫项目，使用 Scrapy 这种专业的爬虫框架能提供更多功能（如调度、中间件、管道）。</li>
<li><strong>数据存储</strong>：将抓取到的数据存储到 CSV、JSON、数据库（SQLite, PostgreSQL, MongoDB）等。</li>
<li><strong>异常处理和日志记录</strong>：构建健壮的爬虫，处理各种运行时错误。</li>
</ul>
<p>掌握 Beautiful Soup，你将能够从海量的网页信息中提取有用的数据，为数据分析、市场研究、内容聚合等提供原始数据支持。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.tbf1211.xx.kg">TeaTang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.tbf1211.xx.kg/06bc4d655ced/">https://blog.tbf1211.xx.kg/06bc4d655ced/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.tbf1211.xx.kg" target="_blank">1024 维度</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2023/">2023</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/HTML/">HTML</a><a class="post-meta__tags" href="/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/">网络爬虫</a><a class="post-meta__tags" href="/tags/Beautiful-Soup/">Beautiful Soup</a></div><div class="post-share"><div class="social-share" data-image="/img/cover/default_cover-30.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/fc3deef3ef61/" title="构建工具 Gradle 详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-07.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">构建工具 Gradle 详解</div></div><div class="info-2"><div class="info-item-1"> Gradle 是一个基于 Apache Ant 和 Apache Maven 概念的项目自动化构建工具。它使用 Groovy 语言（或 Kotlin DSL）来编写构建脚本，提供了一种声明式和命令式兼备的强大构建方式。Gradle 融合了 Ant 的灵活性和 Maven 的约定式管理及依赖管理能力，旨在为多项目构建提供更强大的支持、更高的性能和更灵活的配置。  核心思想：Gradle 采用 基于 Groovy&#x2F;Kotlin DSL 的脚本 来定义构建逻辑，结合了 增量编译 和 构建缓存 技术，以实现高性能。它通过 自定义任务和插件 提供了极高的灵活性，同时通过 约定优于配置 的原则降低了复杂性。   一、为什么需要 Gradle？尽管 Maven 在 Java 项目构建中取得了巨大成功，但它也存在一些局限性，促使了 Gradle 的出现和流行：  Maven 的 XML 配置冗长复杂： pom.xml 文件随着项目规模的增长会变得非常庞大和难以阅读。 XML 配置相比于编程语言，表达能力有限，实现复杂逻辑时会很繁琐。   Maven 的灵活性不足： Maven 严格遵...</div></div></div></a><a class="pagination-related" href="/5febe994b52e/" title="Java 构建工具 Maven 详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-08.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Java 构建工具 Maven 详解</div></div><div class="info-2"><div class="info-item-1"> Apache Maven (Maven) 是一个强大的项目管理和构建自动化工具，主要服务于基于 Java 的项目。它遵循约定优于配置 (Convention over Configuration) 的原则，提供了一个标准化的项目结构和生命周期，用于编译、测试、打包、部署等任务。Maven 的核心目标是让项目构建过程标准化、可预测且易于维护，同时提供强大的依赖管理功能。  核心思想：Maven 将项目视为一系列相互依赖的模块，通过一个声明式的 XML 文件 (pom.xml) 来管理项目的构建、报告和文档。它推崇一套标准的项目布局和生命周期，从而减少开发者在配置上的工作量。   一、为什么需要 Maven？在 Maven 出现之前，Java 项目的构建和管理通常面临诸多挑战：  依赖管理混乱： 项目所需的所有第三方 JAR 包都需要手动下载并添加到项目的 classpath 中。 如果多个项目使用相同库的不同版本，容易引发冲突 (JAR Hell)。 依赖的依赖（传递性依赖）管理起来更加复杂。   构建过程非标准化： 不同的项目可能有不同的构建脚本 (如 Ant)，导致构建步骤不...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/3d8fe1e715a5/" title="Python lxml详解：高效XML&#x2F;HTML解析与处理"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-21.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-05</div><div class="info-item-2">Python lxml详解：高效XML&#x2F;HTML解析与处理</div></div><div class="info-2"><div class="info-item-1"> lxml 是 Python 的一个强大且功能丰富的库，用于解析和处理 XML 和 HTML 文档。它结合了 C 语言库 libxml2 和 libxslt 的速度和功能，以及 Python 的简洁和灵活性。lxml 提供了多种解析方式（如 ElementTree API 和 SAX），并支持强大的 XPath 和 CSS 选择器进行数据提取。在高性能要求的场景下，lxml 往往是处理大型 XML&#x2F;HTML 文档的首选。  核心思想：lxml 利用底层的 C 库，提供了比纯 Python 解析器快得多的性能，同时通过 Pythonic 的接口，使得 XML&#x2F;HTML 的解析、导航和数据提取变得高效而直观。   一、为什么选择 lxml？在 Python 处理 XML&#x2F;HTML 文档时，我们有多种选择，例如 Python 标准库中的 xml.etree.ElementTree、minidom，以及 Beautiful Soup。然而，lxml 在性能和功能上提供了独特的优势：  极高的性能：由于其核心解析引擎是用 C 语言实现的 libxml2 和 l...</div></div></div></a><a class="pagination-related" href="/109739b91598/" title="Python Matplotlib 详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-28.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-22</div><div class="info-item-2">Python Matplotlib 详解</div></div><div class="info-2"><div class="info-item-1"> Matplotlib 是一个用于创建静态、动态和交互式可视化在 Python 中的综合库。它提供了强大的工具集，用于生成各种出版质量级别的图表，从简单的线图、散点图到复杂的3D图表和动画。它是 Python 科学计算生态系统（如 NumPy, SciPy, Pandas）中不可或缺的一部分。  核心思想：提供一个灵活、可高度定制的绘图框架，让开发者能够精确控制图表的每一个细节，以满足从数据探索到学术出版的各种可视化需求。   一、为什么需要 Matplotlib？在数据分析、科学研究、工程计算等领域，数据可视化是理解数据、发现模式和传达洞察的关键。然而，手动绘制图表或使用通用工具往往效率低下且难以定制。Matplotlib 旨在解决以下问题：  数据理解：海量数据以表格形式呈现时难以理解，通过图表能够直观展示数据的分布、趋势和关系。 报告与演示：需要高质量、专业级的图表用于学术论文、商业报告或演示文稿。 定制化需求：通用绘图工具可能无法满足特定的可视化需求，需要能够对图表的每个元素（颜色、字体、线条、布局等）进行精确控制。 编程集成：希望在 Python 程序中直接生成和操作图...</div></div></div></a><a class="pagination-related" href="/91353ff26772/" title="Peewee ORM 详解：接口使用与实践"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-15.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-11</div><div class="info-item-2">Peewee ORM 详解：接口使用与实践</div></div><div class="info-2"><div class="info-item-1"> Peewee 是一个小型、富有表现力、功能齐全的 Python ORM (Object-Relational Mapper)。它提供了一种简单且 Pythonic 的方式来与数据库进行交互，支持 SQLite、PostgreSQL 和 MySQL 等多种关系型数据库。Peewee 的设计理念是轻量级和易用性，使得开发者可以快速地构建应用程序，而无需编写大量的 SQL 语句。  核心思想：将数据库表映射为 Python 类，将表的行映射为类的实例，将表的列映射为类的属性。 通过 Python 对象和方法来操作数据库，从而抽象掉底层的 SQL 细节。   一、为什么选择 Peewee？在 Python 生态中，存在多种 ORM 解决方案，如 SQLAlchemy、Django ORM 等。Peewee 在其中脱颖而出，主要归因于以下特点：  轻量级与简洁性：Peewee 本身代码量较少，API 设计简洁直观，学习曲线平缓。 富有表现力：其查询 API 允许开发者使用类似 Python 原生语法的方式链式调用，构建复杂的查询。 兼容性强：支持 SQLite、PostgreSQL 和 ...</div></div></div></a><a class="pagination-related" href="/f6307a80c973/" title="Python 防止循环依赖 (Circular Dependencies) 详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-06.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-07</div><div class="info-item-2">Python 防止循环依赖 (Circular Dependencies) 详解</div></div><div class="info-2"><div class="info-item-1"> 循环依赖 (Circular Dependency) 指的是两个或多个模块（在 Python 中通常是文件或包）之间相互直接或间接地导入对方。例如，moduleA.py 导入了 moduleB.py，而 moduleB.py 也导入了 moduleA.py。与 Golang 等语言在编译时直接报错不同，Python 在运行时才处理导入，因此循环依赖通常不会立即导致语法错误，但会在运行时触发 ImportError 或导致不可预测的行为，使代码难以理解、测试和维护。  核心思想：Python 允许在运行时灵活处理导入，但循环依赖是一个设计缺陷的信号，会导致运行时错误或维护噩梦。解决它的关键在于重构代码以建立单向依赖。   一、为什么循环依赖是一个问题？尽管 Python 不像 Go 那样在编译时严格禁止循环依赖，但它依然是需要极力避免的设计缺陷：  运行时 ImportError:这是最常见的直接问题。当 Python 解释器遇到循环导入时，某个模块在被完全初始化之前可能就被另一个模块尝试导入，导致模块中的对象、函数或类尚未定义而引发 ImportError。 示例：module...</div></div></div></a><a class="pagination-related" href="/dbdbe99385cd/" title="Python Pandas详解：数据处理与分析的瑞士军刀"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-25.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-21</div><div class="info-item-2">Python Pandas详解：数据处理与分析的瑞士军刀</div></div><div class="info-2"><div class="info-item-1"> Pandas 是 Python 中用于数据分析和处理的核心库。它提供了一套高性能、易于使用的数据结构，最主要的是 DataFrame（二维表格数据）和 Series（一维带标签数组），用于快速处理和分析结构化数据（如 CSV、Excel、数据库表格数据）。Pandas 以其直观的语法和强大的功能，成为数据科学家和数据工程师的首选工具。  核心思想：Pandas 将表格数据抽象为 DataFrame 和 Series 对象，提供类似 SQL 和 Excel 的操作，通过向量化和 C&#x2F;Cython 实现的底层优化，极大提升了数据处理效率。   一、为什么选择 Pandas？在数据驱动的时代，我们经常需要处理各种形式的表格数据。Python 原生的数据结构（如列表、字典）虽然灵活，但在处理大量、复杂、异构的表格数据时显得力不从心。Pandas 解决了这些痛点：  直观的数据结构：DataFrame 和 Series 提供了强大的标签索引功能，使得数据操作更加直观，无需关注底层实现。 高效的数据操作：底层基于 NumPy 优化，利用 C 和 Cython 实现，对于大规模数据...</div></div></div></a><a class="pagination-related" href="/a1d408b2ddbe/" title="Python多进程实现生产者-消费者模式详解"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-29.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-15</div><div class="info-item-2">Python多进程实现生产者-消费者模式详解</div></div><div class="info-2"><div class="info-item-1"> 生产者-消费者模式是并发编程中一个非常常见的设计模式，用于解决生产者和消费者之间由于生产和消费的速度不一致而导致的线程（或进程）同步问题。在 Python 中，可以使用 multiprocessing 模块实现多进程版的生产者-消费者模式，以充分利用多核 CPU 资源。  核心思想：利用共享队列作为缓冲，实现生产者与消费者解耦，并通过互斥锁和条件变量（或自带的线程安全队列）进行同步，避免数据不一致和资源竞争。   一、生产者-消费者模式概述模式构成：  生产者 (Producer)：负责生成数据，并将其放入共享的缓冲区（队列）中。 消费者 (Consumer)：负责从共享的缓冲区（队列）中取出数据进行处理。 缓冲区 (Buffer &#x2F; Queue)：一个共享的数据结构，通常是一个队列，用于存储生产者生产的数据和消费者消费的数据。它充当了生产者和消费者之间的桥梁。  解决的问题：  解耦：生产者和消费者可以独立运行，互不干扰，提高系统的灵活性。 并发：允许多个生产者和多个消费者同时存在，提高处理效率。 削峰填谷：当生产速度快于消费速度时，缓冲区可以存储多余的数据，防止数...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/loading.gif" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">TeaTang</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">533</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">229</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">84</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/teatang"><i class="fab fa-github"></i><span>GitHub主页</span></a><div class="card-info-social-icons"><a class="social-icon" href="mailto:tea.tang1211@gmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">网站更多功能即将上线，敬请期待！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-Beautiful-Soup%EF%BC%9F"><span class="toc-text">一、为什么需要 Beautiful Soup？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85-Beautiful-Soup"><span class="toc-text">二、安装 Beautiful Soup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%EF%BC%9A%E5%88%9B%E5%BB%BA-Beautiful-Soup-%E5%AF%B9%E8%B1%A1"><span class="toc-text">三、基本使用：创建 Beautiful Soup 对象</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Beautiful-Soup-%E7%9A%84%E5%9B%9B%E5%A4%A7%E5%AF%B9%E8%B1%A1%E7%B1%BB%E5%9E%8B"><span class="toc-text">四、Beautiful Soup 的四大对象类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%AF%BC%E8%88%AA%E6%96%87%E6%A1%A3%E6%A0%91-Navigating-the-Tree"><span class="toc-text">五、导航文档树 (Navigating the Tree)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E9%80%9A%E8%BF%87%E6%A0%87%E7%AD%BE%E5%90%8D%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE"><span class="toc-text">5.1 通过标签名直接访问</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-contents-%E5%92%8C-children"><span class="toc-text">5.2 contents 和 children</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-parent-%E5%92%8C-parents"><span class="toc-text">5.3 parent 和 parents</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-next-sibling-%E5%92%8C-previous-sibling"><span class="toc-text">5.4 next_sibling 和 previous_sibling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%90%9C%E7%B4%A2%E6%96%87%E6%A1%A3%E6%A0%91-Searching-the-Tree"><span class="toc-text">六、搜索文档树 (Searching the Tree)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-find-%E5%92%8C-find-all"><span class="toc-text">6.1 find() 和 find_all()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-CSS-%E9%80%89%E6%8B%A9%E5%99%A8-select"><span class="toc-text">6.2 CSS 选择器 (select())</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-text">七、提取数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E5%B1%9E%E6%80%A7"><span class="toc-text">7.1 获取标签属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E8%8E%B7%E5%8F%96%E6%96%87%E6%9C%AC%E5%86%85%E5%AE%B9"><span class="toc-text">7.2 获取文本内容</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%B8%B8%E8%A7%81%E7%88%AC%E8%99%AB%E6%B5%81%E7%A8%8B%E7%A4%BA%E4%BE%8B"><span class="toc-text">八、常见爬虫流程示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E5%AE%89%E5%85%A8%E6%80%A7%E4%B8%8E%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-text">九、安全性与注意事项</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%81%E3%80%81%E6%80%BB%E7%BB%93%E4%B8%8E%E8%BF%9B%E9%98%B6"><span class="toc-text">十、总结与进阶</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/5341a0037256/" title="CSS-in-JS 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-02.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CSS-in-JS 详解"/></a><div class="content"><a class="title" href="/5341a0037256/" title="CSS-in-JS 详解">CSS-in-JS 详解</a><time datetime="2026-01-25T22:24:00.000Z" title="发表于 2026-01-26 06:24:00">2026-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/0b52cb819619/" title="Git 核心对象：Commit, Tree, Blob 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-28.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Git 核心对象：Commit, Tree, Blob 详解"/></a><div class="content"><a class="title" href="/0b52cb819619/" title="Git 核心对象：Commit, Tree, Blob 详解">Git 核心对象：Commit, Tree, Blob 详解</a><time datetime="2026-01-21T22:24:00.000Z" title="发表于 2026-01-22 06:24:00">2026-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/1d2a942bda1e/" title="Terraform 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-29.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Terraform 详解"/></a><div class="content"><a class="title" href="/1d2a942bda1e/" title="Terraform 详解">Terraform 详解</a><time datetime="2026-01-19T22:24:00.000Z" title="发表于 2026-01-20 06:24:00">2026-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/26cdb2447b3d/" title="WebView 详解"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-26.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="WebView 详解"/></a><div class="content"><a class="title" href="/26cdb2447b3d/" title="WebView 详解">WebView 详解</a><time datetime="2026-01-17T22:24:00.000Z" title="发表于 2026-01-18 06:24:00">2026-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/e62a1e8acade/" title="AI 辅助编程的关键要点与代码幻觉防范"><img src="/img/loading.gif" data-lazy-src="/img/cover/default_cover-03.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI 辅助编程的关键要点与代码幻觉防范"/></a><div class="content"><a class="title" href="/e62a1e8acade/" title="AI 辅助编程的关键要点与代码幻觉防范">AI 辅助编程的关键要点与代码幻觉防范</a><time datetime="2026-01-15T22:24:00.000Z" title="发表于 2026-01-16 06:24:00">2026-01-16</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/cover/default_cover-30.jpg);"><div class="footer-flex"><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">我的轨迹</div><div class="footer-flex-content"><a href="/archives/2023/" target="_blank" title="🆕 2023">🆕 2023</a><a href="/archives/2024/" target="_blank" title="🆒 2024">🆒 2024</a><a href="/archives/2025/" target="_blank" title="👨‍👩‍👦 2025">👨‍👩‍👦 2025</a><a href="/archives/2026/" target="_blank" title="🆙 2026">🆙 2026</a></div></div></div><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">维度</div><div class="footer-flex-content"><a href="/categories/" target="_blank" title="📁 分类">📁 分类</a><a href="/tags/" target="_blank" title="🔖 标签">🔖 标签</a><a href="/categories/" target="_blank" title="📽️ 时间线">📽️ 时间线</a></div></div></div><div class="footer-flex-items"><div class="footer-flex-item"><div class="footer-flex-title">其他</div><div class="footer-flex-content"><a href="/shuoshuo" target="_blank" title="💬 说说">💬 说说</a></div></div></div></div><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2023 - 2026 By TeaTang</span><span class="framework-info"><span class="footer-separator">|</span><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.9/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const parseViewBox = viewBox => {
    if (!viewBox) return null
    const parts = viewBox.trim().split(/[\s,]+/).map(n => Number(n))
    if (parts.length !== 4 || parts.some(n => Number.isNaN(n))) return null
    return parts
  }

  const getSvgViewBox = svg => {
    const attr = parseViewBox(svg.getAttribute('viewBox'))
    if (attr) return attr

    // Fallback: use bbox to build a viewBox
    try {
      const bbox = svg.getBBox()
      if (bbox && bbox.width && bbox.height) return [bbox.x, bbox.y, bbox.width, bbox.height]
    } catch (e) {
      // getBBox may fail on some edge cases; ignore
    }

    const w = Number(svg.getAttribute('width')) || 0
    const h = Number(svg.getAttribute('height')) || 0
    if (w > 0 && h > 0) return [0, 0, w, h]
    return [0, 0, 100, 100]
  }

  const setSvgViewBox = (svg, vb) => {
    svg.setAttribute('viewBox', `${vb[0]} ${vb[1]} ${vb[2]} ${vb[3]}`)
  }

  const clamp = (v, min, max) => Math.max(min, Math.min(max, v))

  const openSvgInNewTab = ({ source, initViewBox }) => {
    const getClonedSvg = () => {
      if (typeof source === 'string') {
        const template = document.createElement('template')
        template.innerHTML = source.trim()
        const svg = template.content.querySelector('svg')
        return svg ? svg.cloneNode(true) : null
      }
      if (source && typeof source.cloneNode === 'function') {
        return source.cloneNode(true)
      }
      return null
    }

    const clone = getClonedSvg()
    if (!clone) return
    if (initViewBox && initViewBox.length === 4) {
      clone.setAttribute('viewBox', initViewBox.join(' '))
    }
    if (!clone.getAttribute('xmlns')) clone.setAttribute('xmlns', 'http://www.w3.org/2000/svg')
    if (!clone.getAttribute('xmlns:xlink') && clone.outerHTML.includes('xlink:')) {
      clone.setAttribute('xmlns:xlink', 'http://www.w3.org/1999/xlink')
    }
    // inject background to match current theme
    const isDark = document.documentElement.getAttribute('data-theme') === 'dark'
    const bg = getComputedStyle(document.body).backgroundColor || (isDark ? '#1e1e1e' : '#ffffff')
    if (!clone.style.background) clone.style.background = bg

    const serializer = new XMLSerializer()
    const svgSource = serializer.serializeToString(clone)
    const htmlSource = `<!doctype html><html><head><meta charset="utf-8" />
      <style>
        html, body { width: 100%; height: 100%; margin: 0; display: flex; align-items: center; justify-content: center; background: ${bg}; }
        svg { max-width: 100%; max-height: 100%; height: auto; width: auto; }
      </style>
      </head><body>${svgSource}</body></html>`
    const blob = new Blob([htmlSource], { type: 'text/html;charset=utf-8' })
    const url = URL.createObjectURL(blob)
    window.open(url, '_blank', 'noopener')
    setTimeout(() => URL.revokeObjectURL(url), 30000)
  }

  const attachMermaidViewerButton = wrap => {
    let btn = wrap.querySelector('.mermaid-open-btn')
    if (!btn) {
      btn = document.createElement('button')
      btn.type = 'button'
      btn.className = 'mermaid-open-btn'
      wrap.appendChild(btn)
    }

    btn.innerHTML = '<i class="fa fa-search fa-fw" aria-hidden="true"></i>'

    if (!btn.__mermaidViewerBound) {
      btn.addEventListener('click', e => {
        e.preventDefault()
        e.stopPropagation()
        const svg = wrap.__mermaidOriginalSvg || wrap.querySelector('svg')
        if (!svg) return
        const initViewBox = wrap.__mermaidInitViewBox
        if (typeof svg === 'string') {
          openSvgInNewTab({ source: svg, initViewBox })
          return
        }
        openSvgInNewTab({ source: svg, initViewBox })
      })
      btn.__mermaidViewerBound = true
    }
  }

  // Zoom around a point (px, py) in the SVG viewport (in viewBox coordinates)
  const zoomAtPoint = (vb, factor, px, py) => {
    const w = vb[2] * factor
    const h = vb[3] * factor
    const nx = px - (px - vb[0]) * factor
    const ny = py - (py - vb[1]) * factor
    return [nx, ny, w, h]
  }

  const initMermaidGestures = wrap => {
    const svg = wrap.querySelector('svg')
    if (!svg) return

    // Ensure viewBox exists so gestures always work
    const initVb = getSvgViewBox(svg)
    wrap.__mermaidInitViewBox = initVb
    wrap.__mermaidCurViewBox = initVb.slice()
    setSvgViewBox(svg, initVb)

    // Avoid binding multiple times on themeChange/pjax
    if (wrap.__mermaidGestureBound) return
    wrap.__mermaidGestureBound = true

    // Helper: map client (viewport) coordinate -> viewBox coordinate
    const clientToViewBox = (clientX, clientY) => {
      const rect = svg.getBoundingClientRect()
      const vb = wrap.__mermaidCurViewBox || getSvgViewBox(svg)
      const x = vb[0] + (clientX - rect.left) * (vb[2] / rect.width)
      const y = vb[1] + (clientY - rect.top) * (vb[3] / rect.height)
      return { x, y, rect, vb }
    }

    const state = {
      pointers: new Map(),
      startVb: null,
      startDist: 0,
      startCenter: null
    }

    const clampVb = vb => {
      const init = wrap.__mermaidInitViewBox || vb
      const minW = init[2] * 0.1
      const maxW = init[2] * 10
      const minH = init[3] * 0.1
      const maxH = init[3] * 10
      vb[2] = clamp(vb[2], minW, maxW)
      vb[3] = clamp(vb[3], minH, maxH)
      return vb
    }

    const setCurVb = vb => {
      vb = clampVb(vb)
      wrap.__mermaidCurViewBox = vb
      setSvgViewBox(svg, vb)
    }

    const onPointerDown = e => {
      // Allow only primary button for mouse
      if (e.pointerType === 'mouse' && e.button !== 0) return
      svg.setPointerCapture(e.pointerId)
      state.pointers.set(e.pointerId, { x: e.clientX, y: e.clientY })

      if (state.pointers.size === 1) {
        state.startVb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
      } else if (state.pointers.size === 2) {
        const pts = [...state.pointers.values()]
        const dx = pts[0].x - pts[1].x
        const dy = pts[0].y - pts[1].y
        state.startDist = Math.hypot(dx, dy)
        state.startVb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
        state.startCenter = { x: (pts[0].x + pts[1].x) / 2, y: (pts[0].y + pts[1].y) / 2 }
      }
    }

    const onPointerMove = e => {
      if (!state.pointers.has(e.pointerId)) return
      state.pointers.set(e.pointerId, { x: e.clientX, y: e.clientY })

      // Pan with 1 pointer
      if (state.pointers.size === 1 && state.startVb) {
        const p = [...state.pointers.values()][0]
        const prev = { x: e.clientX - e.movementX, y: e.clientY - e.movementY }
        // movementX/Y unreliable on touch, compute from stored last position
        const last = wrap.__mermaidLastSinglePointer || p
        const dxClient = p.x - last.x
        const dyClient = p.y - last.y
        wrap.__mermaidLastSinglePointer = p

        const { rect } = clientToViewBox(p.x, p.y)
        const vb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
        const dx = dxClient * (vb[2] / rect.width)
        const dy = dyClient * (vb[3] / rect.height)
        setCurVb([vb[0] - dx, vb[1] - dy, vb[2], vb[3]])
        return
      }

      // Pinch zoom with 2 pointers
      if (state.pointers.size === 2 && state.startVb && state.startDist > 0) {
        const pts = [...state.pointers.values()]
        const dx = pts[0].x - pts[1].x
        const dy = pts[0].y - pts[1].y
        const dist = Math.hypot(dx, dy)
        if (!dist) return
        const factor = state.startDist / dist // dist bigger => zoom in (viewBox smaller)

        const cx = (pts[0].x + pts[1].x) / 2
        const cy = (pts[0].y + pts[1].y) / 2
        const centerClient = { x: cx, y: cy }

        const pxy = clientToViewBox(centerClient.x, centerClient.y)
        const cpx = pxy.x
        const cpy = pxy.y

        const vb = zoomAtPoint(state.startVb, factor, cpx, cpy)
        setCurVb(vb)
      }
    }

    const onPointerUpOrCancel = e => {
      state.pointers.delete(e.pointerId)
      if (state.pointers.size === 0) {
        state.startVb = null
        state.startDist = 0
        state.startCenter = null
        wrap.__mermaidLastSinglePointer = null
      } else if (state.pointers.size === 1) {
        // reset single pointer baseline to avoid jump
        wrap.__mermaidLastSinglePointer = [...state.pointers.values()][0]
      }
    }

    // Wheel zoom (mouse/trackpad)
    const onWheel = e => {
      // ctrlKey on mac trackpad pinch; we treat both as zoom
      e.preventDefault()
      const delta = e.deltaY
      const zoomFactor = delta > 0 ? 1.1 : 0.9
      const { x, y } = clientToViewBox(e.clientX, e.clientY)
      const vb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
      setCurVb(zoomAtPoint(vb, zoomFactor, x, y))
    }

    const onDblClick = () => {
      const init = wrap.__mermaidInitViewBox
      if (!init) return
      wrap.__mermaidCurViewBox = init.slice()
      setSvgViewBox(svg, init)
    }

    svg.addEventListener('pointerdown', onPointerDown)
    svg.addEventListener('pointermove', onPointerMove)
    svg.addEventListener('pointerup', onPointerUpOrCancel)
    svg.addEventListener('pointercancel', onPointerUpOrCancel)
    svg.addEventListener('wheel', onWheel, { passive: false })
    svg.addEventListener('dblclick', onDblClick)
  }

  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild

      // Clear old render (themeChange/pjax will rerun)
      const oldSvg = item.querySelector('svg')
      if (oldSvg) oldSvg.remove()
      item.__mermaidGestureBound = false

      const config = mermaidSrc.dataset.config ? JSON.parse(mermaidSrc.dataset.config) : {}
      if (!config.theme) {
        config.theme = theme
      }
      const mermaidThemeConfig = `%%{init: ${JSON.stringify(config)}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
        if (true) initMermaidGestures(item)
        item.__mermaidOriginalSvg = svg
        if (true) attachMermaidViewerButton(item)
      }


      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const applyThemeDefaultsConfig = theme => {
    if (theme === 'dark-mode') {
      Chart.defaults.color = "rgba(255, 255, 255, 0.8)"
      Chart.defaults.borderColor = "rgba(255, 255, 255, 0.2)"
      Chart.defaults.scale.ticks.backdropColor = "transparent"
    } else {
      Chart.defaults.color = "rgba(0, 0, 0, 0.8)"
      Chart.defaults.borderColor = "rgba(0, 0, 0, 0.1)"
      Chart.defaults.scale.ticks.backdropColor = "transparent"
    }
  }

  // Recursively traverse the config object and automatically apply theme-specific color schemes
  const applyThemeConfig = (obj, theme) => {
    if (typeof obj !== 'object' || obj === null) return

    Object.keys(obj).forEach(key => {
      const value = obj[key]
      // If the property is an object and has theme-specific options, apply them
      if (typeof value === 'object' && value !== null) {
        if (value[theme]) {
          obj[key] = value[theme] // Apply the value for the current theme
        } else {
          // Recursively process child objects
          applyThemeConfig(value, theme)
        }
      }
    })
  }

  const runChartJS = ele => {
    window.loadChartJS = true

    Array.from(ele).forEach((item, index) => {
      const chartSrc = item.firstElementChild
      const chartID = item.getAttribute('data-chartjs-id') || ('chartjs-' + index) // Use custom ID or default ID
      const width = item.getAttribute('data-width')
      const existingCanvas = document.getElementById(chartID)

      // If a canvas already exists, remove it to avoid rendering duplicates
      if (existingCanvas) {
          existingCanvas.parentNode.remove()
      }

      const chartDefinition = chartSrc.textContent
      const canvas = document.createElement('canvas')
      canvas.id = chartID

      const div = document.createElement('div')
      div.className = 'chartjs-wrap'

      if (width) {
        div.style.width = width
      }

      div.appendChild(canvas)
      chartSrc.insertAdjacentElement('afterend', div)

      const ctx = document.getElementById(chartID).getContext('2d')

      const config = JSON.parse(chartDefinition)

      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark-mode' : 'light-mode'

      // Set default styles (initial setup)
      applyThemeDefaultsConfig(theme)

      // Automatically traverse the config and apply dual-mode color schemes
      applyThemeConfig(config, theme)

      new Chart(ctx, config)
    })
  }

  const loadChartJS = () => {
    const chartJSEle = document.querySelectorAll('#article-container .chartjs-container')
    if (chartJSEle.length === 0) return

    window.loadChartJS ? runChartJS(chartJSEle) : btf.getScript('https://cdn.jsdelivr.net/npm/chart.js@4.5.1/dist/chart.umd.min.js').then(() => runChartJS(chartJSEle))
  }

  // Listen for theme change events
  btf.addGlobalFn('themeChange', loadChartJS, 'chartjs')
  btf.addGlobalFn('encrypt', loadChartJS, 'chartjs')

  window.pjax ? loadChartJS() : document.addEventListener('DOMContentLoaded', loadChartJS)
})()</script></div><script data-pjax src="/self/btf.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="ture"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,200,200" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js" defer="defer"></script><script>document.addEventListener('DOMContentLoaded', () => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => {
      try {
        fn()
      } catch (err) {
        console.debug('Pjax callback failed:', err)
      }
    })
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      true
        ? pjax.loadUrl('/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})</script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.4"></script></div></div></body></html>